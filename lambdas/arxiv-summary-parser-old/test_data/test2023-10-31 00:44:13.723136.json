{"records": [{"identifier": "oai:arXiv.org:2310.18458", "abstract_url": "http://arxiv.org/abs/2310.18458", "authors": [{"last_name": "Zhu", "first_name": "Chloe Qinyu"}, {"last_name": "Stureborg", "first_name": "Rickard"}, {"last_name": "Fain", "first_name": "Brandon"}], "primary_category": "CL", "categories": ["CL", "CY"], "abstract": "  Language Representation Models (LRMs) trained with real-world data may\ncapture and exacerbate undesired bias and cause unfair treatment of people in\nvarious demographic groups. Several techniques have been investigated for\napplying interventions to LRMs to remove bias in benchmark evaluations on, for\nexample, word embeddings. However, the negative side effects of debiasing\ninterventions are usually not revealed in the downstream tasks. We propose\nxGAP-DEBIAS, a set of evaluations on assessing the fairness of debiasing. In\nthis work, We examine four debiasing techniques on a real-world text\nclassification task and show that reducing biasing is at the cost of degrading\nperformance for all demographic groups, including those the debiasing\ntechniques aim to protect. We advocate that a debiasing technique should have\ngood downstream performance with the constraint of ensuring no harm to the\nprotected group.\n", "title": "Do Not Harm Protected Groups in Debiasing Language Representation Models", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18459", "abstract_url": "http://arxiv.org/abs/2310.18459", "authors": [{"last_name": "Piacenza", "first_name": "Pedro"}, {"last_name": "Yuan", "first_name": "Jiacheng"}, {"last_name": "Huh", "first_name": "Jinwook"}, {"last_name": "Isler", "first_name": "Volkan"}], "primary_category": "RO", "categories": ["RO"], "abstract": "  We consider the problem of closed-loop robotic grasping and present a novel\nplanner which uses Visual Feedback and an uncertainty-aware Adaptive Sampling\nstrategy (VFAS) to close the loop. At each iteration, our method VFAS-Grasp\nbuilds a set of candidate grasps by generating random perturbations of a seed\ngrasp. The candidates are then scored using a novel metric which combines a\nlearned grasp-quality estimator, the uncertainty in the estimate and the\ndistance from the seed proposal to promote temporal consistency. Additionally,\nwe present two mechanisms to improve the efficiency of our sampling strategy:\nWe dynamically scale the sampling region size and number of samples in it based\non past grasp scores. We also leverage a motion vector field estimator to shift\nthe center of our sampling region. We demonstrate that our algorithm can run in\nreal time (20 Hz) and is capable of improving grasp performance for static\nscenes by refining the initial grasp proposal. We also show that it can enable\ngrasping of slow moving objects, such as those encountered during human to\nrobot handover.\n", "title": "VFAS-Grasp: Closed Loop Grasping with Visual Feedback and Adaptive\n  Sampling", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18460", "abstract_url": "http://arxiv.org/abs/2310.18460", "authors": [{"last_name": "Le", "first_name": "Tuan Anh"}, {"last_name": "Yang", "first_name": "Xin-She"}], "primary_category": "IT", "categories": ["IT", ""], "abstract": "  This paper proposes a generalized Firefly Algorithm (FA) to solve an\noptimization framework having objective function and constraints as\nmultivariate functions of independent optimization variables. Four\nrepresentative examples of how the proposed generalized FA can be adopted to\nsolve downlink beamforming problems are shown for a classic transmit\nbeamforming, cognitive beamforming, reconfigurable-intelligent-surfaces-aided\n(RIS-aided) transmit beamforming, and RIS-aided wireless power transfer (WPT).\nComplexity analyzes indicate that in large-antenna regimes the proposed FA\napproaches require less computational complexity than their corresponding\ninterior point methods (IPMs) do, yet demand a higher complexity than the\niterative and the successive convex approximation (SCA) approaches do.\nSimulation results reveal that the proposed FA attains the same global optimal\nsolution as that of the IPM for an optimization problem in cognitive\nbeamforming. On the other hand, the proposed FA approaches outperform the\niterative, IPM and SCA in terms of obtaining better solution for optimization\nproblems, respectively, for a classic transmit beamforming, RIS-aided transmit\nbeamforming and RIS-aided WPT.\n", "title": "Generalized Firefly Algorithm for Optimal Transmit Beamforming", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18461", "abstract_url": "http://arxiv.org/abs/2310.18461", "authors": [{"last_name": "Hirvonen", "first_name": "Toni"}, {"last_name": "Namazi", "first_name": "Mahmoud"}], "primary_category": "", "categories": ["", "MM"], "abstract": "  In this paper, techniques for improving multichannel lossless coding are\nexamined. A method is proposed for the simultaneous coding of two or more\ndifferent renderings (mixes) of the same content. The signal model uses both\npast samples of the upmix, and the current time samples of downmix samples to\npredict the upmix. Model parameters are optimized via a general linear solver,\nand the prediction residual is Rice coded. Additionally, the use of an SVD\nprojection prior to residual coding is proposed. A comparison is made against\nvarious baselines, including FLAC. The proposed methods show improved\ncompression ratios for the storage and transmission of immersive audio.\n", "title": "Improved Lossless Coding for Storage and Transmission of Multichannel\n  Immersive Audio", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18463", "abstract_url": "http://arxiv.org/abs/2310.18463", "authors": [{"last_name": "Li", "first_name": "Mingchen"}, {"last_name": "Chen", "first_name": "M."}, {"last_name": "Zhou", "first_name": "Huixue"}, {"last_name": "Zhang", "first_name": "Rui"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  The automatic extraction of biomedical entities and their interaction from\nunstructured data remains a challenging task due to the limited availability of\nexpert-labeled standard datasets. In this paper, we introduce PETAI-LOR, a\nretrieval-based language framework that is augmented by tailored chunk scorer.\nUnlike previous retrieval-augmented language models (LM) that retrieve relevant\ndocuments by calculating the similarity between the input sentence and the\ncandidate document set, PETAILOR segments the sentence into chunks and\nretrieves the relevant chunk from our pre-computed chunk-based relational\nkey-value memory. Moreover, in order to comprehend the specific requirements of\nthe LM, PETAI-LOR adapt the tailored chunk scorer to the LM. We also introduce\nGM-CIHT, an expert annotated biomedical triple extraction dataset with more\nrelation types. This dataset is centered on the non-drug treatment and general\nbiomedical domain. Additionally, we investigate the efficacy of triple\nextraction models trained on general domains when applied to the biomedical\ndomain. Our experiments reveal that PETAI-LOR achieves state-of-the-art\nperformance on GM-CIHT\n", "title": "PeTailor: Improving Large Language Model by Tailored Chunk Scorer in\n  Biomedical Triple Extraction", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18465", "abstract_url": "http://arxiv.org/abs/2310.18465", "authors": [{"last_name": "Tajdini", "first_name": "Artin"}, {"last_name": "Jain", "first_name": "Lalit"}, {"last_name": "Jamieson", "first_name": "Kevin"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  We consider maximizing a monotonic, submodular set function $f: 2^{[n]}\n\\rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is\nunknown to the learner but at each time $t=1,\\dots,T$ the learner chooses a set\n$S_t \\subset [n]$ with $|S_t| \\leq k$ and receives reward $f(S_t) + \\eta_t$\nwhere $\\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize\nthe learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation\nof maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of\n$f$. To date, the best regret bound in the literature scales as $k n^{1/3}\nT^{2/3}$. And by trivially treating every set as a unique arm one deduces that\n$\\sqrt{ {n \\choose k} T }$ is also achievable. In this work, we establish the\nfirst minimax lower bound for this setting that scales like\n$\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$. Moreover, we\npropose an algorithm that is capable of matching the lower bound regret.\n", "title": "Minimax Optimal Submodular Optimization with Bandit Feedback", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18467", "abstract_url": "http://arxiv.org/abs/2310.18467", "authors": [{"last_name": "Dao", "first_name": "Tuan Anh"}, {"last_name": "Nazarov", "first_name": "Murtazo"}, {"last_name": "Tomas", "first_name": "Ignacio"}], "primary_category": "", "categories": ["", ""], "abstract": "  We introduce a novel structure-preserving method in order to approximate the\ncompressible ideal Magnetohydrodynamics (MHD) equations. This technique\naddresses the MHD equations using a non-divergence formulation, where the\ncontributions of the magnetic field to the momentum and total mechanical energy\nare treated as source terms. Our approach uses the Marchuk-Strang splitting\ntechnique and involves three distinct components: a compressible Euler solver,\na source-system solver, and an update procedure for the total mechanical\nenergy. The scheme allows for significant freedom on the choice of Euler's\nequation solver, while the magnetic field is discretized using a\ncurl-conforming finite element space, yielding exact preservation of the\ninvolution constraints. We prove that the method preserves invariant domain\nproperties, including positivity of density, positivity of internal energy, and\nthe minimum principle of the specific entropy. If the scheme used to solve\nEuler's equation conserves total energy, then the resulting MHD scheme can be\nproven to preserve total energy. Similarly, if the scheme used to solve Euler's\nequation is entropy-stable, then the resulting MHD scheme is entropy stable as\nwell. In our approach, the CFL condition does not depend on magnetosonic\nwave-speeds, but only on the usual maximum wave speed from Euler's system. To\nvalidate the effectiveness of our method, we solve a variety of ideal MHD\nproblems, showing that the method is capable of delivering high-order accuracy\nin space for smooth problems, while also offering unconditional robustness in\nthe shock hydrodynamics regime as well.\n", "title": "Structure preserving numerical methods for the ideal compressible MHD\n  system", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18469", "abstract_url": "http://arxiv.org/abs/2310.18469", "authors": [{"last_name": "Leblond-Menard", "first_name": "Cedric"}, {"last_name": "Picard-Krashevski", "first_name": "Gabriel"}, {"last_name": "Achiche", "first_name": "Sofiane"}], "primary_category": "CV", "categories": ["CV", "", "HC", "LG"], "abstract": "  Although the number of gaze estimation datasets is growing, the application\nof appearance-based gaze estimation methods is mostly limited to estimating the\npoint of gaze on a screen. This is in part because most datasets are generated\nin a similar fashion, where the gaze target is on a screen close to camera's\norigin. In other applications such as assistive robotics or marketing research,\nthe 3D point of gaze might not be close to the camera's origin, meaning models\ntrained on current datasets do not generalize well to these tasks. We therefore\nsuggest generating a textured tridimensional mesh of the face and rendering the\ntraining images from a virtual camera at a specific position and orientation\nrelated to the application as a mean of augmenting the existing datasets. In\nour tests, this lead to an average 47% decrease in gaze estimation angular\nerror.\n", "title": "Semi-Synthetic Dataset Augmentation for Application-Specific Gaze\n  Estimation", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18471", "abstract_url": "http://arxiv.org/abs/2310.18471", "authors": [{"last_name": "Walker", "first_name": "Elise"}, {"last_name": "Actor", "first_name": "Jonas A."}, {"last_name": "Martinez", "first_name": "Carianne"}, {"last_name": "Trask", "first_name": "Nathaniel"}], "primary_category": "LG", "categories": ["LG", "", "", ""], "abstract": "  Causal representation learning algorithms discover lower-dimensional\nrepresentations of data that admit a decipherable interpretation of cause and\neffect; as achieving such interpretable representations is challenging, many\ncausal learning algorithms utilize elements indicating prior information, such\nas (linear) structural causal models, interventional data, or weak supervision.\nUnfortunately, in exploratory causal representation learning, such elements and\nprior information may not be available or warranted. Alternatively, scientific\ndatasets often have multiple modalities or physics-based constraints, and the\nuse of such scientific, multimodal data has been shown to improve\ndisentanglement in fully unsupervised settings. Consequently, we introduce a\ncausal representation learning algorithm (causalPIMA) that can use multimodal\ndata and known physics to discover important features with causal\nrelationships. Our innovative algorithm utilizes a new differentiable\nparametrization to learn a directed acyclic graph (DAG) together with a latent\nspace of a variational autoencoder in an end-to-end differentiable framework\nvia a single, tractable evidence lower bound loss function. We place a Gaussian\nmixture prior on the latent space and identify each of the mixtures with an\noutcome of the DAG nodes; this novel identification enables feature discovery\nwith causal relationships. Tested against a synthetic and a scientific dataset,\nour results demonstrate the capability of learning an interpretable causal\nstructure while simultaneously discovering key features in a fully unsupervised\nsetting.\n", "title": "Causal disentanglement of multimodal data", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18472", "abstract_url": "http://arxiv.org/abs/2310.18472", "authors": [{"last_name": "Barabadi", "first_name": "Maede Ashofteh"}, {"last_name": "Zhu", "first_name": "Xiaodan"}, {"last_name": "Chan", "first_name": "Wai Yip"}, {"last_name": "Simpson", "first_name": "Amber L."}, {"last_name": "Do", "first_name": "Richard K. G."}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Understanding the progression of cancer is crucial for defining treatments\nfor patients. The objective of this study is to automate the detection of\nmetastatic liver disease from free-style computed tomography (CT) radiology\nreports. Our research demonstrates that transferring knowledge using three\napproaches can improve model performance. First, we utilize generic language\nmodels (LMs), pretrained in a self-supervised manner. Second, we use a\nsemi-supervised approach to train our model by automatically annotating a large\nunlabeled dataset; this approach substantially enhances the model's\nperformance. Finally, we transfer knowledge from related tasks by designing a\nmulti-task transfer learning methodology. We leverage the recent advancement of\nparameter-efficient LM adaptation strategies to improve performance and\ntraining efficiency. Our dataset consists of CT reports collected at Memorial\nSloan Kettering Cancer Center (MSKCC) over the course of 12 years. 2,641\nreports were manually annotated by domain experts; among them, 841 reports have\nbeen annotated for the presence of liver metastases. Our best model achieved an\nF1-score of 73.8%, a precision of 84%, and a recall of 65.8%.\n", "title": "Parameter-Efficient Methods for Metastases Detection from Clinical Notes", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18473", "abstract_url": "http://arxiv.org/abs/2310.18473", "authors": [{"last_name": "Piacenza", "first_name": "Pedro"}, {"last_name": "Lee", "first_name": "Daewon"}, {"last_name": "Isler", "first_name": "Volkan"}], "primary_category": "RO", "categories": ["RO"], "abstract": "  As service robots begin to be deployed to assist humans, it is important for\nthem to be able to perform a skill as ubiquitous as pouring. Specifically, we\nfocus on the task of pouring an exact amount of water without any environmental\ninstrumentation, that is, using only the robot's own sensors to perform this\ntask in a general way robustly. In our approach we use a simple PID controller\nwhich uses the measured change in weight of the held container to supervise the\npour. Unlike previous methods which use specialized force-torque sensors at the\nrobot wrist, we use our robot joint torque sensors and investigate the added\nbenefit of tactile sensors at the fingertips. We train three estimators from\ndata which regress the poured weight out of the source container and show that\nwe can accurately pour within 10 ml of the target on average while being robust\nenough to pour at novel locations and with different grasps on the source\ncontainer.\n", "title": "Pouring by Feel: An Analysis of Tactile and Proprioceptive Sensing for\n  Accurate Pouring", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18477", "abstract_url": "http://arxiv.org/abs/2310.18477", "authors": [{"last_name": "Deng", "first_name": "Yian"}, {"last_name": "Mu", "first_name": "Tingting"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  The strategy of ensemble has become popular in adversarial defense, which\ntrains multiple base classifiers to defend against adversarial attacks in a\ncooperative manner. Despite the empirical success, theoretical explanations on\nwhy an ensemble of adversarially trained classifiers is more robust than single\nones remain unclear. To fill in this gap, we develop a new error theory\ndedicated to understanding ensemble adversarial defense, demonstrating a\nprovable 0-1 loss reduction on challenging sample sets in an adversarial\ndefense scenario. Guided by this theory, we propose an effective approach to\nimprove ensemble adversarial defense, named interactive global adversarial\ntraining (iGAT). The proposal includes (1) a probabilistic distributing rule\nthat selectively allocates to different base classifiers adversarial examples\nthat are globally challenging to the ensemble, and (2) a regularization term to\nrescue the severest weaknesses of the base classifiers. Being tested over\nvarious existing ensemble adversarial defense techniques, iGAT is capable of\nboosting their performance by increases up to 17% evaluated using CIFAR10 and\nCIFAR100 datasets under both white-box and black-box attacks.\n", "title": "Understanding and Improving Ensemble Adversarial Defense", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18479", "abstract_url": "http://arxiv.org/abs/2310.18479", "authors": [{"last_name": "Osti", "first_name": "Manish"}, {"last_name": "Thakuri", "first_name": "Aashray"}, {"last_name": "Qolomany", "first_name": "Basheer"}, {"last_name": "Mulahuwaish", "first_name": "Aos"}], "primary_category": "LG", "categories": ["LG", "", "DC"], "abstract": "  This study presents Weighted Sampled Split Learning (WSSL), an innovative\nframework tailored to bolster privacy, robustness, and fairness in distributed\nmachine learning systems. Unlike traditional approaches, WSSL disperses the\nlearning process among multiple clients, thereby safeguarding data\nconfidentiality. Central to WSSL's efficacy is its utilization of weighted\nsampling. This approach ensures equitable learning by tactically selecting\ninfluential clients based on their contributions. Our evaluation of WSSL\nspanned various client configurations and employed two distinct datasets: Human\nGait Sensor and CIFAR-10. We observed three primary benefits: heightened model\naccuracy, enhanced robustness, and maintained fairness across diverse client\ncompositions. Notably, our distributed frameworks consistently surpassed\ncentralized counterparts, registering accuracy peaks of 82.63% and 75.51% for\nthe Human Gait Sensor and CIFAR-10 datasets, respectively. These figures\ncontrast with the top accuracies of 81.12% and 58.60% achieved by centralized\nsystems. Collectively, our findings champion WSSL as a potent and scalable\nsuccessor to conventional centralized learning, marking it as a pivotal stride\nforward in privacy-focused, resilient, and impartial distributed machine\nlearning.\n", "title": "Weighted Sampled Split Learning (WSSL): Balancing Privacy, Robustness,\n  and Fairness in Distributed Learning Environments", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18480", "abstract_url": "http://arxiv.org/abs/2310.18480", "authors": [{"last_name": "Zhong", "first_name": "Haitian"}, {"last_name": "Sankoff", "first_name": "David"}], "primary_category": "CE", "categories": ["CE", ""], "abstract": "  Capacity restrictions in stores, maintained by mechanisms like spacing\ncustomer intake, became familiar features of retailing in the time of the\npandemic. Shopping rates in a crowded store under a social distance regime is\nprone to considerable slowdown. Inspired by the random particle collision\nconcepts of statistical mechanics, we introduce a dynamical model of the\nevolution of shopping rate as a function of a given customer intake rate. The\nslowdown of each individual customer is incorporated as an additive term to a\nbaseline value shopping time, proportional to the number of other customers in\nthe store. We determine analytically and by simulation the trajectory of the\nmodel as it approaches a Little's Law equilibrium, and identify the point\nbeyond which equilibrium cannot be achieved. By relating customer shopping rate\nto the slowdown compared to the baseline, we can calculate the optimal intake\nrate leading to maximum equilibrium spending. This turns out to be the maximum\nrate compatible with equilibrium. The slowdown due to the largest possible\nnumber of shoppers is more than compensated for by the increased volume of\nshopping. This macroscopic model is validated by simulation experiments in\nwhich avoidance interactions between pairs of shoppers are responsible for\nshopping delays.\n", "title": "Capacity, Collision Avoidance and Shopping Rate under a Social\n  Distancing Regime", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18481", "abstract_url": "http://arxiv.org/abs/2310.18481", "authors": [{"last_name": "Hu", "first_name": "Bodun"}, {"last_name": "Xu", "first_name": "Le"}, {"last_name": "Moon", "first_name": "Jeongyoon"}, {"last_name": "Yadwadkar", "first_name": "Neeraja J."}, {"last_name": "Akella", "first_name": "Aditya"}], "primary_category": "LG", "categories": ["LG", "", "OS"], "abstract": "  Rapid advancements over the years have helped machine learning models reach\npreviously hard-to-achieve goals, sometimes even exceeding human capabilities.\nHowever, to attain the desired accuracy, the model sizes and in turn their\ncomputational requirements have increased drastically. Thus, serving\npredictions from these models to meet any target latency and cost requirements\nof applications remains a key challenge, despite recent work in building\ninference-serving systems as well as algorithmic approaches that dynamically\nadapt models based on inputs. In this paper, we introduce a form of dynamism,\nmodality selection, where we adaptively choose modalities from inference inputs\nwhile maintaining the model quality. We introduce MOSEL, an automated inference\nserving system for multi-modal ML models that carefully picks input modalities\nper request based on user-defined performance and accuracy requirements. MOSEL\nexploits modality configurations extensively, improving system throughput by\n3.6$\\times$ with an accuracy guarantee and shortening job completion times by\n11$\\times$.\n", "title": "MOSEL: Inference Serving Using Dynamic Modality Selection", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18491", "abstract_url": "http://arxiv.org/abs/2310.18491", "authors": [{"last_name": "Fairoze", "first_name": "Jaiden"}, {"last_name": "Garg", "first_name": "Sanjam"}, {"last_name": "Jha", "first_name": "Somesh"}, {"last_name": "Mahloujifar", "first_name": "Saeed"}, {"last_name": "Mahmoody", "first_name": "Mohammad"}, {"last_name": "Wang", "first_name": "Mingyuan"}], "primary_category": "LG", "categories": ["LG", "CL", "CR"], "abstract": "  We construct the first provable watermarking scheme for language models with\npublic detectability or verifiability: we use a private key for watermarking\nand a public key for watermark detection. Our protocol is the first\nwatermarking scheme that does not embed a statistical signal in generated text.\nRather, we directly embed a publicly-verifiable cryptographic signature using a\nform of rejection sampling. We show that our construction meets strong formal\nsecurity guarantees and preserves many desirable properties found in schemes in\nthe private-key watermarking setting. In particular, our watermarking scheme\nretains distortion-freeness and model agnosticity. We implement our scheme and\nmake empirical measurements over open models in the 7B parameter range. Our\nexperiments suggest that our watermarking scheme meets our formal claims while\npreserving text quality.\n", "title": "Publicly Detectable Watermarking for Language Models", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18493", "abstract_url": "http://arxiv.org/abs/2310.18493", "authors": [{"last_name": "Tsai", "first_name": "Ping-Hsuan"}, {"last_name": "Chung", "first_name": "Seung Whan"}, {"last_name": "Ghosh", "first_name": "Debojyoti"}, {"last_name": "Loffeld", "first_name": "John"}, {"last_name": "Choi", "first_name": "Youngsoo"}, {"last_name": "Belof", "first_name": "Jonathan L."}], "primary_category": "", "categories": ["", ""], "abstract": "  Despite the advancements in high-performance computing and modern numerical\nalgorithms, the cost remains prohibitive for multi-query kinetic plasma\nsimulations. In this work, we develop data-driven reduced-order models (ROM)\nfor collisionless electrostatic plasma dynamics, based on the kinetic\nVlasov-Poisson equation. Our ROM approach projects the equation onto a linear\nsubspace defined by principal proper orthogonal decomposition (POD) modes. We\nintroduce an efficient tensorial method to update the nonlinear term using a\nprecomputed third-order tensor. We capture multiscale behavior with a minimal\nnumber of POD modes by decomposing the solution into multiple time windows\nusing a physical-time indicator and creating a temporally-local ROM. Applied to\n1D-1V simulations, specifically the benchmark two-stream instability case, our\ntime-windowed reduced-order model (TW-ROM) with the tensorial approach solves\nthe equation approximately 450 times faster than Eulerian simulations while\nmaintaining a maximum relative error of 3% for the training data and 12% for\nthe testing data.\n", "title": "Accelerating Kinetic Simulations of Electrostatic Plasmas with\n  Reduced-Order Modeling", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18494", "abstract_url": "http://arxiv.org/abs/2310.18494", "authors": [{"last_name": "Sizikova", "first_name": "Elena"}, {"last_name": "Saharkhiz", "first_name": "Niloufar"}, {"last_name": "Sharma", "first_name": "Diksha"}, {"last_name": "Lago", "first_name": "Miguel"}, {"last_name": "Sahiner", "first_name": "Berkman"}, {"last_name": "Delfino", "first_name": "Jana G."}, {"last_name": "Badano", "first_name": "Aldo"}], "primary_category": "", "categories": ["", "CV"], "abstract": "  To generate evidence regarding the safety and efficacy of artificial\nintelligence (AI) enabled medical devices, AI models need to be evaluated on a\ndiverse population of patient cases, some of which may not be readily\navailable. We propose an evaluation approach for testing medical imaging AI\nmodels that relies on in silico imaging pipelines in which stochastic digital\nmodels of human anatomy (in object space) with and without pathology are imaged\nusing a digital replica imaging acquisition system to generate realistic\nsynthetic image datasets. Here, we release M-SYNTH, a dataset of cohorts with\nfour breast fibroglandular density distributions imaged at different exposure\nlevels using Monte Carlo x-ray simulations with the publicly available Virtual\nImaging Clinical Trial for Regulatory Evaluation (VICTRE) toolkit. We utilize\nthe synthetic dataset to analyze AI model performance and find that model\nperformance decreases with increasing breast density and increases with higher\nmass density, as expected. As exposure levels decrease, AI model performance\ndrops with the highest performance achieved at exposure levels lower than the\nnominal recommended dose for the breast type.\n", "title": "Knowledge-based in silico models and dataset for the comparative\n  evaluation of mammography AI for a range of breast characteristics, lesion\n  conspicuities and doses", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18496", "abstract_url": "http://arxiv.org/abs/2310.18496", "authors": [{"last_name": "Carmichael", "first_name": "Zachariah"}, {"last_name": "Scheirer", "first_name": "Walter J."}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Surging interest in deep learning from high-stakes domains has precipitated\nconcern over the inscrutable nature of black box neural networks. Explainable\nAI (XAI) research has led to an abundance of explanation algorithms for these\nblack boxes. Such post hoc explainers produce human-comprehensible\nexplanations, however, their fidelity with respect to the model is not well\nunderstood - explanation evaluation remains one of the most challenging issues\nin XAI. In this paper, we ask a targeted but important question: can popular\nfeature-additive explainers (e.g., LIME, SHAP, SHAPR, MAPLE, and PDP) explain\nfeature-additive predictors? Herein, we evaluate such explainers on ground\ntruth that is analytically derived from the additive structure of a model. We\ndemonstrate the efficacy of our approach in understanding these explainers\napplied to symbolic expressions, neural networks, and generalized additive\nmodels on thousands of synthetic and several real-world tasks. Our results\nsuggest that all explainers eventually fail to correctly attribute the\nimportance of features, especially when a decision-making process involves\nfeature interactions.\n", "title": "How Well Do Feature-Additive Explainers Explain Feature-Additive\n  Predictors?", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18498", "abstract_url": "http://arxiv.org/abs/2310.18498", "authors": [{"last_name": "Chen", "first_name": "Ruibo"}, {"last_name": "Xiong", "first_name": "Tianyi"}, {"last_name": "Wu", "first_name": "Yihan"}, {"last_name": "Liu", "first_name": "Guodong"}, {"last_name": "Hu", "first_name": "Zhengmian"}, {"last_name": "Chen", "first_name": "Lichang"}, {"last_name": "Chen", "first_name": "Yanshuo"}, {"last_name": "Liu", "first_name": "Chenxi"}, {"last_name": "Huang", "first_name": "Heng"}], "primary_category": "CV", "categories": ["CV", "LG"], "abstract": "  This technical report delves into the application of GPT-4 Vision (GPT-4V) in\nthe nuanced realm of COVID-19 image classification, leveraging the\ntransformative potential of in-context learning to enhance diagnostic\nprocesses.\n", "title": "GPT-4 Vision on Medical Image Classification -- A Case Study on COVID-19\n  Dataset", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18502", "abstract_url": "http://arxiv.org/abs/2310.18502", "authors": [{"last_name": "Valentini", "first_name": "Maria"}, {"last_name": "Weber", "first_name": "Jennifer"}, {"last_name": "Salcido", "first_name": "Jesus"}, {"last_name": "Wright", "first_name": "T\u00e9a"}, {"last_name": "Colunga", "first_name": "Eliana"}, {"last_name": "Kann", "first_name": "Katharina"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  With recent advances in large language models (LLMs), the concept of\nautomatically generating children's educational materials has become\nincreasingly realistic. Working toward the goal of age-appropriate simplicity\nin generated educational texts, we first examine the ability of several popular\nLLMs to generate stories with properly adjusted lexical and readability levels.\nWe find that, in spite of the growing capabilities of LLMs, they do not yet\npossess the ability to limit their vocabulary to levels appropriate for younger\nage groups. As a second experiment, we explore the ability of state-of-the-art\nlexical simplification models to generalize to the domain of children's stories\nand, thus, create an efficient pipeline for their automatic generation. In\norder to test these models, we develop a dataset of child-directed lexical\nsimplification instances, with examples taken from the LLM-generated stories in\nour first experiment. We find that, while the strongest-performing current\nlexical simplification models do not perform as well on material designed for\nchildren due to their reliance on large language models behind the scenes, some\nmodels that still achieve fairly strong results on general data can mimic or\neven improve their performance on children-directed data with proper\nfine-tuning, which we conduct using our newly created child-directed\nsimplification dataset.\n", "title": "On the Automatic Generation and Simplification of Children's Stories", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18505", "abstract_url": "http://arxiv.org/abs/2310.18505", "authors": [{"last_name": "Eweis-LaBolle", "first_name": "Jonathan Tammer"}, {"last_name": "Zhao", "first_name": "Chuanning"}, {"last_name": "Won", "first_name": "Yoonjin"}, {"last_name": "Bostanabad", "first_name": "Ramin"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  As modern electronic devices are increasingly miniaturized and integrated,\ntheir performance relies more heavily on effective thermal management.\nTwo-phase cooling methods enhanced by porous surfaces, which capitalize on\nthin-film evaporation atop structured porous surfaces, are emerging as\npotential solutions. In such porous structures, the optimum heat dissipation\ncapacity relies on two competing objectives that depend on mass and heat\ntransfer. The computational costs of evaluating these objectives, the high\ndimensionality of the design space which a voxelated microstructure\nrepresentation, and the manufacturability constraints hinder the optimization\nprocess for thermal management. We address these challenges by developing a\ndata-driven framework for designing optimal porous microstructures for cooling\napplications. In our framework we leverage spectral density functions (SDFs) to\nencode the design space via a handful of interpretable variables and, in turn,\nefficiently search it. We develop physics-based formulas to quantify the\nthermofluidic properties and feasibility of candidate designs via offline\nsimulations. To decrease the reliance on expensive simulations, we generate\nmulti-fidelity data and build emulators to find Pareto-optimal designs. We\napply our approach to a canonical problem on evaporator wick design and obtain\nfin-like topologies in the optimal microstructures which are also\ncharacteristics often observed in industrial applications.\n", "title": "Multi-fidelity Design of Porous Microstructures for Thermofluidic\n  Applications", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18509", "abstract_url": "http://arxiv.org/abs/2310.18509", "authors": [{"last_name": "Gaudet", "first_name": "Brian"}, {"last_name": "Drozd", "first_name": "Kris"}, {"last_name": "Furfaro", "first_name": "Roberto"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  We use deep reinforcement learning (RL) to optimize a weapons to target\nassignment (WTA) policy for multi-vehicle hypersonic strike against multiple\ntargets. The objective is to maximize the total value of destroyed targets in\neach episode. Each randomly generated episode varies the number and initial\nconditions of the hypersonic strike weapons (HSW) and targets, the value\ndistribution of the targets, and the probability of a HSW being intercepted. We\ncompare the performance of this WTA policy to that of a benchmark WTA policy\nderived using non-linear integer programming (NLIP), and find that the RL WTA\npolicy gives near optimal performance with a 1000X speedup in computation time,\nallowing real time operation that facilitates autonomous decision making in the\nmission end game.\n", "title": "Deep Reinforcement Learning for Weapons to Targets Assignment in a\n  Hypersonic strike", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18511", "abstract_url": "http://arxiv.org/abs/2310.18511", "authors": [{"last_name": "Slim", "first_name": "Habib"}, {"last_name": "Li", "first_name": "Xiang"}, {"last_name": "Li", "first_name": "Yuchen"}, {"last_name": "Ahmed", "first_name": "Mahmoud"}, {"last_name": "Ayman", "first_name": "Mohamed"}, {"last_name": "Upadhyay", "first_name": "Ujjwal"}, {"last_name": "Abdelreheem", "first_name": "Ahmed"}, {"last_name": "Prajapati", "first_name": "Arpit"}, {"last_name": "Pothigara", "first_name": "Suhail"}, {"last_name": "Wonka", "first_name": "Peter"}, {"last_name": "Elhoseiny", "first_name": "Mohamed"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  In this work, we present 3DCoMPaT$^{++}$, a multimodal 2D/3D dataset with 160\nmillion rendered views of more than 10 million stylized 3D shapes carefully\nannotated at the part-instance level, alongside matching RGB point clouds, 3D\ntextured meshes, depth maps, and segmentation masks. 3DCoMPaT$^{++}$ covers 41\nshape categories, 275 fine-grained part categories, and 293 fine-grained\nmaterial classes that can be compositionally applied to parts of 3D objects. We\nrender a subset of one million stylized shapes from four equally spaced views\nas well as four randomized views, leading to a total of 160 million renderings.\nParts are segmented at the instance level, with coarse-grained and fine-grained\nsemantic levels. We introduce a new task, called Grounded CoMPaT Recognition\n(GCR), to collectively recognize and ground compositions of materials on parts\nof 3D objects. Additionally, we report the outcomes of a data challenge\norganized at CVPR2023, showcasing the winning method's utilization of a\nmodified PointNet$^{++}$ model trained on 6D inputs, and exploring alternative\ntechniques for GCR enhancement. We hope our work will help ease future research\non compositional 3D Vision.\n", "title": "3DCoMPaT$^{++}$: An improved Large-scale 3D Vision Dataset for\n  Compositional Recognition", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18512", "abstract_url": "http://arxiv.org/abs/2310.18512", "authors": [{"last_name": "Roger", "first_name": "Fabien"}, {"last_name": "Greenblatt", "first_name": "Ryan"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Large language models (LLMs) often benefit from intermediate steps of\nreasoning to generate answers to complex problems. When these intermediate\nsteps of reasoning are used to monitor the activity of the model, it is\nessential that this explicit reasoning is faithful, i.e. that it reflects what\nthe model is actually reasoning about. In this work, we focus on one potential\nway intermediate steps of reasoning could be unfaithful: encoded reasoning,\nwhere an LLM could encode intermediate steps of reasoning in the generated text\nin a way that is not understandable to human readers. We show that language\nmodels can be trained to make use of encoded reasoning to get higher\nperformance without the user understanding the intermediate steps of reasoning.\nWe argue that, as language models get stronger, this behavior becomes more\nlikely to appear naturally. Finally, we describe a methodology that enables the\nevaluation of defenses against encoded reasoning, and show that, under the\nright conditions, paraphrasing successfully prevents even the best encoding\nschemes we built from encoding more than 3 bits of information per KB of text.\n", "title": "Preventing Language Models From Hiding Their Reasoning", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18515", "abstract_url": "http://arxiv.org/abs/2310.18515", "authors": [{"last_name": "Bushuiev", "first_name": "Anton"}, {"last_name": "Bushuiev", "first_name": "Roman"}, {"last_name": "Filkin", "first_name": "Anatolii"}, {"last_name": "Kouba", "first_name": "Petr"}, {"last_name": "Gabrielova", "first_name": "Marketa"}, {"last_name": "Gabriel", "first_name": "Michal"}, {"last_name": "Sedlar", "first_name": "Jiri"}, {"last_name": "Pluskal", "first_name": "Tomas"}, {"last_name": "Damborsky", "first_name": "Jiri"}, {"last_name": "Mazurenko", "first_name": "Stanislav"}, {"last_name": "Sivic", "first_name": "Josef"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Discovering mutations enhancing protein-protein interactions (PPIs) is\ncritical for advancing biomedical research and developing improved\ntherapeutics. While machine learning approaches have substantially advanced the\nfield, they often struggle to generalize beyond training data in practical\nscenarios. The contributions of this work are three-fold. First, we construct\nPPIRef, the largest and non-redundant dataset of 3D protein-protein\ninteractions, enabling effective large-scale learning. Second, we leverage the\nPPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model\ngeneralizing across diverse protein-binder variants. We fine-tune PPIformer to\npredict effects of mutations on protein-protein interactions via a\nthermodynamically motivated adjustment of the pre-training loss function.\nFinally, we demonstrate the enhanced generalization of our new PPIformer\napproach by outperforming other state-of-the-art methods on new, non-leaking\nsplits of standard labeled PPI mutational data and independent case studies\noptimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic\nactivity of staphylokinase.\n", "title": "Learning to design protein-protein interactions with enhanced\n  generalization", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18517", "abstract_url": "http://arxiv.org/abs/2310.18517", "authors": [{"last_name": "Zunair", "first_name": "Hasib"}, {"last_name": "Hamza", "first_name": "A. Ben"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Recognizing multiple objects in an image is challenging due to occlusions,\nand becomes even more so when the objects are small. While promising, existing\nmulti-label image recognition models do not explicitly learn context-based\nrepresentations, and hence struggle to correctly recognize small and occluded\nobjects. Intuitively, recognizing occluded objects requires knowledge of\npartial input, and hence context. Motivated by this intuition, we propose\nMasked Supervised Learning (MSL), a single-stage, model-agnostic learning\nparadigm for multi-label image recognition. The key idea is to learn\ncontext-based representations using a masked branch and to model label\nco-occurrence using label consistency. Experimental results demonstrate the\nsimplicity, applicability and more importantly the competitive performance of\nMSL against previous state-of-the-art methods on standard multi-label image\nrecognition benchmarks. In addition, we show that MSL is robust to random\nmasking and demonstrate its effectiveness in recognizing non-masked objects.\nCode and pretrained models are available on GitHub.\n", "title": "Learning to recognize occluded and small objects with partial inputs", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18518", "abstract_url": "http://arxiv.org/abs/2310.18518", "authors": [{"last_name": "Bousquet", "first_name": "Nicolas"}, {"last_name": "De Meyer", "first_name": "Lucas"}, {"last_name": "Pierron", "first_name": "Th\u00e9o"}, {"last_name": "Wesolek", "first_name": "Alexandra"}], "primary_category": "CG", "categories": ["CG", "DM", ""], "abstract": "  A non-crossing spanning tree of a set of points in the plane is a spanning\ntree whose edges pairwise do not cross. Avis and Fukuda in 1996 proved that\nthere always exists a flip sequence of length at most $2n-4$ between any pair\nof non-crossing spanning trees (where $n$ denotes the number of points).\nHernando et al. proved that the length of a minimal flip sequence can be of\nlength at least $\\frac 32 n$. Two recent results of Aichholzer et al. and\nBousquet et al. improved the Avis and Fukuda upper bound by proving that there\nalways exists a flip sequence of length respectively at most $2n - \\log n$ and\n$2n - \\sqrt{n}$. We improve the upper bound by a linear factor for the first\ntime in 25 years by proving that there always exists a flip sequence between\nany pair of non-crossing spanning trees $T_1,T_2$ of length at most $c n$ where\n$c \\approx 1.95$. Our result is actually stronger since we prove that, for any\ntwo trees $T_1,T_2$, there exists a flip sequence from $T_1$ to $T_2$ of length\nat most $c |T_1 \\setminus T_2|$. We also improve the best lower bound in terms\nof the symmetric difference by proving that there exists a pair of trees\n$T_1,T_2$ such that a minimal flip sequence has length $\\frac 53 |T_1 \\setminus\nT_2|$, improving the lower bound of Hernando et al. by considering the\nsymmetric difference instead of the number of vertices. We generalize this\nlower bound construction to non-crossing flips (where we close the gap between\nupper and lower bounds) and rotations.\n", "title": "Reconfiguration of plane trees in convex geometric graphs", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18523", "abstract_url": "http://arxiv.org/abs/2310.18523", "authors": [{"last_name": "Fuchs", "first_name": "Lukas"}, {"last_name": "Kirstein", "first_name": "Tom"}, {"last_name": "Mahr", "first_name": "Christoph"}, {"last_name": "Furat", "first_name": "Orkun"}, {"last_name": "Baric", "first_name": "Valentin"}, {"last_name": "Rosenauer", "first_name": "Andreas"}, {"last_name": "Maedler", "first_name": "Lutz"}, {"last_name": "Schmidt", "first_name": "Volker"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  The structural characterization of hetero-aggregates in 3D is of great\ninterest, e.g., for deriving process-structure or structure-property\nrelationships. However, since 3D imaging techniques are often difficult to\nperform as well as time and cost intensive, a characterization of\nhetero-aggregates based on 2D image data is desirable, but often non-trivial.\nTo overcome the issues of characterizing 3D structures from 2D measurements, a\nmethod is presented that relies on machine learning combined with methods of\nspatial stochastic modeling, where the latter are utilized for the generation\nof synthetic training data. This kind of training data has the advantage that\ntime-consuming experiments for the synthesis of differently structured\nmaterials followed by their 3D imaging can be avoided. More precisely, a\nparametric stochastic 3D model is presented, from which a wide spectrum of\nvirtual hetero-aggregates can be generated. Additionally, the virtual\nstructures are passed to a physics-based simulation tool in order to generate\nvirtual scanning transmission electron microscopy (STEM) images. The preset\nparameters of the 3D model together with the simulated STEM images serve as a\ndatabase for the training of convolutional neural networks, which can be used\nto determine the parameters of the underlying 3D model and, consequently, to\npredict 3D structures of hetero-aggregates from 2D STEM images. Furthermore, an\nerror analysis is performed to evaluate the prediction power of the trained\nneural networks with respect to structural descriptors, e.g. the\nhetero-coordination number.\n", "title": "Using convolutional neural networks for stereological characterization\n  of 3D hetero-aggregates based on synthetic STEM data", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18526", "abstract_url": "http://arxiv.org/abs/2310.18526", "authors": [{"last_name": "Tsai", "first_name": "Che-Ping"}, {"last_name": "Yeh", "first_name": "Chih-Kuan"}, {"last_name": "Ravikumar", "first_name": "Pradeep"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  We propose a general class of sample based explanations of machine learning\nmodels, which we term generalized representers. To measure the effect of a\ntraining sample on a model's test prediction, generalized representers use two\ncomponents: a global sample importance that quantifies the importance of the\ntraining point to the model and is invariant to test samples, and a local\nsample importance that measures similarity between the training sample and the\ntest point with a kernel. A key contribution of the paper is to show that\ngeneralized representers are the only class of sample based explanations\nsatisfying a natural set of axiomatic properties. We discuss approaches to\nextract global importances given a kernel, and also natural choices of kernels\ngiven modern non-linear models. As we show, many popular existing sample based\nexplanations could be cast as generalized representers with particular choices\nof kernels and approaches to extract global importances. Additionally, we\nconduct empirical comparisons of different generalized representers on two\nimage and two text classification datasets.\n", "title": "Sample based Explanations via Generalized Representers", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18531", "abstract_url": "http://arxiv.org/abs/2310.18531", "authors": [{"last_name": "Weinberger", "first_name": "Ethan"}, {"last_name": "Covert", "first_name": "Ian"}, {"last_name": "Lee", "first_name": "Su-In"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Contrastive analysis (CA) refers to the exploration of variations uniquely\nenriched in a target dataset as compared to a corresponding background dataset\ngenerated from sources of variation that are irrelevant to a given task. For\nexample, a biomedical data analyst may wish to find a small set of genes to use\nas a proxy for variations in genomic data only present among patients with a\ngiven disease (target) as opposed to healthy control subjects (background).\nHowever, as of yet the problem of feature selection in the CA setting has\nreceived little attention from the machine learning community. In this work we\npresent contrastive feature selection (CFS), a method for performing feature\nselection in the CA setting. We motivate our approach with a novel\ninformation-theoretic analysis of representation learning in the CA setting,\nand we empirically validate CFS on a semi-synthetic dataset and four real-world\nbiomedical datasets. We find that our method consistently outperforms\npreviously proposed state-of-the-art supervised and fully unsupervised feature\nselection methods not designed for the CA setting. An open-source\nimplementation of our method is available at https://github.com/suinleelab/CFS.\n", "title": "Feature Selection in the Contrastive Analysis Setting", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18532", "abstract_url": "http://arxiv.org/abs/2310.18532", "authors": [{"last_name": "Mohajer", "first_name": "Mohammad Mahdi"}, {"last_name": "Aleithan", "first_name": "Reem"}, {"last_name": "Harzevili", "first_name": "Nima Shiri"}, {"last_name": "Wei", "first_name": "Moshi"}, {"last_name": "Belle", "first_name": "Alvine Boaye"}, {"last_name": "Pham", "first_name": "Hung Viet"}, {"last_name": "Wang", "first_name": "Song"}], "primary_category": "SE", "categories": ["SE"], "abstract": "  We introduce SkipAnalyzer, the first large language model (LLM)-powered\nembodied agent for static code analysis. It can detect bugs, filter false\npositive warnings, and patch the detected bugs without human intervention.\nSkipAnalyzer consists of three components, 1) an LLM-based static bug detector\nthat scans source code and reports specific types of bugs, 2) an LLM-based\nfalse-positive filter that can identify false-positive bugs in the results of\nstatic bug detectors to improve detection accuracy, and 3) an LLM-based patch\ngenerator that can generate patches for the detected bugs above. As a\nproof-of-concept, SkipAnalyzer is built on ChatGPT, which has exhibited\noutstanding performance in various software engineering tasks. To evaluate\nSkipAnalyzer, we focus on two types of typical and critical bugs that are\ntargeted by static bug detection, i.e., Null Dereference and Resource Leak as\nsubjects. We employ Infer to aid the gathering of these two bug types from 10\nopen-source projects. Consequently, our experiment dataset contains 222\ninstances of Null Dereference bugs and 46 instances of Resource Leak bugs. Our\nstudy demonstrates that SkipAnalyzer achieves remarkable performance in the\nmentioned static analysis tasks, including bug detection, false-positive\nwarning removal, and bug repair. In static bug detection, SkipAnalyzer achieves\naccuracy values of up to 68.37% for detecting Null Dereference bugs and 76.95%\nfor detecting Resource Leak bugs, outperforming the current leading bug\ndetector, Infer. For removing false-positive warnings, SkipAnalyzer can reach a\nprecision of up to 93.88% for Null Dereference bugs and 63.33% for Resource\nLeak bugs. Additionally, SkipAnalyzer surpasses state-of-the-art false-positive\nwarning removal tools. Furthermore, in bug repair, SkipAnalyzer can generate\nsyntactically correct patches to fix its detected bugs with a success rate of\nup to 97.30%.\n", "title": "SkipAnalyzer: An Embodied Agent for Code Analysis with Large Language\n  Models", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18534", "abstract_url": "http://arxiv.org/abs/2310.18534", "authors": [{"last_name": "Shaj", "first_name": "Vaisakh"}, {"last_name": "Zadeh", "first_name": "Saleh Gholam"}, {"last_name": "Demir", "first_name": "Ozan"}, {"last_name": "Douat", "first_name": "Luiz Ricardo"}, {"last_name": "Neumann", "first_name": "Gerhard"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Intelligent agents use internal world models to reason and make predictions\nabout different courses of their actions at many scales. Devising learning\nparadigms and architectures that allow machines to learn world models that\noperate at multiple levels of temporal abstractions while dealing with complex\nuncertainty predictions is a major technical hurdle. In this work, we propose a\nprobabilistic formalism to learn multi-time scale world models which we call\nthe Multi Time Scale State Space (MTS3) model. Our model uses a computationally\nefficient inference scheme on multiple time scales for highly accurate\nlong-horizon predictions and uncertainty estimates over several seconds into\nthe future. Our experiments, which focus on action conditional long horizon\nfuture predictions, show that MTS3 outperforms recent methods on several system\nidentification benchmarks including complex simulated and real-world dynamical\nsystems.\n", "title": "Multi Time Scale World Models", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18535", "abstract_url": "http://arxiv.org/abs/2310.18535", "authors": [{"last_name": "Hu", "first_name": "Yifan"}, {"last_name": "Wang", "first_name": "Jie"}, {"last_name": "Xie", "first_name": "Yao"}, {"last_name": "Krause", "first_name": "Andreas"}, {"last_name": "Kuhn", "first_name": "Daniel"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  We introduce contextual stochastic bilevel optimization (CSBO) -- a\nstochastic bilevel optimization framework with the lower-level problem\nminimizing an expectation conditioned on some contextual information and the\nupper-level decision variable. This framework extends classical stochastic\nbilevel optimization when the lower-level decision maker responds optimally not\nonly to the decision of the upper-level decision maker but also to some side\ninformation and when there are multiple or even infinite many followers. It\ncaptures important applications such as meta-learning, personalized federated\nlearning, end-to-end learning, and Wasserstein distributionally robust\noptimization with side information (WDRO-SI). Due to the presence of contextual\ninformation, existing single-loop methods for classical stochastic bilevel\noptimization are unable to converge. To overcome this challenge, we introduce\nan efficient double-loop gradient method based on the Multilevel Monte-Carlo\n(MLMC) technique and establish its sample and computational complexities. When\nspecialized to stochastic nonconvex optimization, our method matches existing\nlower bounds. For meta-learning, the complexity of our method does not depend\non the number of tasks. Numerical experiments further validate our theoretical\nresults.\n", "title": "Contextual Stochastic Bilevel Optimization", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18537", "abstract_url": "http://arxiv.org/abs/2310.18537", "authors": [{"last_name": "Sahu", "first_name": "Subhajit"}], "primary_category": "CY", "categories": ["CY", "SI", ""], "abstract": "  This research study investigates the minimization of inequality in the ranks\nof vertices obtained using the PageRank algorithm. PageRank is a widely used\nalgorithm for ranking webpages and plays a significant role in determining web\ntraffic. This study employs the Gini coefficient, a measure of income/wealth\ninequality, to assess the inequality in PageRank distributions on various types\nof graphs. The investigation involves two experiments: one that modifies\nstrategies for handling dead-end nodes and another that explores six\ndeterministic methods for reducing inequality. Our findings indicate that a\ncombination of two distinct heuristics may present an effective strategy for\nminimizing inequality.\n", "title": "Heuristics for Inequality minimization in PageRank values", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18538", "abstract_url": "http://arxiv.org/abs/2310.18538", "authors": [{"last_name": "Pourreza", "first_name": "Mohammadreza"}, {"last_name": "Rafiei", "first_name": "Davood"}], "primary_category": "CL", "categories": ["CL", "DB", "LG"], "abstract": "  Text-to-SQL benchmarks play a crucial role in evaluating the progress made in\nthe field and the ranking of different models. However, accurately matching a\nmodel-generated SQL query to a reference SQL query in a benchmark fails for\nvarious reasons, such as underspecified natural language queries, inherent\nassumptions in both model-generated and reference queries, and the\nnon-deterministic nature of SQL output under certain conditions. In this paper,\nwe conduct an extensive study of several prominent cross-domain text-to-SQL\nbenchmarks and re-evaluate some of the top-performing models within these\nbenchmarks, by both manually evaluating the SQL queries and rewriting them in\nequivalent expressions. Our evaluation reveals that attaining a perfect\nperformance on these benchmarks is unfeasible due to the multiple\ninterpretations that can be derived from the provided samples. Furthermore, we\nfind that the true performance of the models is underestimated and their\nrelative performance changes after a re-evaluation. Most notably, our\nevaluation reveals a surprising discovery: a recent GPT4-based model surpasses\nthe gold standard reference queries in the Spider benchmark in our human\nevaluation. This finding highlights the importance of interpreting benchmark\nevaluations cautiously, while also acknowledging the critical role of\nadditional independent evaluations in driving advancements in the field.\n", "title": "Evaluating Cross-Domain Text-to-SQL Models and Benchmarks", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18541", "abstract_url": "http://arxiv.org/abs/2310.18541", "authors": [{"last_name": "Chen", "first_name": "Suiyao"}, {"last_name": "Wu", "first_name": "Jing"}, {"last_name": "Hovakimyan", "first_name": "Naira"}, {"last_name": "Yao", "first_name": "Handong"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Representation learning stands as one of the critical machine learning\ntechniques across various domains. Through the acquisition of high-quality\nfeatures, pre-trained embeddings significantly reduce input space redundancy,\nbenefiting downstream pattern recognition tasks such as classification,\nregression, or detection. Nonetheless, in the domain of tabular data, feature\nengineering and selection still heavily rely on manual intervention, leading to\ntime-consuming processes and necessitating domain expertise. In response to\nthis challenge, we introduce ReConTab, a deep automatic representation learning\nframework with regularized contrastive learning. Agnostic to any type of\nmodeling task, ReConTab constructs an asymmetric autoencoder based on the same\nraw features from model inputs, producing low-dimensional representative\nembeddings. Specifically, regularization techniques are applied for raw feature\nselection. Meanwhile, ReConTab leverages contrastive learning to distill the\nmost pertinent information for downstream tasks. Experiments conducted on\nextensive real-world datasets substantiate the framework's capacity to yield\nsubstantial and robust performance improvements. Furthermore, we empirically\ndemonstrate that pre-trained embeddings can seamlessly integrate as easily\nadaptable features, enhancing the performance of various traditional methods\nsuch as XGBoost and Random Forest.\n", "title": "ReConTab: Regularized Contrastive Representation Learning for Tabular\n  Data", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18542", "abstract_url": "http://arxiv.org/abs/2310.18542", "authors": [{"last_name": "Ibrahim", "first_name": "Shibal"}, {"last_name": "Behdin", "first_name": "Kayhan"}, {"last_name": "Mazumder", "first_name": "Rahul"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Joint feature selection and tree ensemble learning is a challenging task.\nPopular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests\nsupport feature selection post-training based on feature importances, which are\nknown to be misleading, and can significantly hurt performance. We propose\nSkinny Trees: a toolkit for feature selection in tree ensembles, such that\nfeature selection and tree ensemble learning occurs simultaneously. It is based\non an end-to-end optimization approach that considers feature selection in\ndifferentiable trees with Group $\\ell_0 - \\ell_2$ regularization. We optimize\nwith a first-order proximal method and present convergence guarantees for a\nnon-convex and non-smooth objective. Interestingly, dense-to-sparse\nregularization scheduling can lead to more expressive and sparser tree\nensembles than vanilla proximal method. On 15 synthetic and real-world\ndatasets, Skinny Trees can achieve $1.5\\times$ - $620\\times$ feature\ncompression rates, leading up to $10\\times$ faster inference over dense trees,\nwithout any loss in performance. Skinny Trees lead to superior feature\nselection than many existing toolkits e.g., in terms of AUC performance for\n$25\\%$ feature budget, Skinny Trees outperforms LightGBM by $10.2\\%$ (up to\n$37.7\\%$), and Random Forests by $3\\%$ (up to $12.5\\%$).\n", "title": "End-to-end Feature Selection Approach for Learning Skinny Trees", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18544", "abstract_url": "http://arxiv.org/abs/2310.18544", "authors": [{"last_name": "Lei", "first_name": "Yuanyuan"}, {"last_name": "Huang", "first_name": "Ruihong"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Propaganda is a form of deceptive narratives that instigate or mislead the\npublic, usually with a political purpose. In this paper, we aim to identify\npropaganda in political news at two fine-grained levels: sentence-level and\ntoken-level. We observe that propaganda content is more likely to be embedded\nin sentences that attribute causality or assert contrast to nearby sentences,\nas well as seen in opinionated evaluation, speculation and discussions of\nfuture expectation. Hence, we propose to incorporate both local and global\ndiscourse structures for propaganda discovery and construct two teacher models\nfor identifying PDTB-style discourse relations between nearby sentences and\ncommon discourse roles of sentences in a news article respectively. We further\ndevise two methods to incorporate the two types of discourse structures for\npropaganda identification by either using teacher predicted probabilities as\nadditional features or soliciting guidance in a knowledge distillation\nframework. Experiments on the benchmark dataset demonstrate that leveraging\nguidance from discourse structures can significantly improve both precision and\nrecall of propaganda content identification.\n", "title": "Discourse Structures Guided Fine-grained Propaganda Identification", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18545", "abstract_url": "http://arxiv.org/abs/2310.18545", "authors": [{"last_name": "Lei", "first_name": "Yuanyuan"}, {"last_name": "Huang", "first_name": "Ruihong"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Conspiracy theories, as a type of misinformation, are narratives that\nexplains an event or situation in an irrational or malicious manner. While most\nprevious work examined conspiracy theory in social media short texts, limited\nattention was put on such misinformation in long news documents. In this paper,\nwe aim to identify whether a news article contains conspiracy theories. We\nobserve that a conspiracy story can be made up by mixing uncorrelated events\ntogether, or by presenting an unusual distribution of relations between events.\nAchieving a contextualized understanding of events in a story is essential for\ndetecting conspiracy theories. Thus, we propose to incorporate an event\nrelation graph for each article, in which events are nodes, and four common\ntypes of event relations, coreference, temporal, causal, and subevent\nrelations, are considered as edges. Then, we integrate the event relation graph\ninto conspiracy theory identification in two ways: an event-aware language\nmodel is developed to augment the basic language model with the knowledge of\nevents and event relations via soft labels; further, a heterogeneous graph\nattention network is designed to derive a graph embedding based on hard labels.\nExperiments on a large benchmark dataset show that our approach based on event\nrelation graph improves both precision and recall of conspiracy theory\nidentification, and generalizes well for new unseen media sources.\n", "title": "Identifying Conspiracy Theories News based on Event Relation Graph", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18547", "abstract_url": "http://arxiv.org/abs/2310.18547", "authors": [{"last_name": "Chen", "first_name": "Lequn"}, {"last_name": "Ye", "first_name": "Zihao"}, {"last_name": "Wu", "first_name": "Yongji"}, {"last_name": "Zhuo", "first_name": "Danyang"}, {"last_name": "Ceze", "first_name": "Luis"}, {"last_name": "Krishnamurthy", "first_name": "Arvind"}], "primary_category": "DC", "categories": ["DC", "LG"], "abstract": "  Low-rank adaptation (LoRA) has become an important and popular method to\nadapt pre-trained models to specific domains. We present Punica, a system to\nserve multiple LoRA models in a shared GPU cluster. Punica contains a new CUDA\nkernel design that allows batching of GPU operations for different LoRA models.\nThis allows a GPU to hold only a single copy of the underlying pre-trained\nmodel when serving multiple, different LoRA models, significantly enhancing GPU\nefficiency in terms of both memory and computation. Our scheduler consolidates\nmulti-tenant LoRA serving workloads in a shared GPU cluster. With a fixed-sized\nGPU cluster, our evaluations show that Punica achieves 12x higher throughput in\nserving multiple LoRA models compared to state-of-the-art LLM serving systems\nwhile only adding 2ms latency per token. Punica is open source at\nhttps://github.com/punica-ai/punica .\n", "title": "Punica: Multi-Tenant LoRA Serving", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18548", "abstract_url": "http://arxiv.org/abs/2310.18548", "authors": [{"last_name": "Reyna", "first_name": "Ana Rosal\u00eda Huam\u00e1n"}, {"last_name": "Farf\u00e1n", "first_name": "Alex Josu\u00e9 Fl\u00f3rez"}, {"last_name": "Filho", "first_name": "Geraldo Pereira Rocha"}, {"last_name": "Sampaio", "first_name": "Sandra"}, {"last_name": "de Grande", "first_name": "Robson"}, {"last_name": "Hideo", "first_name": "Luis"}, {"last_name": "Nakamura", "first_name": "Vasconcelos"}, {"last_name": "Meneguette", "first_name": "Rodolfo Ipolito"}], "primary_category": "CV", "categories": ["CV", "CY", "", ""], "abstract": "  Currently, there are computer vision systems that help us with tasks that\nwould be dull for humans, such as surveillance and vehicle tracking. An\nimportant part of this analysis is to identify traffic anomalies. An anomaly\ntells us that something unusual has happened, in this case on the highway. This\npaper aims to model vehicle tracking using computer vision to detect traffic\nanomalies on a highway. We develop the steps of detection, tracking, and\nanalysis of traffic: the detection of vehicles from video of urban traffic, the\ntracking of vehicles using a bipartite graph and the Convex Hull algorithm to\ndelimit moving areas. Finally for anomaly detection we use two data structures\nto detect the beginning and end of the anomaly. The first is the QuadTree that\ngroups vehicles that are stopped for a long time on the road and the second\nthat approaches vehicles that are occluded. Experimental results show that our\nmethod is acceptable on the Track4 test set, with an F1 score of 85.7% and a\nmean squared error of 25.432.\n", "title": "MEDAVET: Traffic Vehicle Anomaly Detection Mechanism based on spatial\n  and temporal structures in vehicle traffic", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18549", "abstract_url": "http://arxiv.org/abs/2310.18549", "authors": [{"last_name": "Gong", "first_name": "Zhiqiang"}, {"last_name": "Zhou", "first_name": "Xian"}, {"last_name": "Yao", "first_name": "Wen"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Convolutional neural networks (CNNs) have been demonstrated their powerful\nability to extract discriminative features for hyperspectral image\nclassification. However, general deep learning methods for CNNs ignore the\ninfluence of complex environmental factor which enlarges the intra-class\nvariance and decreases the inter-class variance. This multiplies the difficulty\nto extract discriminative features. To overcome this problem, this work\ndevelops a novel deep intrinsic decomposition with adversarial learning, namely\nAdverDecom, for hyperspectral image classification to mitigate the negative\nimpact of environmental factors on classification performance. First, we\ndevelop a generative network for hyperspectral image (HyperNet) to extract the\nenvironmental-related feature and category-related feature from the image.\nThen, a discriminative network is constructed to distinguish different\nenvironmental categories. Finally, a environmental and category joint learning\nloss is developed for adversarial learning to make the deep model learn\ndiscriminative features. Experiments are conducted over three commonly used\nreal-world datasets and the comparison results show the superiority of the\nproposed method. The implementation of the proposed method and other compared\nmethods could be accessed at https://github.com/shendu-sw/Adversarial Learning\nIntrinsic Decomposition for the sake of reproducibility.\n", "title": "Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral\n  Image Classification", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18550", "abstract_url": "http://arxiv.org/abs/2310.18550", "authors": [{"last_name": "Gong", "first_name": "Zhiqiang"}, {"last_name": "Zhou", "first_name": "Xian"}, {"last_name": "Yao", "first_name": "Wen"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Due to the powerful ability in capturing the global information, Transformer\nhas become an alternative architecture of CNNs for hyperspectral image\nclassification. However, general Transformer mainly considers the global\nspectral information while ignores the multiscale spatial information of the\nhyperspectral image. In this paper, we propose a multiscale spectral-spatial\nconvolutional Transformer (MultiscaleFormer) for hyperspectral image\nclassification. First, the developed method utilizes multiscale spatial patches\nas tokens to formulate the spatial Transformer and generates multiscale spatial\nrepresentation of each band in each pixel. Second, the spatial representation\nof all the bands in a given pixel are utilized as tokens to formulate the\nspectral Transformer and generate the multiscale spectral-spatial\nrepresentation of each pixel. Besides, a modified spectral-spatial CAF module\nis constructed in the MultiFormer to fuse cross-layer spectral and spatial\ninformation. Therefore, the proposed MultiFormer can capture the multiscale\nspectral-spatial information and provide better performance than most of other\narchitectures for hyperspectral image classification. Experiments are conducted\nover commonly used real-world datasets and the comparison results show the\nsuperiority of the proposed method.\n", "title": "MultiScale Spectral-Spatial Convolutional Transformer for Hyperspectral\n  Image Classification", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18552", "abstract_url": "http://arxiv.org/abs/2310.18552", "authors": [{"last_name": "Lei", "first_name": "Xiangyun"}, {"last_name": "Ye", "first_name": "Weike"}, {"last_name": "Montoya", "first_name": "Joseph"}, {"last_name": "Mueller", "first_name": "Tim"}, {"last_name": "Hung", "first_name": "Linda"}, {"last_name": "Hummelshoej", "first_name": "Jens"}], "primary_category": "", "categories": ["", "CE", "LG"], "abstract": "  This paper introduces the Chemical Environment Modeling Theory (CEMT), a\nnovel, generalized framework designed to overcome the limitations inherent in\ntraditional atom-centered Machine Learning Force Field (MLFF) models, widely\nused in atomistic simulations of chemical systems. CEMT demonstrated enhanced\nflexibility and adaptability by allowing reference points to exist anywhere\nwithin the modeled domain and thus, enabling the study of various model\narchitectures. Utilizing Gaussian Multipole (GMP) featurization functions,\nseveral models with different reference point sets, including finite difference\ngrid-centered and bond-centered models, were tested to analyze the variance in\ncapabilities intrinsic to models built on distinct reference points. The\nresults underscore the potential of non-atom-centered reference points in force\ntraining, revealing variations in prediction accuracy, inference speed and\nlearning efficiency. Finally, a unique connection between CEMT and real-space\norbital-free finite element Density Functional Theory (FE-DFT) is established,\nand the implications include the enhancement of data efficiency and robustness.\nIt allows the leveraging of spatially-resolved energy densities and charge\ndensities from FE-DFT calculations, as well as serving as a pivotal step\ntowards integrating known quantum-mechanical laws into the architecture of ML\nmodels.\n", "title": "The Role of Reference Points in Machine-Learned Atomistic Simulation\n  Models", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18553", "abstract_url": "http://arxiv.org/abs/2310.18553", "authors": [{"last_name": "Feldman", "first_name": "Dan"}, {"last_name": "Rao", "first_name": "Ashwin"}, {"last_name": "He", "first_name": "Zihao"}, {"last_name": "Lerman", "first_name": "Kristina"}], "primary_category": "SI", "categories": ["SI"], "abstract": "  Affective polarization has grown dramatically in recent years, with surveys\nshowing that liberals and conservatives not only disagree on policy issues but\nalso dislike and distrust each other. While studies have implicated social\nmedia in amplifying polarization, there is a lack of agreement on the\nmechanisms driving affective polarization and methods to measure it. Our paper\naddresses these gaps. First, we directly measure affective polarization on\nsocial media by quantifying the emotional tone of reply interactions between\nusers. As predicted by affective polarization, in-group interactions between\nsame-partisanship users tend to be positive, while out-group interactions\nbetween opposite-partisanship users are characterized by negativity and\ntoxicity. Second, we show that affective polarization generalizes beyond the\nin-group/out-group dichotomy and can be considered a structural property of\nsocial networks. Specifically, we show that emotions vary with network distance\nbetween users, with closer interactions eliciting positive emotions and more\ndistant interactions leading to anger, disgust, and toxicity. These findings\nare consistent across diverse datasets and languages, spanning discussions on\ntopics such as the Covid-19 pandemic, abortion, and the 2017 French Election.\nOur research provides new insights into the complex social dynamics of\naffective polarization in the digital age and its implications for political\ndiscourse.\n", "title": "Affective Polarization in Social Networks", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18554", "abstract_url": "http://arxiv.org/abs/2310.18554", "authors": [{"last_name": "Lee", "first_name": "Junghyun"}, {"last_name": "Yun", "first_name": "Se-Young"}, {"last_name": "Jun", "first_name": "Kwang-Sung"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Logistic bandit is a ubiquitous framework of modeling users' choices, e.g.,\nclick vs. no click for advertisement recommender system. We observe that the\nprior works overlook or neglect dependencies in $S \\geq \\lVert \\theta_\\star\n\\rVert_2$, where $\\theta_\\star \\in \\mathbb{R}^d$ is the unknown parameter\nvector, which is particularly problematic when $S$ is large, e.g., $S \\geq d$.\nIn this work, we improve the dependency on $S$ via a novel approach called {\\it\nregret-to-confidence set conversion (R2CS)}, which allows us to construct a\nconvex confidence set based on only the \\textit{existence} of an online\nlearning algorithm with a regret guarantee. Using R2CS, we obtain a strict\nimprovement in the regret bound w.r.t. $S$ in logistic bandits while retaining\ncomputational feasibility and the dependence on other factors such as $d$ and\n$T$. We apply our new confidence set to the regret analyses of logistic bandits\nwith a new martingale concentration step that circumvents an additional factor\nof $S$. We then extend this analysis to multinomial logistic bandits and obtain\nsimilar improvements in the regret, showing the efficacy of R2CS. While we\napplied R2CS to the (multinomial) logistic model, R2CS is a generic approach\nfor developing confidence sets that can be used for various models, which can\nbe of independent interest.\n", "title": "Improved Regret Bounds of (Multinomial) Logistic Bandits via\n  Regret-to-Confidence-Set Conversion", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18555", "abstract_url": "http://arxiv.org/abs/2310.18555", "authors": [{"last_name": "Tsirigotis", "first_name": "Christos"}, {"last_name": "Monteiro", "first_name": "Joao"}, {"last_name": "Rodriguez", "first_name": "Pau"}, {"last_name": "Vazquez", "first_name": "David"}, {"last_name": "Courville", "first_name": "Aaron"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Empirical risk minimization (ERM) is sensitive to spurious correlations in\nthe training data, which poses a significant risk when deploying systems\ntrained under this paradigm in high-stake applications. While the existing\nliterature focuses on maximizing group-balanced or worst-group accuracy,\nestimating these accuracies is hindered by costly bias annotations. This study\ncontends that current bias-unsupervised approaches to group robustness continue\nto rely on group information to achieve optimal performance. Firstly, these\nmethods implicitly assume that all group combinations are represented during\ntraining. To illustrate this, we introduce a systematic generalization task on\nthe MPI3D dataset and discover that current algorithms fail to improve the ERM\nbaseline when combinations of observed attribute values are missing. Secondly,\nbias labels are still crucial for effective model selection, restricting the\npracticality of these methods in real-world scenarios. To address these\nlimitations, we propose a revised methodology for training and validating\ndebiased models in an entirely bias-unsupervised manner. We achieve this by\nemploying pretrained self-supervised models to reliably extract bias\ninformation, which enables the integration of a logit adjustment training loss\nwith our validation criterion. Our empirical analysis on synthetic and\nreal-world tasks provides evidence that our approach overcomes the identified\nchallenges and consistently enhances robust accuracy, attaining performance\nwhich is competitive with or outperforms that of state-of-the-art methods,\nwhich, conversely, rely on bias labels for validation.\n", "title": "Group Robust Classification Without Any Group Information", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18562", "abstract_url": "http://arxiv.org/abs/2310.18562", "authors": [{"last_name": "Wang", "first_name": "Shuoyuan"}, {"last_name": "Wang", "first_name": "Jindong"}, {"last_name": "Xi", "first_name": "HuaJun"}, {"last_name": "Zhang", "first_name": "Bob"}, {"last_name": "Zhang", "first_name": "Lei"}, {"last_name": "Wei", "first_name": "Hongxin"}], "primary_category": "CV", "categories": ["CV", "", "LG"], "abstract": "  Human Activity Recognition (HAR) models often suffer from performance\ndegradation in real-world applications due to distribution shifts in activity\npatterns across individuals. Test-Time Adaptation (TTA) is an emerging learning\nparadigm that aims to utilize the test stream to adjust predictions in\nreal-time inference, which has not been explored in HAR before. However, the\nhigh computational cost of optimization-based TTA algorithms makes it\nintractable to run on resource-constrained edge devices. In this paper, we\npropose an Optimization-Free Test-Time Adaptation (OFTTA) framework for\nsensor-based HAR. OFTTA adjusts the feature extractor and linear classifier\nsimultaneously in an optimization-free manner. For the feature extractor, we\npropose Exponential DecayTest-time Normalization (EDTN) to replace the\nconventional batch normalization (CBN) layers. EDTN combines CBN and Test-time\nbatch Normalization (TBN) to extract reliable features against domain shifts\nwith TBN's influence decreasing exponentially in deeper layers. For the\nclassifier, we adjust the prediction by computing the distance between the\nfeature and the prototype, which is calculated by a maintained support set. In\naddition, the update of the support set is based on the pseudo label, which can\nbenefit from reliable features extracted by EDTN. Extensive experiments on\nthree public cross-person HAR datasets and two different TTA settings\ndemonstrate that OFTTA outperforms the state-of-the-art TTA approaches in both\nclassification performance and computational efficiency. Finally, we verify the\nsuperiority of our proposed OFTTA on edge devices, indicating possible\ndeployment in real applications. Our code is available at\n\\href{https://github.com/Claydon-Wang/OFTTA}{this https URL}.\n", "title": "Optimization-Free Test-Time Adaptation for Cross-Person Activity\n  Recognition", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18564", "abstract_url": "http://arxiv.org/abs/2310.18564", "authors": [{"last_name": "Sanborn", "first_name": "Sophia"}, {"last_name": "Miolane", "first_name": "Nina"}], "primary_category": "LG", "categories": ["LG", "", "CV"], "abstract": "  We introduce a general method for achieving robust group-invariance in\ngroup-equivariant convolutional neural networks ($G$-CNNs), which we call the\n$G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the\ntriple-correlation on groups, which is the unique, lowest-degree polynomial\ninvariant map that is also complete. Many commonly used invariant maps - such\nas the max - are incomplete: they remove both group and signal structure. A\ncomplete invariant, by contrast, removes only the variation due to the actions\nof the group, while preserving all information about the structure of the\nsignal. The completeness of the triple correlation endows the $G$-TC layer with\nstrong robustness, which can be observed in its resistance to invariance-based\nadversarial attacks. In addition, we observe that it yields measurable\nimprovements in classification accuracy over standard Max $G$-Pooling in\n$G$-CNN architectures. We provide a general and efficient implementation of the\nmethod for any discretized group, which requires only a table defining the\ngroup's product structure. We demonstrate the benefits of this method for\n$G$-CNNs defined on both commutative and non-commutative groups - $SO(2)$,\n$O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$,\nchiral octahedral $O$ and full octahedral $O_h$ groups) - acting on\n$\\mathbb{R}^2$ and $\\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10\ndatasets.\n", "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18565", "abstract_url": "http://arxiv.org/abs/2310.18565", "authors": [{"last_name": "Foucart", "first_name": "Simon"}], "primary_category": "", "categories": ["", ""], "abstract": "  This note is concerned with deterministic constructions of $m \\times N$\nmatrices satisfying a restricted isometry property from $\\ell_2$ to $\\ell_1$ on\n$s$-sparse vectors. Similarly to the standard ($\\ell_2$ to $\\ell_2$) restricted\nisometry property, such constructions can be found in the regime $m \\asymp\ns^2$, at least in theory. With effectiveness of implementation in mind, two\nsimple constructions are presented in the less pleasing but still relevant\nregime $m \\asymp s^4$. The first one, executing a Las Vegas strategy, is\nquasideterministic and applies in the real setting. The second one, exploiting\nGolomb rulers, is explicit and applies to the complex setting. As a stepping\nstone, an explicit isometric embedding from $\\ell_2^n(\\mathbb{C})$ to\n$\\ell_4^{cn^2}(\\mathbb{C})$ is presented. Finally, the extension of the problem\nfrom sparse vectors to low-rank matrices is raised as an open question.\n", "title": "Linearly Embedding Sparse Vectors from $\\ell_2$ to $\\ell_1$ via\n  Deterministic Dimension-Reducing Maps", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18568", "abstract_url": "http://arxiv.org/abs/2310.18568", "authors": [{"last_name": "Man", "first_name": "Yuying"}, {"last_name": "Li", "first_name": "Nian"}, {"last_name": "Xiang", "first_name": "Zejun"}, {"last_name": "Zeng", "first_name": "Xiangyong"}], "primary_category": "IT", "categories": ["IT"], "abstract": "  Boukerrou et al. (IACR Trans. Symmetric Cryptol. 2020(1), 331-362) introduced\nthe notion of Feistel Boomerang Connectivity Table (FBCT), the Feistel\ncounterpart of the Boomerang Connectivity Table (BCT), and the Feistel\nboomerang uniformity (which is the same as the second-order zero differential\nuniformity in even characteristic). FBCT is a crucial table for the analysis of\nthe resistance of block ciphers to power attacks such as differential and\nboomerang attacks. It is worth noting that the coefficients of FBCT are related\nto the second-order zero differential spectra of functions. In this paper, by\ncarrying out certain finer manipulations of solving specific equations over the\nfinite field $\\mathbb{F}_{p^n}$, we explicitly determine the second-order zero\ndifferential spectra of some power functions with low differential uniformity,\nand show that our considered functions also have low second-order zero\ndifferential uniformity. Our study pushes further former investigations on\nsecond-order zero differential uniformity and Feistel boomerang differential\nuniformity for a power function $F$.\n", "title": "On the second-order zero differential spectra of some power functions\n  over finite fields", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18569", "abstract_url": "http://arxiv.org/abs/2310.18569", "authors": [{"last_name": "Hu", "first_name": "Xiao"}, {"last_name": "Chen", "first_name": "Xiangsheng"}], "primary_category": "RO", "categories": ["RO"], "abstract": "  Grasping algorithms have evolved from planar depth grasping to utilizing\npoint cloud information, allowing for application in a wider range of\nscenarios. However, data-driven grasps based on models trained on basic\nopen-source datasets may not perform well on novel objects, which are often\nrequired in different scenarios, necessitating fine-tuning using new objects.\nThe data driving these algorithms essentially corresponds to the closing region\nof the hand in 6D pose, and due to the uniqueness of 6D pose, synthetic\nannotation or real-machine annotation methods are typically employed. Acquiring\nlarge amounts of data with real-machine annotation is challenging, making\nsynthetic annotation a common practice. However, obtaining annotated 6D pose\ndata using conventional methods is extremely time-consuming. Therefore, we\npropose a method to quickly acquire data for novel objects, enabling more\nefficient fine-tuning. Our method primarily samples grasp orientations to\ngenerate and annotate grasps. Experimental results demonstrate that our\nfine-tuning process for a new object is 400 \\% faster than other methods.\nFurthermore, we propose an optimized grasp annotation framework that accounts\nfor the effects of the gripper closing, making the annotations more reasonable.\nUpon acceptance of this paper, we will release our algorithm as open-source.\n", "title": "Enhancing Grasping Performance of Novel Objects through an Improved\n  Fine-Tuning Process", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18573", "abstract_url": "http://arxiv.org/abs/2310.18573", "authors": [{"last_name": "Nie", "first_name": "Mingcheng"}, {"last_name": "Li", "first_name": "Shuangyang"}, {"last_name": "Mishra", "first_name": "Deepak"}], "primary_category": "IT", "categories": ["IT"], "abstract": "  Orthogonal time frequency space (OTFS) has been widely acknowledged as a\npromising wireless technology for challenging transmission scenarios, including\nhigh-mobility channels. In this paper, we investigate the pilot design for the\nmulti-user OTFS system based on the a priori statistical channel state\ninformation (CSI), where the practical threshold-based estimation scheme is\nadopted. Specifically, we first derive the a posteriori Cramer-Rao bound (PCRB)\nbased on a priori channel information for each user. According to our\nderivation, the PCRB only relates to the user's pilot signal-to-noise ratio\n(SNR) and the range of delay and Doppler shifts under the practical power-delay\nand power-Doppler profiles. Then, a pilot scheme is proposed to minimize the\naverage PCRB of different users, where a closed-form global optimal pilot power\nallocation is derived. Our numerical results verify the multi-user PCRB\nanalysis. Also, we demonstrate an around 3 dB improvement in the average\nnormalized-mean-square error (NMSE) by using the proposed pilot design in\ncomparison to the conventional embedded pilot design under the same total pilot\npower.\n", "title": "Improving Channel Estimation Performance for Uplink OTFS Transmissions:\n  Pilot Design based on A Posteriori Cramer-Rao Bound", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18574", "abstract_url": "http://arxiv.org/abs/2310.18574", "authors": [{"last_name": "Liu", "first_name": "Zheyuan"}, {"last_name": "Dou", "first_name": "Guangyao"}, {"last_name": "Tian", "first_name": "Yijun"}, {"last_name": "Zhang", "first_name": "Chunhui"}, {"last_name": "Chien", "first_name": "Eli"}, {"last_name": "Zhu", "first_name": "Ziwei"}], "primary_category": "CR", "categories": ["CR", "", "LG"], "abstract": "  Machine Unlearning (MU) algorithms have become increasingly critical due to\nthe imperative adherence to data privacy regulations. The primary objective of\nMU is to erase the influence of specific data samples on a given model without\nthe need to retrain it from scratch. Accordingly, existing methods focus on\nmaximizing user privacy protection. However, there are different degrees of\nprivacy regulations for each real-world web-based application. Exploring the\nfull spectrum of trade-offs between privacy, model utility, and runtime\nefficiency is critical for practical unlearning scenarios. Furthermore,\ndesigning the MU algorithm with simple control of the aforementioned trade-off\nis desirable but challenging due to the inherent complex interaction. To\naddress the challenges, we present Controllable Machine Unlearning (ConMU), a\nnovel framework designed to facilitate the calibration of MU. The ConMU\nframework contains three integral modules: an important data selection module\nthat reconciles the runtime efficiency and model generalization, a progressive\nGaussian mechanism module that balances privacy and model generalization, and\nan unlearning proxy that controls the trade-offs between privacy and runtime\nefficiency. Comprehensive experiments on various benchmark datasets have\ndemonstrated the robust adaptability of our control mechanism and its\nsuperiority over established unlearning methods. ConMU explores the full\nspectrum of the Privacy-Utility-Efficiency trade-off and allows practitioners\nto account for different real-world regulations. Source code available at:\nhttps://github.com/guangyaodou/ConMU.\n", "title": "Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable\n  Machine Unlearning", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18577", "abstract_url": "http://arxiv.org/abs/2310.18577", "authors": [{"last_name": "Nie", "first_name": "Mingcheng"}, {"last_name": "Mishra", "first_name": "Deepak"}, {"last_name": "Al-nahari", "first_name": "Azzam"}, {"last_name": "Yuan", "first_name": "Jinhong"}, {"last_name": "Jantti", "first_name": "Riku"}], "primary_category": "IT", "categories": ["IT"], "abstract": "  This paper focuses on secure backscatter transmission in the presence of a\npassive multi-antenna eavesdropper through a symbiotic radio (SR) network.\nSpecifically, a single-antenna backscatter device (BD) aims to transmit\nconfidential information to a primary receiver (PR) by using a multi-antenna\nprimary transmitter's (PT) signal, where the received symbols are jointly\ndecoded at the PR. Our objective is to achieve confidential communications for\nBD while ensuring that the primary system's quality of service (QoS)\nrequirements are met. We propose an alternating optimisation algorithm that\nmaximises the achievable secrecy rate of BD by jointly optimising primary\ntransmit beamforming and power sharing between information and artificial noise\n(AN) signals. Numerical results verify our analytical claims on the optimality\nof the proposed solution and the proposed methodology's underlying low\ncomplexity. Additionally, our simulations provide nontrivial design insights\ninto the critical system parameters and quantify the achievable gains over the\nrelevant benchmark schemes.\n", "title": "QoS Aware Transmit Beamforming for Secure Backscattering in Symbiotic\n  Radio Systems", "date": "2023-10-27", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18581", "abstract_url": "http://arxiv.org/abs/2310.18581", "authors": [{"last_name": "Varshney", "first_name": "Neeraj"}, {"last_name": "Chatterjee", "first_name": "Agneet"}, {"last_name": "Parmar", "first_name": "Mihir"}, {"last_name": "Baral", "first_name": "Chitta"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Large Language Models (LLMs) have achieved remarkable performance across a\nwide variety of natural language tasks; however, their large size makes their\ninference slow and computationally expensive which poses a practical challenge\nfor resource constrained real-world applications. Focusing on this problem, we\npropose to instruction tune LLMs in a way that enables intermediate layer\ndecoding for efficiently generating text, but importantly without compromising\nthe quality of the generation. Specifically, we instruction tune LLMs with\nadditional explicit Losses from the InTermediate layErs (LITE) and show that it\nenables these layers to acquire 'good' generation ability without affecting the\ngeneration ability of the final layer. We perform 'dynamic confidence-based\nearly exiting' at token level from the intermediate layers which improves the\nefficiency of inference while maintaining the generation quality. We conduct\ncomprehensive experiments by instruction tuning LLaMA-2 models on the widely\nused Alpaca dataset and holistically evaluate on four different\nhuman-instruction test sets: Vicuna, WizardLM, Koala, and Self-Instruct. We\nshow that 'dynamic early exiting' achieves consistent and considerable cost\nimprovements (37.86% on average) while maintaining the generation quality of\nthe responses. We further conduct a thorough analysis of the results over\nseveral important aspects, such as comparing the semantic similarity of the\noutputs and dissecting the efficiency improvements by comparing the number of\ntokens generated in the output. In summary, our work contributes to improving\nthe efficiency of LLM inference while maintaining the generation quality, a\ncrucial step en route to enabling their widespread adoption.\n", "title": "Accelerating LLM Inference by Enabling Intermediate Layer Decoding", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18583", "abstract_url": "http://arxiv.org/abs/2310.18583", "authors": [{"last_name": "Wang", "first_name": "Hao"}, {"last_name": "Ahn", "first_name": "Euijoon"}, {"last_name": "Bi", "first_name": "Lei"}, {"last_name": "Kim", "first_name": "Jinman"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  The clinical diagnosis of skin lesion involves the analysis of dermoscopic\nand clinical modalities. Dermoscopic images provide a detailed view of the\nsurface structures whereas clinical images offer a complementary macroscopic\ninformation. The visual diagnosis of melanoma is also based on seven-point\nchecklist which involves identifying different visual attributes. Recently,\nsupervised learning approaches such as convolutional neural networks (CNNs)\nhave shown great performances using both dermoscopic and clinical modalities\n(Multi-modality). The seven different visual attributes in the checklist are\nalso used to further improve the the diagnosis. The performances of these\napproaches, however, are still reliant on the availability of large-scaled\nlabeled data. The acquisition of annotated dataset is an expensive and\ntime-consuming task, more so with annotating multi-attributes. To overcome this\nlimitation, we propose a self-supervised learning (SSL) algorithm for\nmulti-modality skin lesion classification. Our algorithm enables the\nmulti-modality learning by maximizing the similarities between paired\ndermoscopic and clinical images from different views. In addition, we generate\nsurrogate pseudo-multi-labels that represent seven attributes via clustering\nanalysis. We also propose a label-relation-aware module to refine each\npseudo-label embedding and capture the interrelationships between\npseudo-multi-labels. We validated the effectiveness of our algorithm using\nwell-benchmarked seven-point skin lesion dataset. Our results show that our\nalgorithm achieved better performances than other state-of-the-art SSL\ncounterparts.\n", "title": "Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion\n  Classification", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18585", "abstract_url": "http://arxiv.org/abs/2310.18585", "authors": [{"last_name": "Barkan", "first_name": "Oren"}, {"last_name": "Elisha", "first_name": "Yehonatan"}, {"last_name": "Asher", "first_name": "Yuval"}, {"last_name": "Eshel", "first_name": "Amit"}, {"last_name": "Koenigstein", "first_name": "Noam"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  We introduce Iterated Integrated Attributions (IIA) - a generic method for\nexplaining the predictions of vision models. IIA employs iterative integration\nacross the input image, the internal representations generated by the model,\nand their gradients, yielding precise and focused explanation maps. We\ndemonstrate the effectiveness of IIA through comprehensive evaluations across\nvarious tasks, datasets, and network architectures. Our results showcase that\nIIA produces accurate explanation maps, outperforming other state-of-the-art\nexplanation techniques.\n", "title": "Visual Explanations via Iterated Integrated Attributions", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18586", "abstract_url": "http://arxiv.org/abs/2310.18586", "authors": [{"last_name": "Oh", "first_name": "Jung Hun"}, {"last_name": "Elkin", "first_name": "Rena"}, {"last_name": "Simhal", "first_name": "Anish Kumar"}, {"last_name": "Zhu", "first_name": "Jiening"}, {"last_name": "Deasy", "first_name": "Joseph O"}, {"last_name": "Tannenbaum", "first_name": "Allen"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  The Wasserstein distance from optimal mass transport (OMT) is a powerful\nmathematical tool with numerous applications that provides a natural measure of\nthe distance between two probability distributions. Several methods to\nincorporate OMT into widely used probabilistic models, such as Gaussian or\nGaussian mixture, have been developed to enhance the capability of modeling\ncomplex multimodal densities of real datasets. However, very few studies have\nexplored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein\nthe kernel trick is utilized to avoid the need to explicitly map input data\ninto a high-dimensional feature space. In the current study, we propose a\nWasserstein-type metric to compute the distance between two Gaussian mixtures\nin a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.\n", "title": "Optimal Transport for Kernel Gaussian Mixture Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18587", "abstract_url": "http://arxiv.org/abs/2310.18587", "authors": [{"last_name": "Yang", "first_name": "Guang"}, {"last_name": "Zhou", "first_name": "Yu"}, {"last_name": "Zhang", "first_name": "Xiangyu"}, {"last_name": "Chen", "first_name": "Xiang"}, {"last_name": "Han", "first_name": "Tingting"}, {"last_name": "Chen", "first_name": "Taolue"}], "primary_category": "SE", "categories": ["SE"], "abstract": "  Context: Pre-trained models (PTMs) have demonstrated significant potential in\nautomatic code translation. However, the vulnerability of these models in\ntranslation tasks, particularly in terms of syntax, has not been extensively\ninvestigated. Objective: To fill this gap, our study aims to propose a novel\napproach CoTR to assess and improve the syntactic adversarial robustness of\nPTMs in code translation. Method: CoTR consists of two components: CoTR-A and\nCoTR-D. CoTR-A generates adversarial examples by transforming programs, while\nCoTR-D proposes a semantic distance-based sampling data augmentation method and\nadversarial training method to improve the model's robustness and\ngeneralization capabilities. The Pass@1 metric is used by CoTR to assess the\nperformance of PTMs, which is more suitable for code translation tasks and\noffers a more precise evaluation in real world scenarios. Results: The\neffectiveness of CoTR is evaluated through experiments on real world Java to\nPython datasets. The results demonstrate that CoTR-A can significantly reduce\nthe performance of existing PTMs, while CoTR-D effectively improves the\nrobustness of PTMs. Conclusion: Our study identifies the limitations of current\nPTMs, including large language models, in code translation tasks. It highlights\nthe potential of CoTR as an effective solution to enhance the robustness of\nPTMs for code translation tasks.\n", "title": "Assessing and Improving Syntactic Adversarial Robustness of Pre-trained\n  Models for Code Translation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18589", "abstract_url": "http://arxiv.org/abs/2310.18589", "authors": [{"last_name": "Ma", "first_name": "Chiyu"}, {"last_name": "Zhao", "first_name": "Brandon"}, {"last_name": "Chen", "first_name": "Chaofan"}, {"last_name": "Rudin", "first_name": "Cynthia"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  We present ProtoConcepts, a method for interpretable image classification\ncombining deep learning and case-based reasoning using prototypical parts.\nExisting work in prototype-based image classification uses a ``this looks like\nthat'' reasoning process, which dissects a test image by finding prototypical\nparts and combining evidence from these prototypes to make a final\nclassification. However, all of the existing prototypical part-based image\nclassifiers provide only one-to-one comparisons, where a single training image\npatch serves as a prototype to compare with a part of our test image. With\nthese single-image comparisons, it can often be difficult to identify the\nunderlying concept being compared (e.g., ``is it comparing the color or the\nshape?''). Our proposed method modifies the architecture of prototype-based\nnetworks to instead learn prototypical concepts which are visualized using\nmultiple image patches. Having multiple visualizations of the same prototype\nallows us to more easily identify the concept captured by that prototype (e.g.,\n``the test image and the related training patches are all the same shade of\nblue''), and allows our model to create richer, more interpretable visual\nexplanations. Our experiments show that our ``this looks like those'' reasoning\nprocess can be applied as a modification to a wide range of existing\nprototypical image classification networks while achieving comparable accuracy\non benchmark datasets.\n", "title": "This Looks Like Those: Illuminating Prototypical Concepts Using Multiple\n  Visualizations", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18590", "abstract_url": "http://arxiv.org/abs/2310.18590", "authors": [{"last_name": "Tiwari", "first_name": "Rishabh"}, {"last_name": "Sivasubramanian", "first_name": "Durga"}, {"last_name": "Mekala", "first_name": "Anmol"}, {"last_name": "Ramakrishnan", "first_name": "Ganesh"}, {"last_name": "Shenoy", "first_name": "Pradeep"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Deep networks tend to learn spurious feature-label correlations in real-world\nsupervised learning tasks. This vulnerability is aggravated in distillation,\nwhere a student model may have lesser representational capacity than the\ncorresponding teacher model. Often, knowledge of specific spurious correlations\nis used to reweight instances & rebalance the learning process. We propose a\nnovel early readout mechanism whereby we attempt to predict the label using\nrepresentations from earlier network layers. We show that these early readouts\nautomatically identify problem instances or groups in the form of confident,\nincorrect predictions. Leveraging these signals to modulate the distillation\nloss on an instance level allows us to substantially improve not only group\nfairness measures across benchmark datasets, but also overall accuracy of the\nstudent model. We also provide secondary analyses that bring insight into the\nrole of feature learning in supervision and distillation.\n", "title": "Using Early Readouts to Mediate Featural Bias in Distillation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18591", "abstract_url": "http://arxiv.org/abs/2310.18591", "authors": [{"last_name": "Jarrett", "first_name": "Daniel"}, {"last_name": "H\u00fcy\u00fck", "first_name": "Alihan"}, {"last_name": "van der Schaar", "first_name": "Mihaela"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Decision analysis deals with modeling and enhancing decision processes. A\nprincipal challenge in improving behavior is in obtaining a transparent\ndescription of existing behavior in the first place. In this paper, we develop\nan expressive, unifying perspective on inverse decision modeling: a framework\nfor learning parameterized representations of sequential decision behavior.\nFirst, we formalize the forward problem (as a normative standard), subsuming\ncommon classes of control behavior. Second, we use this to formalize the\ninverse problem (as a descriptive model), generalizing existing work on\nimitation/reward learning -- while opening up a much broader class of research\nproblems in behavior representation. Finally, we instantiate this approach with\nan example (inverse bounded rational control), illustrating how this structure\nenables learning (interpretable) representations of (bounded) rationality --\nwhile naturally capturing intuitive notions of suboptimal actions, biased\nbeliefs, and imperfect knowledge of environments.\n", "title": "Inverse Decision Modeling: Learning Interpretable Representations of\n  Behavior", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18593", "abstract_url": "http://arxiv.org/abs/2310.18593", "authors": [{"last_name": "Lee", "first_name": "Junghyun"}, {"last_name": "Cho", "first_name": "Hanseul"}, {"last_name": "Yun", "first_name": "Se-Young"}, {"last_name": "Yun", "first_name": "Chulhee"}], "primary_category": "", "categories": ["", "CY", "LG"], "abstract": "  Fair Principal Component Analysis (PCA) is a problem setting where we aim to\nperform PCA while making the resulting representation fair in that the\nprojected distributions, conditional on the sensitive attributes, match one\nanother. However, existing approaches to fair PCA have two main problems:\ntheoretically, there has been no statistical foundation of fair PCA in terms of\nlearnability; practically, limited memory prevents us from using existing\napproaches, as they explicitly rely on full access to the entire data. On the\ntheoretical side, we rigorously formulate fair PCA using a new notion called\n\\emph{probably approximately fair and optimal} (PAFO) learnability. On the\npractical side, motivated by recent advances in streaming algorithms for\naddressing memory limitation, we propose a new setting called \\emph{fair\nstreaming PCA} along with a memory-efficient algorithm, fair noisy power method\n(FNPM). We then provide its {\\it statistical} guarantee in terms of\nPAFO-learnability, which is the first of its kind in fair PCA literature.\nLastly, we verify the efficacy and memory efficiency of our algorithm on\nreal-world datasets.\n", "title": "Fair Streaming Principal Component Analysis: Statistical and Algorithmic\n  Viewpoint", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18596", "abstract_url": "http://arxiv.org/abs/2310.18596", "authors": [{"last_name": "Li", "first_name": "Chao"}, {"last_name": "Palanisamy", "first_name": "Balaji"}, {"last_name": "Xu", "first_name": "Runhua"}, {"last_name": "Duan", "first_name": "Li"}, {"last_name": "Liu", "first_name": "Jiqiang"}, {"last_name": "Wang", "first_name": "Wei"}], "primary_category": "CR", "categories": ["CR", "SI"], "abstract": "  Delegated-Proof-of-Stake (DPoS) blockchains, such as EOSIO, Steem and TRON,\nare governed by a committee of block producers elected via a coin-based voting\nsystem. We recently witnessed the first de facto blockchain takeover that\nhappened between Steem and TRON. Within one hour of this incident, TRON founder\ntook over the entire Steem committee, forcing the original Steem community to\nleave the blockchain that they maintained for years. This is a historical event\nin the evolution of blockchains and Web 3.0. Despite its significant disruptive\nimpact, little is known about how vulnerable DPoS blockchains are in general to\ntakeovers and the ways in which we can improve their resistance to takeovers.\n  In this paper, we demonstrate that the resistance of a DPoS blockchain to\ntakeovers is governed by both the theoretical design and the actual use of its\nunderlying coin-based voting governance system. When voters actively cooperate\nto resist potential takeovers, our theoretical analysis reveals that the\ncurrent active resistance of DPoS blockchains is far below the theoretical\nupper bound. However in practice, voter preferences could be significantly\ndifferent. This paper presents the first large-scale empirical study of the\npassive takeover resistance of EOSIO, Steem and TRON. Our study identifies the\ndiversity in voter preferences and characterizes the impact of this diversity\non takeover resistance. Through both theoretical and empirical analyses, our\nstudy provides novel insights into the security of coin-based voting governance\nand suggests potential ways to improve the takeover resistance of any\nblockchain that implements this governance model.\n", "title": "How Hard is Takeover in DPoS Blockchains? Understanding the Security of\n  Coin-based Voting Governance", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18598", "abstract_url": "http://arxiv.org/abs/2310.18598", "authors": [{"last_name": "Nguyen", "first_name": "Toan"}, {"last_name": "Do", "first_name": "Kien"}, {"last_name": "Duong", "first_name": "Bao"}, {"last_name": "Nguyen", "first_name": "Thin"}], "primary_category": "LG", "categories": ["LG", "CV"], "abstract": "  We propose a novel approach for domain generalisation (DG) leveraging risk\ndistributions to characterise domains, thereby achieving domain invariance. In\nour findings, risk distributions effectively highlight differences between\ntraining domains and reveal their inherent complexities. In testing, we may\nobserve similar, or potentially intensifying in magnitude, divergences between\nrisk distributions. Hence, we propose a compelling proposition: Minimising the\ndivergences between risk distributions across training domains leads to robust\ninvariance for DG. The key rationale behind this concept is that a model,\ntrained on domain-invariant or stable features, may consistently produce\nsimilar risk distributions across various domains. Building upon this idea, we\npropose Risk Distribution Matching (RDM). Using the maximum mean discrepancy\n(MMD) distance, RDM aims to minimise the variance of risk distributions across\ntraining domains. However, when the number of domains increases, the direct\noptimisation of variance leads to linear growth in MMD computations, resulting\nin inefficiency. Instead, we propose an approximation that requires only one\nMMD computation, by aligning just two distributions: that of the worst-case\ndomain and the aggregated distribution from all domains. Notably, this method\nempirically outperforms optimising distributional variance while being\ncomputationally more efficient. Unlike conventional DG matching algorithms, RDM\nstands out for its enhanced efficacy by concentrating on scalar risk\ndistributions, sidestepping the pitfalls of high-dimensional challenges seen in\nfeature or gradient matching. Our extensive experiments on standard benchmark\ndatasets demonstrate that RDM shows superior generalisation capability over\nstate-of-the-art DG methods.\n", "title": "Domain Generalisation via Risk Distribution Matching", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18600", "abstract_url": "http://arxiv.org/abs/2310.18600", "authors": [{"last_name": "Datta", "first_name": "Debtanu"}, {"last_name": "Soni", "first_name": "Shubham"}, {"last_name": "Mukherjee", "first_name": "Rajdeep"}, {"last_name": "Ghosh", "first_name": "Saptarshi"}], "primary_category": "CL", "categories": ["CL", ""], "abstract": "  Automatic summarization of legal case judgments is a practically important\nproblem that has attracted substantial research efforts in many countries. In\nthe context of the Indian judiciary, there is an additional complexity --\nIndian legal case judgments are mostly written in complex English, but a\nsignificant portion of India's population lacks command of the English\nlanguage. Hence, it is crucial to summarize the legal documents in Indian\nlanguages to ensure equitable access to justice. While prior research primarily\nfocuses on summarizing legal case judgments in their source languages, this\nstudy presents a pioneering effort toward cross-lingual summarization of\nEnglish legal documents into Hindi, the most frequently spoken Indian language.\nWe construct the first high-quality legal corpus comprising of 3,122 case\njudgments from prominent Indian courts in English, along with their summaries\nin both English and Hindi, drafted by legal practitioners. We benchmark the\nperformance of several diverse summarization approaches on our corpus and\ndemonstrate the need for further research in cross-lingual summarization in the\nlegal domain.\n", "title": "MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of\n  Indian Legal Case Judgments", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18601", "abstract_url": "http://arxiv.org/abs/2310.18601", "authors": [{"last_name": "Jarrett", "first_name": "Daniel"}, {"last_name": "H\u00fcy\u00fck", "first_name": "Alihan"}, {"last_name": "van der Schaar", "first_name": "Mihaela"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Consider learning a decision support assistant to serve as an intermediary\nbetween (oracle) expert behavior and (imperfect) human behavior: At each time,\nthe algorithm observes an action chosen by a fallible agent, and decides\nwhether to *accept* that agent's decision, *intervene* with an alternative, or\n*request* the expert's opinion. For instance, in clinical diagnosis,\nfully-autonomous machine behavior is often beyond ethical affordances, thus\nreal-world decision support is often limited to monitoring and forecasting.\nInstead, such an intermediary would strike a prudent balance between the former\n(purely prescriptive) and latter (purely descriptive) approaches, while\nproviding an efficient interface between human mistakes and expert feedback. In\nthis work, we first formalize the sequential problem of *online decision\nmediation* -- that is, of simultaneously learning and evaluating mediator\npolicies from scratch with *abstentive feedback*: In each round, deferring to\nthe oracle obviates the risk of error, but incurs an upfront penalty, and\nreveals the otherwise hidden expert action as a new training data point.\nSecond, we motivate and propose a solution that seeks to trade off (immediate)\nloss terms against (future) improvements in generalization error; in doing so,\nwe identify why conventional bandit algorithms may fail. Finally, through\nexperiments and sensitivities on a variety of datasets, we illustrate\nconsistent gains over applicable benchmarks on performance measures with\nrespect to the mediator policy, the learned model, and the decision-making\nsystem as a whole.\n", "title": "Online Decision Mediation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18602", "abstract_url": "http://arxiv.org/abs/2310.18602", "authors": [{"last_name": "Wu", "first_name": "Hai"}, {"last_name": "Chen", "first_name": "Xu"}, {"last_name": "Huang", "first_name": "Kaibin"}], "primary_category": "NI", "categories": ["NI", "IT"], "abstract": "  Foundation models (FoMos), referring to large-scale AI models, possess\nhuman-like capabilities and are able to perform competitively in the domain of\nhuman intelligence. The breakthrough in FoMos has inspired researchers to\ndeploy such models in the sixth-generation (6G) mobile networks for automating\na broad range of tasks in next-generation mobile applications. While the sizes\nof FoMos are reaching their peaks, their next phase is expected to focus on\nfine-tuning the models to specific downstream tasks. This inspires us to\npropose the vision of FoMo fine-tuning as a 6G service. Its key feature is the\nexploitation of existing parameter-efficient fine-tuning (PEFT) techniques to\ntweak only a small fraction of model weights for a FoMo to become customized\nfor a specific task. To materialize the said vision, we survey the\nstate-of-the-art PEFT and then present a novel device-edge fine-tuning (DEFT)\nframework for providing efficient and privacy-preserving fine-tuning services\nat the 6G network edge. The framework consists of the following comprehensive\nset of techniques: 1) Control of fine-tuning parameter sizes in different\ntransformer blocks of a FoMo; 2) Over-the-air computation for realizing neural\nconnections in DEFT; 3) Federated DEFT in a multi-device system by downloading\na FoMo emulator or gradients; 4) On-the-fly prompt-ensemble tuning; 5)\nDevice-to-device prompt transfer among devices. Experiments are conducted using\npre-trained FoMos with up to 11 billion parameters to demonstrate the\neffectiveness of DEFT techniques. The article is concluded by presenting future\nresearch opportunities.\n", "title": "Device-Edge Cooperative Fine-Tuning of Foundation Models as a 6G Service", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18603", "abstract_url": "http://arxiv.org/abs/2310.18603", "authors": [{"last_name": "You", "first_name": "Wencong"}, {"last_name": "Hammoudeh", "first_name": "Zayd"}, {"last_name": "Lowd", "first_name": "Daniel"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Backdoor attacks manipulate model predictions by inserting innocuous triggers\ninto training and test data. We focus on more realistic and more challenging\nclean-label attacks where the adversarial training examples are correctly\nlabeled. Our attack, LLMBkd, leverages language models to automatically insert\ndiverse style-based triggers into texts. We also propose a poison selection\ntechnique to improve the effectiveness of both LLMBkd as well as existing\ntextual backdoor attacks. Lastly, we describe REACT, a baseline defense to\nmitigate backdoor attacks via antidote training examples. Our evaluations\ndemonstrate LLMBkd's effectiveness and efficiency, where we consistently\nachieve high attack success rates across a wide range of styles with little\neffort and no model training.\n", "title": "Large Language Models Are Better Adversaries: Exploring Generative\n  Clean-Label Backdoor Attacks Against Text Classifiers", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18604", "abstract_url": "http://arxiv.org/abs/2310.18604", "authors": [{"last_name": "Lu", "first_name": "Chonggang"}, {"last_name": "Zhang", "first_name": "Richong"}, {"last_name": "Sun", "first_name": "Kai"}, {"last_name": "Kim", "first_name": "Jaein"}, {"last_name": "Zhang", "first_name": "Cunwang"}, {"last_name": "Mao", "first_name": "Yongyi"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Document-level relation extraction (DocRE) involves identifying relations\nbetween entities distributed in multiple sentences within a document. Existing\nmethods focus on building a heterogeneous document graph to model the internal\nstructure of an entity and the external interaction between entities. However,\nthere are two drawbacks in existing methods. On one hand, anaphor plays an\nimportant role in reasoning to identify relations between entities but is\nignored by these methods. On the other hand, these methods achieve\ncross-sentence entity interactions implicitly by utilizing a document or\nsentences as intermediate nodes. Such an approach has difficulties in learning\nfine-grained interactions between entities across different sentences,\nresulting in sub-optimal performance. To address these issues, we propose an\nAnaphor-Assisted (AA) framework for DocRE tasks. Experimental results on the\nwidely-used datasets demonstrate that our model achieves a new state-of-the-art\nperformance.\n", "title": "Anaphor Assisted Document-Level Relation Extraction", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18605", "abstract_url": "http://arxiv.org/abs/2310.18605", "authors": [{"last_name": "Geng", "first_name": "Zhengyang"}, {"last_name": "Kolter", "first_name": "J. Zico"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Deep Equilibrium (DEQ) Models, an emerging class of implicit models that maps\ninputs to fixed points of neural networks, are of growing interest in the deep\nlearning community. However, training and applying DEQ models is currently done\nin an ad-hoc fashion, with various techniques spread across the literature. In\nthis work, we systematically revisit DEQs and present TorchDEQ, an\nout-of-the-box PyTorch-based library that allows users to define, train, and\ninfer using DEQs over multiple domains with minimal code and best practices.\nUsing TorchDEQ, we build a ``DEQ Zoo'' that supports six published implicit\nmodels across different domains. By developing a joint framework that\nincorporates the best practices across all models, we have substantially\nimproved the performance, training stability, and efficiency of DEQs on ten\ndatasets across all six projects in the DEQ Zoo. TorchDEQ and DEQ Zoo are\nreleased as \\href{https://github.com/locuslab/torchdeq}{open source}.\n", "title": "TorchDEQ: A Library for Deep Equilibrium Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18606", "abstract_url": "http://arxiv.org/abs/2310.18606", "authors": [{"last_name": "Cai", "first_name": "Kunlin"}, {"last_name": "Zhang", "first_name": "Jinghuai"}, {"last_name": "Shand", "first_name": "Will"}, {"last_name": "Hong", "first_name": "Zhiqing"}, {"last_name": "Wang", "first_name": "Guang"}, {"last_name": "Zhang", "first_name": "Desheng"}, {"last_name": "Chi", "first_name": "Jianfeng"}, {"last_name": "Tian", "first_name": "Yuan"}], "primary_category": "LG", "categories": ["LG", "CR"], "abstract": "  As location-based services (LBS) have grown in popularity, the collection of\nhuman mobility data has become increasingly extensive to build machine learning\n(ML) models offering enhanced convenience to LBS users. However, the\nconvenience comes with the risk of privacy leakage since this type of data\nmight contain sensitive information related to user identities, such as\nhome/work locations. Prior work focuses on protecting mobility data privacy\nduring transmission or prior to release, lacking the privacy risk evaluation of\nmobility data-based ML models. To better understand and quantify the privacy\nleakage in mobility data-based ML models, we design a privacy attack suite\ncontaining data extraction and membership inference attacks tailored for\npoint-of-interest (POI) recommendation models, one of the most widely used\nmobility data-based ML models. These attacks in our attack suite assume\ndifferent adversary knowledge and aim to extract different types of sensitive\ninformation from mobility data, providing a holistic privacy risk assessment\nfor POI recommendation models. Our experimental evaluation using two real-world\nmobility datasets demonstrates that current POI recommendation models are\nvulnerable to our attacks. We also present unique findings to understand what\ntypes of mobility data are more susceptible to privacy attacks. Finally, we\nevaluate defenses against these attacks and highlight future directions and\nchallenges.\n", "title": "Where have you been? A Study of Privacy Risk for Point-of-Interest\n  Recommendation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18608", "abstract_url": "http://arxiv.org/abs/2310.18608", "authors": [{"last_name": "Zhao", "first_name": "Xiangyu"}, {"last_name": "Wang", "first_name": "Maolin"}, {"last_name": "Zhao", "first_name": "Xinjian"}, {"last_name": "Li", "first_name": "Jiansheng"}, {"last_name": "Zhou", "first_name": "Shucheng"}, {"last_name": "Yin", "first_name": "Dawei"}, {"last_name": "Li", "first_name": "Qing"}, {"last_name": "Tang", "first_name": "Jiliang"}, {"last_name": "Guo", "first_name": "Ruocheng"}], "primary_category": "IR", "categories": ["IR", ""], "abstract": "  Recommender systems have become an essential component of many online\nplatforms, providing personalized recommendations to users. A crucial aspect is\nembedding techniques that coverts the high-dimensional discrete features, such\nas user and item IDs, into low-dimensional continuous vectors and can enhance\nthe recommendation performance. Applying embedding techniques captures complex\nentity relationships and has spurred substantial research. In this survey, we\nprovide an overview of the recent literature on embedding techniques in\nrecommender systems. This survey covers embedding methods like collaborative\nfiltering, self-supervised learning, and graph-based techniques. Collaborative\nfiltering generates embeddings capturing user-item preferences, excelling in\nsparse data. Self-supervised methods leverage contrastive or generative\nlearning for various tasks. Graph-based techniques like node2vec exploit\ncomplex relationships in network-rich environments. Addressing the scalability\nchallenges inherent to embedding methods, our survey delves into innovative\ndirections within the field of recommendation systems. These directions aim to\nenhance performance and reduce computational complexity, paving the way for\nimproved recommender systems. Among these innovative approaches, we will\nintroduce Auto Machine Learning (AutoML), hash techniques, and quantization\ntechniques in this survey. We discuss various architectures and techniques and\nhighlight the challenges and future directions in these aspects. This survey\naims to provide a comprehensive overview of the state-of-the-art in this\nrapidly evolving field and serve as a useful resource for researchers and\npractitioners working in the area of recommender systems.\n", "title": "Embedding in Recommender Systems: A Survey", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18609", "abstract_url": "http://arxiv.org/abs/2310.18609", "authors": [{"last_name": "Zang", "first_name": "Ying"}, {"last_name": "Fu", "first_name": "Chenglong"}, {"last_name": "Chen", "first_name": "Tianrun"}, {"last_name": "Hu", "first_name": "Yuanqi"}, {"last_name": "Liu", "first_name": "Qingshan"}, {"last_name": "Hu", "first_name": "Wenjun"}], "primary_category": "MM", "categories": ["MM"], "abstract": "  As 3D models become critical in today's manufacturing and product design,\nconventional 3D modeling approaches based on Computer-Aided Design (CAD) are\nlabor-intensive, time-consuming, and have high demands on the creators. This\nwork aims to introduce an alternative approach to 3D modeling by utilizing\nfree-hand sketches to obtain desired 3D models. We introduce Deep3DSketch+,\nwhich is a deep-learning algorithm that takes the input of a single free-hand\nsketch and produces a complete and high-fidelity model that matches the sketch\ninput. The neural network has view- and structural-awareness enabled by a Shape\nDiscriminator (SD) and a Stroke Enhancement Module (SEM), which overcomes the\nlimitations of sparsity and ambiguity of the sketches. The network design also\nbrings high robustness to partial sketch input in industrial applications.Our\napproach has undergone extensive experiments, demonstrating its\nstate-of-the-art (SOTA) performance on both synthetic and real-world datasets.\nThese results validate the effectiveness and superiority of our method compared\nto existing techniques. We have demonstrated the conversion of free-hand\nsketches into physical 3D objects using additive manufacturing. We believe that\nour approach has the potential to accelerate product design and democratize\ncustomized manufacturing.\n", "title": "Deep3DSketch+: Obtaining Customized 3D Model by Single Free-Hand Sketch\n  through Deep Learning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18612", "abstract_url": "http://arxiv.org/abs/2310.18612", "authors": [{"last_name": "Qadeer", "first_name": "Saad"}, {"last_name": "Engel", "first_name": "Andrew"}, {"last_name": "Tsou", "first_name": "Adam"}, {"last_name": "Vargas", "first_name": "Max"}, {"last_name": "Stinis", "first_name": "Panos"}, {"last_name": "Chiang", "first_name": "Tony"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Despite their immense promise in performing a variety of learning tasks, a\ntheoretical understanding of the effectiveness and limitations of Deep Neural\nNetworks (DNNs) has so far eluded practitioners. This is partly due to the\ninability to determine the closed forms of the learned functions, making it\nharder to assess their precise dependence on the training data and to study\ntheir generalization properties on unseen datasets. Recent work has shown that\nrandomly initialized DNNs in the infinite width limit converge to kernel\nmachines relying on a Neural Tangent Kernel (NTK) with known closed form. These\nresults suggest, and experimental evidence corroborates, that empirical kernel\nmachines can also act as surrogates for finite width DNNs. The high\ncomputational cost of assembling the full NTK, however, makes this approach\ninfeasible in practice, motivating the need for low-cost approximations. In the\ncurrent work, we study the performance of the Conjugate Kernel (CK), an\nefficient approximation to the NTK that has been observed to yield fairly\nsimilar results. For the regression problem of smooth functions and\nclassification using logistic regression, we show that the CK performance is\nonly marginally worse than that of the NTK and, in certain cases, is shown to\nbe superior. In particular, we establish bounds for the relative test losses,\nverify them with numerical tests, and identify the regularity of the kernel as\nthe key determinant of performance. In addition to providing a theoretical\ngrounding for using CKs instead of NTKs, our framework provides insights into\nunderstanding the robustness of the various approximants and suggests a recipe\nfor improving DNN accuracy inexpensively. We present a demonstration of this on\nthe foundation model GPT-2 by comparing its performance on a classification\ntask using a conventional approach and our prescription.\n", "title": "Efficient kernel surrogates for neural network-based regression", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18614", "abstract_url": "http://arxiv.org/abs/2310.18614", "authors": [{"last_name": "Wang", "first_name": "Jiatai"}, {"last_name": "Xu", "first_name": "Zhiwei"}, {"last_name": "Yang", "first_name": "Xuewen"}, {"last_name": "Wang", "first_name": "Xin"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Multi-view clustering (MVC) can explore common semantics from unsupervised\nviews generated by different sources, and thus has been extensively used in\napplications of practical computer vision. Due to the spatio-temporal\nasynchronism, multi-view data often suffer from view missing and are unaligned\nin real-world applications, which makes it difficult to learn consistent\nrepresentations. To address the above issues, this work proposes a deep MVC\nframework where data recovery and alignment are fused in a hierarchically\nconsistent way to maximize the mutual information among different views and\nensure the consistency of their latent spaces. More specifically, we first\nleverage dual prediction to fill in missing views while achieving the\ninstance-level alignment, and then take the contrastive reconstruction to\nachieve the class-level alignment. To the best of our knowledge, this could be\nthe first successful attempt to handle the missing and unaligned data problem\nseparately with different learning paradigms. Extensive experiments on public\ndatasets demonstrate that our method significantly outperforms state-of-the-art\nmethods on multi-view clustering even in the cases of view missing and\nunalignment.\n", "title": "Hierarchical Mutual Information Analysis: Towards Multi-view Clustering\n  in The Wild", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18615", "abstract_url": "http://arxiv.org/abs/2310.18615", "authors": [{"last_name": "Song", "first_name": "Xiangchen"}, {"last_name": "Yao", "first_name": "Weiran"}, {"last_name": "Fan", "first_name": "Yewen"}, {"last_name": "Dong", "first_name": "Xinshuai"}, {"last_name": "Chen", "first_name": "Guangyi"}, {"last_name": "Niebles", "first_name": "Juan Carlos"}, {"last_name": "Xing", "first_name": "Eric"}, {"last_name": "Zhang", "first_name": "Kun"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  In unsupervised causal representation learning for sequential data with\ntime-delayed latent causal influences, strong identifiability results for the\ndisentanglement of causally-related latent variables have been established in\nstationary settings by leveraging temporal structure. However, in nonstationary\nsetting, existing work only partially addressed the problem by either utilizing\nobserved auxiliary variables (e.g., class labels and/or domain indexes) as side\ninformation or assuming simplified latent causal dynamics. Both constrain the\nmethod to a limited range of scenarios. In this study, we further explored the\nMarkov Assumption under time-delayed causally related process in nonstationary\nsetting and showed that under mild conditions, the independent latent\ncomponents can be recovered from their nonlinear mixture up to a permutation\nand a component-wise transformation, without the observation of auxiliary\nvariables. We then introduce NCTRL, a principled estimation framework, to\nreconstruct time-delayed latent causal variables and identify their relations\nfrom measured sequential data only. Empirical evaluations demonstrated the\nreliable identification of time-delayed latent causal influences, with our\nmethodology substantially outperforming existing baselines that fail to exploit\nthe nonstationarity adequately and then, consequently, cannot distinguish\ndistribution shifts.\n", "title": "Temporally Disentangled Representation Learning under Unknown\n  Nonstationarity", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18617", "abstract_url": "http://arxiv.org/abs/2310.18617", "authors": [{"last_name": "Alizadeh", "first_name": "Shima"}, {"last_name": "Bhargava", "first_name": "Aniruddha"}, {"last_name": "Gopalswamy", "first_name": "Karthick"}, {"last_name": "Jain", "first_name": "Lalit"}, {"last_name": "Kveton", "first_name": "Branislav"}, {"last_name": "Liu", "first_name": "Ge"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Multi-objective optimization is a type of decision making problems where\nmultiple conflicting objectives are optimized. We study offline optimization of\nmulti-objective policies from data collected by an existing policy. We propose\na pessimistic estimator for the multi-objective policy values that can be\neasily plugged into existing formulas for hypervolume computation and\noptimized. The estimator is based on inverse propensity scores (IPS), and\nimproves upon a naive IPS estimator in both theory and experiments. Our\nanalysis is general, and applies beyond our IPS estimators and methods for\noptimizing them. The pessimistic estimator can be optimized by policy gradients\nand performs well in all of our experiments.\n", "title": "Pessimistic Off-Policy Multi-Objective Optimization", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18618", "abstract_url": "http://arxiv.org/abs/2310.18618", "authors": [{"last_name": "Li", "first_name": "Haibo"}], "primary_category": "", "categories": ["", ""], "abstract": "  The Bayesian statistical framework provides a systematic approach to enhance\nthe regularization model by incorporating prior information about the desired\nsolution. For the Bayesian linear inverse problems with Gaussian noise and\nGaussian prior, we propose a new iterative regularization algorithm that\nbelongs to subspace projection regularization (SPR) methods. By treating the\nforward model matrix as a linear operator between the two underlying finite\ndimensional Hilbert spaces with new introduced inner products, we first\nintroduce an iterative process that can generate a series of valid solution\nsubspaces. The SPR method then projects the original problem onto these\nsolution subspaces to get a series of low dimensional linear least squares\nproblems, where an efficient procedure is developed to update the solutions of\nthem to approximate the desired solution of the original problem. With the new\ndesigned early stopping rules, this iterative algorithm can obtain a\nregularized solution with a satisfied accuracy. Several theoretical results\nabout the algorithm are established to reveal the regularization properties of\nit. We use both small-scale and large-scale inverse problems to test the\nproposed algorithm and demonstrate its robustness and efficiency. The most\ncomputationally intensive operations in the proposed algorithm only involve\nmatrix-vector products, making it highly efficient for large-scale problems.\n", "title": "Subspace projection regularization for large-scale Bayesian linear\n  inverse problems", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18619", "abstract_url": "http://arxiv.org/abs/2310.18619", "authors": [{"last_name": "Xu", "first_name": "Nan"}, {"last_name": "Wang", "first_name": "Fei"}, {"last_name": "Dong", "first_name": "Mingtao"}, {"last_name": "Chen", "first_name": "Muhao"}], "primary_category": "CL", "categories": ["CL", "", "IR", "LG"], "abstract": "  Many discriminative natural language understanding (NLU) tasks have large\nlabel spaces. Learning such a process of large-space decision making is\nparticularly challenging due to the lack of training instances per label and\nthe difficulty of selection among many fine-grained labels. Inspired by dense\nretrieval methods for passage finding in open-domain QA, we propose a\nreformulation of large-space discriminative NLU tasks as a learning-to-retrieve\ntask, leading to a novel solution named Dense Decision Retrieval (DDR ).\nInstead of predicting fine-grained decisions as logits, DDR adopts a\ndual-encoder architecture that learns to predict by retrieving from a decision\nthesaurus. This approach not only leverages rich indirect supervision signals\nfrom easy-to-consume learning resources for dense retrieval, it also leads to\nenhanced prediction generalizability with a semantically meaningful\nrepresentation of the large decision space. When evaluated on tasks with\ndecision spaces ranging from hundreds to hundred-thousand scales, DDR\noutperforms strong baselines greatly by 27.54% in P@1 on two extreme\nmulti-label classification tasks, 1.17% in F1 score ultra-fine entity typing,\nand 1.26% in accuracy on three few-shot intent classification tasks on average.\nCode and resources are available at https://github.com/luka-group/DDR\n", "title": "Dense Retrieval as Indirect Supervision for Large-space Decision Making", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18620", "abstract_url": "http://arxiv.org/abs/2310.18620", "authors": [{"last_name": "Zhang", "first_name": "Weijia"}, {"last_name": "Liu", "first_name": "Dongnan"}, {"last_name": "Ma", "first_name": "Chao"}, {"last_name": "Cai", "first_name": "Weidong"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Monocular 3D object detection (M3OD) is a significant yet inherently\nchallenging task in autonomous driving due to absence of implicit depth cues in\na single RGB image. In this paper, we strive to boost currently underperforming\nmonocular 3D object detectors by leveraging an abundance of unlabelled data via\nsemi-supervised learning. Our proposed ODM3D framework entails cross-modal\nknowledge distillation at various levels to inject LiDAR-domain knowledge into\na monocular detector during training. By identifying foreground sparsity as the\nmain culprit behind existing methods' suboptimal training, we exploit the\nprecise localisation information embedded in LiDAR points to enable more\nforeground-attentive and efficient distillation via the proposed BEV occupancy\nguidance mask, leading to notably improved knowledge transfer and M3OD\nperformance. Besides, motivated by insights into why existing cross-modal\nGT-sampling techniques fail on our task at hand, we further design a novel\ncross-modal object-wise data augmentation strategy for effective RGB-LiDAR\njoint learning. Our method ranks 1st in both KITTI validation and test\nbenchmarks, significantly surpassing all existing monocular methods, supervised\nor semi-supervised, on both BEV and 3D detection metrics.\n", "title": "ODM3D: Alleviating Foreground Sparsity for Enhanced Semi-Supervised\n  Monocular 3D Object Detection", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18622", "abstract_url": "http://arxiv.org/abs/2310.18622", "authors": [{"last_name": "Zhang", "first_name": "Yulun"}, {"last_name": "Fontaine", "first_name": "Matthew C."}, {"last_name": "Bhatt", "first_name": "Varun"}, {"last_name": "Nikolaidis", "first_name": "Stefanos"}, {"last_name": "Li", "first_name": "Jiaoyang"}], "primary_category": "RO", "categories": ["RO", "", "MA", "NE"], "abstract": "  We study the problem of generating arbitrarily large environments to improve\nthe throughput of multi-robot systems. Prior work proposes Quality Diversity\n(QD) algorithms as an effective method for optimizing the environments of\nautomated warehouses. However, these approaches optimize only relatively small\nenvironments, falling short when it comes to replicating real-world warehouse\nsizes. The challenge arises from the exponential increase in the search space\nas the environment size increases. Additionally, the previous methods have only\nbeen tested with up to 350 robots in simulations, while practical warehouses\ncould host thousands of robots. In this paper, instead of optimizing\nenvironments, we propose to optimize Neural Cellular Automata (NCA) environment\ngenerators via QD algorithms. We train a collection of NCA generators with QD\nalgorithms in small environments and then generate arbitrarily large\nenvironments from the generators at test time. We show that NCA environment\ngenerators maintain consistent, regularized patterns regardless of environment\nsize, significantly enhancing the scalability of multi-robot systems in two\ndifferent domains with up to 2,350 robots. Additionally, we demonstrate that\nour method scales a single-agent reinforcement learning policy to arbitrarily\nlarge environments with similar patterns. We include the source code at\n\\url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.\n", "title": "Arbitrarily Scalable Environment Generators via Neural Cellular Automata", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18625", "abstract_url": "http://arxiv.org/abs/2310.18625", "authors": [{"last_name": "Watanabe", "first_name": "Yuto"}, {"last_name": "Sakurama", "first_name": "Kazunori"}], "primary_category": "", "categories": ["", ""], "abstract": "  In this study, we explore distributed optimization problems with clique-wise\ncoupling through the lens of operator splitting. This framework of clique-wise\ncoupling extends beyond conventional pairwise coupled problems, encompassing\nconsensus optimization and formation control, and is applicable to a wide array\nof examples. We first introduce a matrix, called the clique-wise duplication\n(CD) matrix, which enables decoupled reformulations for operator splitting\nmethods and distributed computation. Leveraging this matrix, we propose a new\ndistributed optimization algorithm via Davis-Yin splitting (DYS), a versatile\nthree-operator splitting method. We then delve into the properties of this\nmethod and demonstrate how existing consensus optimization methods (NIDS, Exact\nDiffusion, and Diffusion) can be derived from our proposed method. Furthermore,\nbeing inspired by this observation, we derive a Diffusion-like method, the\nclique-based projected gradient descent (CPGD), and present Nesterov's\nacceleration and in-depth convergence analysis for various step sizes. The\npaper concludes with numerical examples that underscore the efficacy of our\nproposed method.\n", "title": "Distributed Optimization of Clique-Wise Coupled Problems via\n  Three-Operator Splitting", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18626", "abstract_url": "http://arxiv.org/abs/2310.18626", "authors": [{"last_name": "Sarkar", "first_name": "Soumyendu"}, {"last_name": "Babu", "first_name": "Ashwin Ramesh"}, {"last_name": "Mousavi", "first_name": "Sajad"}, {"last_name": "Carmichael", "first_name": "Zachariah"}, {"last_name": "Gundecha", "first_name": "Vineet"}, {"last_name": "Ghorbanpour", "first_name": "Sahand"}, {"last_name": "Luna", "first_name": "Ricardo"}, {"last_name": "Guillen", "first_name": "Gutierrez Antonio"}, {"last_name": "Naug", "first_name": "Avisek"}], "primary_category": "CV", "categories": ["CV", "", "LG"], "abstract": "  We present a novel framework for generating adversarial benchmarks to\nevaluate the robustness of image classification models. Our framework allows\nusers to customize the types of distortions to be optimally applied to images,\nwhich helps address the specific distortions relevant to their deployment. The\nbenchmark can generate datasets at various distortion levels to assess the\nrobustness of different image classifiers. Our results show that the\nadversarial samples generated by our framework with any of the image\nclassification models, like ResNet-50, Inception-V3, and VGG-16, are effective\nand transferable to other models causing them to fail. These failures happen\neven when these models are adversarially retrained using state-of-the-art\ntechniques, demonstrating the generalizability of our adversarial samples. We\nachieve competitive performance in terms of net $L_2$ distortion compared to\nstate-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we\ndemonstrate our framework achieves such results with simple distortions like\nGaussian noise without introducing unnatural artifacts or color bleeds. This is\nmade possible by a model-based reinforcement learning (RL) agent and a\ntechnique that reduces a deep tree search of the image for model sensitivity to\nperturbations, to a one-level analysis and action. The flexibility of choosing\ndistortions and setting classification probability thresholds for multiple\nclasses makes our framework suitable for algorithmic audits.\n", "title": "Benchmark Generation Framework with Customizable Distortions for Image\n  Classifier Robustness", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18628", "abstract_url": "http://arxiv.org/abs/2310.18628", "authors": [{"last_name": "Chen", "first_name": "Hailin"}, {"last_name": "Saha", "first_name": "Amrita"}, {"last_name": "Hoi", "first_name": "Steven"}, {"last_name": "Joty", "first_name": "Shafiq"}], "primary_category": "CL", "categories": ["CL", "LG"], "abstract": "  With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are\nincreasing interests in distilling the capabilies of close-sourced LLMs to\nsmaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT\nto generate a set of instructions and answers, for the student model to learn.\nHowever, such standard distillation approach neglects the merits and conditions\nof the student model. Inspired by modern teaching principles, we design a\npersonalised distillation process, in which the student attempts to solve a\ntask first, then the teacher provides an adaptive refinement for the student to\nimprove. Instead of feeding the student with teacher's prior, personalised\ndistillation enables personalised learning for the student model, as it only\nlearns on examples it makes mistakes upon and learns to improve its own\nsolution. On code generation, personalised distillation consistently\noutperforms standard distillation with only one third of the data. With only\n2.5-3K personalised examples that incur a data-collection cost of 4-6$, we\nboost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to\nachieve 45.8% pass@1 on HumanEval.\n", "title": "Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive\n  Learning for Code Generation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18629", "abstract_url": "http://arxiv.org/abs/2310.18629", "authors": [{"last_name": "Liao", "first_name": "Wenlong"}, {"last_name": "Port\u00e9-Agel", "first_name": "Fernando"}, {"last_name": "Fang", "first_name": "Jiannong"}, {"last_name": "Bak-Jensen", "first_name": "Birgitte"}, {"last_name": "Ruan", "first_name": "Guangchun"}, {"last_name": "Yang", "first_name": "Zhe"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Machine learning models (e.g., neural networks) achieve high accuracy in wind\npower forecasting, but they are usually regarded as black boxes that lack\ninterpretability. To address this issue, the paper proposes a glass-box\napproach that combines exceptional accuracy with transparency for wind power\nforecasting. Specifically, advanced artificial intelligence methods (e.g.,\ngradient boosting) are innovatively employed to create shape functions within\nthe forecasting model. These functions effectively map the intricate non-linear\nrelationships between wind power output and input features. Furthermore, the\nforecasting model is enriched by incorporating interaction terms that adeptly\ncapture interdependencies and synergies among the input features. Simulation\nresults show that the proposed glass-box approach effectively interprets the\nresults of wind power forecasting from both global and instance perspectives.\nBesides, it outperforms most benchmark models and exhibits comparable\nperformance to the best-performing neural networks. This dual strength of\ntransparency and high accuracy positions the proposed glass-box approach as a\ncompelling choice for reliable wind power forecasting.\n", "title": "Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach\n  with Exceptional Accuracy", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18630", "abstract_url": "http://arxiv.org/abs/2310.18630", "authors": [{"last_name": "Chen", "first_name": "Xu"}, {"last_name": "He", "first_name": "XinXin"}, {"last_name": "Feng", "first_name": "Zhiyong"}, {"last_name": "Wei", "first_name": "Zhiqing"}, {"last_name": "Zhang", "first_name": "Qixun"}, {"last_name": "Yuan", "first_name": "Xin"}, {"last_name": "Zhang", "first_name": "Ping"}], "primary_category": "IT", "categories": ["IT", ""], "abstract": "  In this paper, we propose a joint single-base localization and communication\nenhancement scheme for the uplink (UL) integrated sensing and communications\n(ISAC) system with asynchronism, which can achieve accurate single-base\nlocalization of user equipment (UE) and significantly improve the communication\nreliability despite the existence of timing offset (TO) due to the clock\nasynchronism between UE and base station (BS). Our proposed scheme integrates\nthe CSI enhancement into the multiple signal classification (MUSIC)-based AoA\nestimation and thus imposes no extra complexity on the ISAC system. We further\nexploit a MUSIC-based range estimation method and prove that it can suppress\nthe time-varying TO-related phase terms. Exploiting the AoA and range\nestimation of UE, we can estimate the location of UE. Finally, we propose a\njoint CSI and data signals-based localization scheme that can coherently\nexploit the data and the CSI signals to improve the AoA and range estimation,\nwhich further enhances the single-base localization of UE. The extensive\nsimulation results show that the enhanced CSI can achieve equivalent bit error\nrate performance to the minimum mean square error (MMSE) CSI estimator. The\nproposed joint CSI and data signals-based localization scheme can achieve\ndecimeter-level localization accuracy despite the existing clock asynchronism\nand improve the localization mean square error (MSE) by about 8 dB compared\nwith the maximum likelihood (ML)-based benchmark method.\n", "title": "Joint Localization and Communication Enhancement in Uplink Integrated\n  Sensing and Communications System with Clock Asynchronism", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18633", "abstract_url": "http://arxiv.org/abs/2310.18633", "authors": [{"last_name": "Tang", "first_name": "Ruixiang"}, {"last_name": "Yuan", "first_name": "Jiayi"}, {"last_name": "Li", "first_name": "Yiming"}, {"last_name": "Liu", "first_name": "Zirui"}, {"last_name": "Chen", "first_name": "Rui"}, {"last_name": "Hu", "first_name": "Xia"}], "primary_category": "LG", "categories": ["LG", "", "CL"], "abstract": "  In the field of natural language processing, the prevalent approach involves\nfine-tuning pretrained language models (PLMs) using local samples. Recent\nresearch has exposed the susceptibility of PLMs to backdoor attacks, wherein\nthe adversaries can embed malicious prediction behaviors by manipulating a few\ntraining samples. In this study, our objective is to develop a\nbackdoor-resistant tuning procedure that yields a backdoor-free model, no\nmatter whether the fine-tuning dataset contains poisoned samples. To this end,\nwe propose and integrate a honeypot module into the original PLM, specifically\ndesigned to absorb backdoor information exclusively. Our design is motivated by\nthe observation that lower-layer representations in PLMs carry sufficient\nbackdoor features while carrying minimal information about the original tasks.\nConsequently, we can impose penalties on the information acquired by the\nhoneypot module to inhibit backdoor creation during the fine-tuning process of\nthe stem network. Comprehensive experiments conducted on benchmark datasets\nsubstantiate the effectiveness and robustness of our defensive strategy.\nNotably, these results indicate a substantial reduction in the attack success\nrate ranging from 10\\% to 40\\% when compared to prior state-of-the-art methods.\n", "title": "Setting the Trap: Capturing and Defeating Backdoors in Pretrained\n  Language Models through Honeypots", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18634", "abstract_url": "http://arxiv.org/abs/2310.18634", "authors": [{"last_name": "Chen", "first_name": "Hang"}, {"last_name": "Yang", "first_name": "Xinyu"}, {"last_name": "Du", "first_name": "Keqing"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  The cross-pollination of deep learning and causal discovery has catalyzed a\nburgeoning field of research seeking to elucidate causal relationships within\nnon-statistical data forms like images, videos, and text. Such data, often\nbeing named `indefinite data', exhibit unique challenges-inconsistency between\ncausal structure and representation, which are not common in conventional data\nforms. To tackle this issue, we theoretically develop intervention strategies\nsuitable for indefinite data and derive causal consistency condition (CCC).\nMoreover, we design a self-supervised learning (SSL) framework that considers\ninterventions as `views' and CCC as a `philosophy' with two implement examples\non Supervised Specialized Models (SSMs) and Large Language Models (LLMs),\nrespectively. To evaluate pure inconsistency manifestations, we have prepared\nthe first high-quality causal dialogue dataset-Causalogue. Evaluations are also\nperformed on three other downstream tasks. Extensive experimentation has\nsubstantiated the efficacy of our methodology, illuminating how CCC could\npotentially play an influential role in various fields.\n", "title": "SSL Framework for Causal Inconsistency between Structures and\n  Representations", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18635", "abstract_url": "http://arxiv.org/abs/2310.18635", "authors": [{"last_name": "Gu", "first_name": "Shuxian"}, {"last_name": "Dai", "first_name": "Yemo"}, {"last_name": "Feng", "first_name": "Zezheng"}, {"last_name": "Wang", "first_name": "Yong"}, {"last_name": "Zeng", "first_name": "Haipeng"}], "primary_category": "HC", "categories": ["HC"], "abstract": "  Taxi drivers often take much time to navigate the streets to look for\npassengers, which leads to high vacancy rates and wasted resources. Empty taxi\ncruising remains a big concern for taxi companies. Analyzing the pick-up point\nselection behavior can solve this problem effectively, providing suggestions\nfor taxi management and dispatch. Many studies have been devoted to analyzing\nand recommending hot-spot regions of pick-up points, which can make it easier\nfor drivers to pick up passengers. However, the selection of pick-up points is\ncomplex and affected by multiple factors, such as convenience and traffic\nmanagement. Most existing approaches cannot produce satisfactory results in\nreal-world applications because of the changing travel demands and the lack of\ninterpretability. In this paper, we introduce a visual analytics system,\nT-PickSeer, for taxi company analysts to better explore and understand the\npick-up point selection behavior of passengers. We explore massive taxi GPS\ndata and employ an overview-to-detail approach to enable effective analysis of\npick-up point selection. Our system provides coordinated views to compare\ndifferent regularities and characteristics in different regions. Also, our\nsystem assists in identifying potential pick-up points and checking the\nperformance of each pick-up point. Three case studies based on a real-world\ndataset and interviews with experts have demonstrated the effectiveness of our\nsystem.\n", "title": "T-PickSeer: Visual Analysis of Taxi Pick-up Point Selection Behavior", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18636", "abstract_url": "http://arxiv.org/abs/2310.18636", "authors": [{"last_name": "Tanyu", "first_name": "Derick Nganyu"}, {"last_name": "Ning", "first_name": "Jianfeng"}, {"last_name": "Hauptmann", "first_name": "Andreas"}, {"last_name": "Jin", "first_name": "Bangti"}, {"last_name": "Maass", "first_name": "Peter"}], "primary_category": "LG", "categories": ["LG", "", "CE", "CV", ""], "abstract": "  Electrical Impedance Tomography (EIT) is a powerful imaging technique with\ndiverse applications, e.g., medical diagnosis, industrial monitoring, and\nenvironmental studies. The EIT inverse problem is about inferring the internal\nconductivity distribution of an object from measurements taken on its boundary.\nIt is severely ill-posed, necessitating advanced computational methods for\naccurate image reconstructions. Recent years have witnessed significant\nprogress, driven by innovations in analytic-based approaches and deep learning.\nThis review explores techniques for solving the EIT inverse problem, focusing\non the interplay between contemporary deep learning-based strategies and\nclassical analytic-based methods. Four state-of-the-art deep learning\nalgorithms are rigorously examined, harnessing the representational\ncapabilities of deep neural networks to reconstruct intricate conductivity\ndistributions. In parallel, two analytic-based methods, rooted in mathematical\nformulations and regularisation techniques, are dissected for their strengths\nand limitations. These methodologies are evaluated through various numerical\nexperiments, encompassing diverse scenarios that reflect real-world\ncomplexities. A suite of performance metrics is employed to assess the efficacy\nof these methods. These metrics collectively provide a nuanced understanding of\nthe methods' ability to capture essential features and delineate complex\nconductivity patterns. One novel feature of the study is the incorporation of\nvariable conductivity scenarios, introducing a level of heterogeneity that\nmimics textured inclusions. This departure from uniform conductivity\nassumptions mimics realistic scenarios where tissues or materials exhibit\nspatially varying electrical properties. Exploring how each method responds to\nsuch variable conductivity scenarios opens avenues for understanding their\nrobustness and adaptability.\n", "title": "Electrical Impedance Tomography: A Fair Comparative Study on Deep\n  Learning and Analytic-based Approaches", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18639", "abstract_url": "http://arxiv.org/abs/2310.18639", "authors": [{"last_name": "Sun", "first_name": "Wenju"}, {"last_name": "Li", "first_name": "Qingyong"}, {"last_name": "Wang", "first_name": "Wen"}, {"last_name": "Geng", "first_name": "Yangli-ao"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  The dilemma between plasticity and stability presents a significant challenge\nin Incremental Learning (IL), especially in the exemplar-free scenario where\naccessing old-task samples is strictly prohibited during the learning of a new\ntask. A straightforward solution to this issue is learning and storing an\nindependent model for each task, known as Single Task Learning (STL). Despite\nthe linear growth in model storage with the number of tasks in STL, we\nempirically discover that averaging these model parameters can potentially\npreserve knowledge across all tasks. Inspired by this observation, we propose a\nDual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA\nemploys a dual-learner design: a plastic learner focused on acquiring new-task\nknowledge and a stable learner responsible for accumulating all learned\nknowledge. The knowledge from the plastic learner is transferred to the stable\nlearner via cumulative parameter averaging. Additionally, several task-specific\nclassifiers work in cooperation with the stable learner to yield the final\nprediction. Specifically, when learning a new task, these modules are updated\nin a cyclic manner: i) the plastic learner is initially optimized using a\nself-supervised loss besides the supervised loss to enhance the feature\nextraction robustness; ii) the stable learner is then updated with respect to\nthe plastic learner in a cumulative parameter averaging manner to maintain its\ntask-wise generalization; iii) the task-specific classifier is accordingly\noptimized to align with the stable learner. Experimental results on CIFAR-100\nand Tiny-ImageNet show that DLCPA outperforms several state-of-the-art\nexemplar-free baselines in both Task-IL and Class-IL settings.\n", "title": "Towards Plastic and Stable Exemplar-Free Incremental Learning: A\n  Dual-Learner Framework with Cumulative Parameter Averaging", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18640", "abstract_url": "http://arxiv.org/abs/2310.18640", "authors": [{"last_name": "Na", "first_name": "Jaemin"}, {"last_name": "Ha", "first_name": "Jung-Woo"}, {"last_name": "Chang", "first_name": "Hyung Jin"}, {"last_name": "Han", "first_name": "Dongyoon"}, {"last_name": "Hwang", "first_name": "Wonjun"}], "primary_category": "CV", "categories": ["CV", "LG"], "abstract": "  The teacher-student framework, prevalent in semi-supervised semantic\nsegmentation, mainly employs the exponential moving average (EMA) to update a\nsingle teacher's weights based on the student's. However, EMA updates raise a\nproblem in that the weights of the teacher and student are getting coupled,\ncausing a potential performance bottleneck. Furthermore, this problem may\nbecome more severe when training with more complicated labels such as\nsegmentation masks but with few annotated data. This paper introduces Dual\nTeacher, a simple yet effective approach that employs dual temporary teachers\naiming to alleviate the coupling problem for the student. The temporary\nteachers work in shifts and are progressively improved, so consistently prevent\nthe teacher and student from becoming excessively close. Specifically, the\ntemporary teachers periodically take turns generating pseudo-labels to train a\nstudent model and maintain the distinct characteristics of the student model\nfor each epoch. Consequently, Dual Teacher achieves competitive performance on\nthe PASCAL VOC, Cityscapes, and ADE20K benchmarks with remarkably shorter\ntraining times than state-of-the-art methods. Moreover, we demonstrate that our\napproach is model-agnostic and compatible with both CNN- and Transformer-based\nmodels. Code is available at \\url{https://github.com/naver-ai/dual-teacher}.\n", "title": "Switching Temporary Teachers for Semi-Supervised Semantic Segmentation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18642", "abstract_url": "http://arxiv.org/abs/2310.18642", "authors": [{"last_name": "Anand", "first_name": "Deepa"}, {"last_name": "M", "first_name": "Gurunath Reddy"}, {"last_name": "Singhal", "first_name": "Vanika"}, {"last_name": "Shanbhag", "first_name": "Dattesh D."}, {"last_name": "KS", "first_name": "Shriram"}, {"last_name": "Patil", "first_name": "Uday"}, {"last_name": "Bhushan", "first_name": "Chitresh"}, {"last_name": "Manickam", "first_name": "Kavitha"}, {"last_name": "Gui", "first_name": "Dawei"}, {"last_name": "Mullick", "first_name": "Rakesh"}, {"last_name": "Gopal", "first_name": "Avinash"}, {"last_name": "Bhatia", "first_name": "Parminder"}, {"last_name": "Kass-Hout", "first_name": "Taha"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Recent advances in Vision Transformers (ViT) and Stable Diffusion (SD) models\nwith their ability to capture rich semantic features of the image have been\nused for image correspondence tasks on natural images. In this paper, we\nexamine the ability of a variety of pre-trained ViT (DINO, DINOv2, SAM, CLIP)\nand SD models, trained exclusively on natural images, for solving the\ncorrespondence problems on medical images. While many works have made a case\nfor in-domain training, we show that the models trained on natural images can\noffer good performance on medical images across different modalities\n(CT,MR,Ultrasound) sourced from various manufacturers, over multiple anatomical\nregions (brain, thorax, abdomen, extremities), and on wide variety of tasks.\nFurther, we leverage the correspondence with respect to a template image to\nprompt a Segment Anything (SAM) model to arrive at single shot segmentation,\nachieving dice range of 62%-90% across tasks, using just one image as\nreference. We also show that our single-shot method outperforms the recently\nproposed few-shot segmentation method - UniverSeg (Dice range 47%-80%) on most\nof the semantic segmentation tasks(six out of seven) across medical imaging\nmodalities.\n", "title": "One-shot Localization and Segmentation of Medical Images with Foundation\n  Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18646", "abstract_url": "http://arxiv.org/abs/2310.18646", "authors": [{"last_name": "Tran", "first_name": "Nhat-Quang"}, {"last_name": "Felipe", "first_name": "Anna"}, {"last_name": "Ngoc", "first_name": "Thanh Nguyen"}, {"last_name": "Huynh", "first_name": "Tom"}, {"last_name": "Tran", "first_name": "Quang"}, {"last_name": "Tang", "first_name": "Arthur"}, {"last_name": "Nguyen", "first_name": "Thuy"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Agricultural price prediction is crucial for farmers, policymakers, and other\nstakeholders in the agricultural sector. However, it is a challenging task due\nto the complex and dynamic nature of agricultural markets. Machine learning\nalgorithms have the potential to revolutionize agricultural price prediction by\nimproving accuracy, real-time prediction, customization, and integration. This\npaper reviews recent research on machine learning algorithms for agricultural\nprice prediction. We discuss the importance of agriculture in developing\ncountries and the problems associated with crop price falls. We then identify\nthe challenges of predicting agricultural prices and highlight how machine\nlearning algorithms can support better prediction. Next, we present a\ncomprehensive analysis of recent research, discussing the strengths and\nweaknesses of various machine learning techniques. We conclude that machine\nlearning has the potential to revolutionize agricultural price prediction, but\nfurther research is essential to address the limitations and challenges\nassociated with this approach.\n", "title": "Predicting Agricultural Commodities Prices with Machine Learning: A\n  Review of Current Research", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18647", "abstract_url": "http://arxiv.org/abs/2310.18647", "authors": [{"last_name": "Lic\u0103", "first_name": "Mircea-Tudor"}, {"last_name": "Dinucu-Jianu", "first_name": "David"}], "primary_category": "", "categories": [""], "abstract": "  This paper aims to explore the separation of the two forward passes in the\nForward-Forward algorithm from a biological perspective in the context of\nsleep. We show the size of the gap between the sleep and awake phase influences\nthe learning capabilities of the algorithm and highlight the importance of\nnegative data in diminishing the devastating effects of sleep deprivation.\n", "title": "Sleep Deprivation in the Forward-Forward Algorithm", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18648", "abstract_url": "http://arxiv.org/abs/2310.18648", "authors": [{"last_name": "Nguyen-Duc", "first_name": "Anh"}, {"last_name": "Cabrero-Daniel", "first_name": "Beatriz"}, {"last_name": "Przybylek", "first_name": "Adam"}, {"last_name": "Arora", "first_name": "Chetan"}, {"last_name": "Khanna", "first_name": "Dron"}, {"last_name": "Herda", "first_name": "Tomas"}, {"last_name": "Rafiq", "first_name": "Usman"}, {"last_name": "Melegati", "first_name": "Jorge"}, {"last_name": "Guerra", "first_name": "Eduardo"}, {"last_name": "Kemell", "first_name": "Kai-Kristian"}, {"last_name": "Saari", "first_name": "Mika"}, {"last_name": "Zhang", "first_name": "Zheying"}, {"last_name": "Le", "first_name": "Huy"}, {"last_name": "Quan", "first_name": "Tho"}, {"last_name": "Abrahamsson", "first_name": "Pekka"}], "primary_category": "SE", "categories": ["SE"], "abstract": "  Generative Artificial Intelligence (GenAI) tools have become increasingly\nprevalent in software development, offering assistance to various managerial\nand technical project activities. Notable examples of these tools include\nOpenAIs ChatGPT, GitHub Copilot, and Amazon CodeWhisperer. Although many recent\npublications have explored and evaluated the application of GenAI, a\ncomprehensive understanding of the current development, applications,\nlimitations, and open challenges remains unclear to many. Particularly, we do\nnot have an overall picture of the current state of GenAI technology in\npractical software engineering usage scenarios. We conducted a literature\nreview and focus groups for a duration of five months to develop a research\nagenda on GenAI for Software Engineering. We identified 78 open Research\nQuestions (RQs) in 11 areas of Software Engineering. Our results show that it\nis possible to explore the adoption of GenAI in partial automation and support\ndecision-making in all software development activities. While the current\nliterature is skewed toward software implementation, quality assurance and\nsoftware maintenance, other areas, such as requirements engineering, software\ndesign, and software engineering education, would need further research\nattention. Common considerations when implementing GenAI include industry-level\nassessment, dependability and accuracy, data accessibility, transparency, and\nsustainability aspects associated with the technology. GenAI is bringing\nsignificant changes to the field of software engineering. Nevertheless, the\nstate of research on the topic still remains immature. We believe that this\nresearch agenda holds significance and practical value for informing both\nresearchers and practitioners about current applications and guiding future\nresearch.\n", "title": "Generative Artificial Intelligence for Software Engineering -- A\n  Research Agenda", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18650", "abstract_url": "http://arxiv.org/abs/2310.18650", "authors": [{"last_name": "Soltani", "first_name": "Marzieh"}, {"last_name": "Atashi", "first_name": "Arash"}], "primary_category": "", "categories": [""], "abstract": "  In order to increase energy efficiency in buildings, optimizing the\nparameters of the facade form can be challenging due to the dynamic nature of\nsolar radiation. One effective solution is the use of kinetic facades as a\nsecond skin, which can control energy consumption. This study proposes a\nparametric kinetic facade to increase building energy efficiency, along with a\nframework to optimize its form using the Bang-Big Crunch (BB-BC) optimization\nalgorithm. The study involved modeling a two-story office building in Shiraz\ncity and calculating the energy consumption resulting from building operation\nover a three-day period without considering the second skin of the facade. In\nthe second stage of the study, the second skin was optimized for the same\nthree-day interval and calculated as a parametric, static facade. In the last\nstep, the parameters of the second skin were optimized for three one-day\nintervals, assuming the possibility of kinematic changes each day. The total\nenergy consumption of building operation for the three days was then calculated\nand analyzed.The Python programming language was used to develop the\noptimization algorithm, while Rhino software, and Grasshopper, Ladybug, and\nHoneybee plugins were used for building modeling and simulation of light,\nenergy, and weather parameters.The results of the study demonstrate the\neffectiveness of the proposed kinetic facade and the proper performance of the\nproposed algorithm for solving similar problems. The study found that the use\nof the second skin with kinetic function reduced energy consumption by 28%.\nAdditionally, the results from the second and third stages of the study showed\nthat the use of the second facade shell with kinematic function, compared to\nits function in static mode, reduced energy consumption by 4%.Overall...\n", "title": "Designing a Kinetic Fa\\c{c}ade Using BB-BC Algorithm with a Focus on\n  Enhancing Building Energy Efficiency", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18651", "abstract_url": "http://arxiv.org/abs/2310.18651", "authors": [{"last_name": "Javidani", "first_name": "Ali"}, {"last_name": "Sadeghi", "first_name": "Mohammad Amin"}, {"last_name": "Araabi", "first_name": "Babak Nadjar"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Self-supervised representation learning methods mainly focus on image-level\ninstance discrimination. This study explores the potential benefits of\nincorporating patch-level discrimination into existing methods to enhance the\nquality of learned representations by simultaneously looking at local and\nglobal visual features. Towards this idea, we present a straightforward yet\neffective patch-matching algorithm that can find the corresponding patches\nacross the augmented views of an image. The augmented views are subsequently\nfed into a self-supervised learning framework employing Vision Transformer\n(ViT) as its backbone. The result is the generation of both image-level and\npatch-level representations. Leveraging the proposed patch-matching algorithm,\nthe model minimizes the representation distance between not only the CLS tokens\nbut also the corresponding patches. As a result, the model gains a more\ncomprehensive understanding of both the entirety of the image as well as its\nfiner details. We pretrain the proposed method on small, medium, and\nlarge-scale datasets. It is shown that our approach could outperform\nstate-of-the-art image-level representation learning methods on both image\nclassification and downstream tasks. Keywords: Self-Supervised Learning; Visual\nRepresentations; Local-Global Representation Learning; Patch-Wise\nRepresentation Learning; Vision Transformer (ViT)\n", "title": "Local-Global Self-Supervised Visual Representation Learning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18652", "abstract_url": "http://arxiv.org/abs/2310.18652", "authors": [{"last_name": "Bae", "first_name": "Seongsu"}, {"last_name": "Kyung", "first_name": "Daeun"}, {"last_name": "Ryu", "first_name": "Jaehee"}, {"last_name": "Cho", "first_name": "Eunbyeol"}, {"last_name": "Lee", "first_name": "Gyubok"}, {"last_name": "Kweon", "first_name": "Sunjun"}, {"last_name": "Oh", "first_name": "Jungwoo"}, {"last_name": "Ji", "first_name": "Lei"}, {"last_name": "Chang", "first_name": "Eric I-Chao"}, {"last_name": "Kim", "first_name": "Tackeun"}, {"last_name": "Choi", "first_name": "Edward"}], "primary_category": "CL", "categories": ["CL", "", "CV"], "abstract": "  Electronic Health Records (EHRs), which contain patients' medical histories\nin various multi-modal formats, often overlook the potential for joint\nreasoning across imaging and table modalities underexplored in current EHR\nQuestion Answering (QA) systems. In this paper, we introduce EHRXQA, a novel\nmulti-modal question answering dataset combining structured EHRs and chest\nX-ray images. To develop our dataset, we first construct two uni-modal\nresources: 1) The MIMIC- CXR-VQA dataset, our newly created medical visual\nquestion answering (VQA) benchmark, specifically designed to augment the\nimaging modality in EHR QA, and 2) EHRSQL (MIMIC-IV), a refashioned version of\na previously established table-based EHR QA dataset. By integrating these two\nuni-modal resources, we successfully construct a multi-modal EHR QA dataset\nthat necessitates both uni-modal and cross-modal reasoning. To address the\nunique challenges of multi-modal questions within EHRs, we propose a\nNeuralSQL-based strategy equipped with an external VQA API. This pioneering\nendeavor enhances engagement with multi-modal EHR sources and we believe that\nour dataset can catalyze advances in real-world medical scenarios such as\nclinical decision-making and research. EHRXQA is available at\nhttps://github.com/baeseongsu/ehrxqa.\n", "title": "EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health\n  Records with Chest X-ray Images", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18653", "abstract_url": "http://arxiv.org/abs/2310.18653", "authors": [{"last_name": "Wang", "first_name": "Yi"}, {"last_name": "Hern\u00e1ndez", "first_name": "Hugo Hern\u00e1ndez"}, {"last_name": "Albrecht", "first_name": "Conrad M"}, {"last_name": "Zhu", "first_name": "Xiao Xiang"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Self-supervised learning guided by masked image modelling, such as Masked\nAutoEncoder (MAE), has attracted wide attention for pretraining vision\ntransformers in remote sensing. However, MAE tends to excessively focus on\npixel details, thereby limiting the model's capacity for semantic\nunderstanding, in particular for noisy SAR images. In this paper, we explore\nspectral and spatial remote sensing image features as improved\nMAE-reconstruction targets. We first conduct a study on reconstructing various\nimage features, all performing comparably well or better than raw pixels. Based\non such observations, we propose Feature Guided Masked Autoencoder (FG-MAE):\nreconstructing a combination of Histograms of Oriented Graidents (HOG) and\nNormalized Difference Indices (NDI) for multispectral images, and\nreconstructing HOG for SAR images. Experimental results on three downstream\ntasks illustrate the effectiveness of FG-MAE with a particular boost for SAR\nimagery. Furthermore, we demonstrate the well-inherited scalability of FG-MAE\nand release a first series of pretrained vision transformers for medium\nresolution SAR and multispectral images.\n", "title": "Feature Guided Masked Autoencoder for Self-supervised Learning in Remote\n  Sensing", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18654", "abstract_url": "http://arxiv.org/abs/2310.18654", "authors": [{"last_name": "Mogensen", "first_name": "S\u00f8ren Wengel"}, {"last_name": "Rathsman", "first_name": "Karin"}, {"last_name": "Nilsson", "first_name": "Per"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Causal discovery outputs a causal structure, represented by a graph, from\nobserved data. For time series data, there is a variety of methods, however, it\nis difficult to evaluate these on real data as realistic use cases very rarely\ncome with a known causal graph to which output can be compared. In this paper,\nwe present a dataset from an industrial subsystem at the European Spallation\nSource along with its causal graph which has been constructed from expert\nknowledge. This provides a testbed for causal discovery from time series\nobservations of complex systems, and we believe this can help inform the\ndevelopment of causal discovery methodology.\n", "title": "Causal discovery in a complex industrial system: A time series benchmark", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18656", "abstract_url": "http://arxiv.org/abs/2310.18656", "authors": [{"last_name": "Shen", "first_name": "Haoran"}, {"last_name": "Zhang", "first_name": "Yifu"}, {"last_name": "Wang", "first_name": "Wenxuan"}, {"last_name": "Chen", "first_name": "Chen"}, {"last_name": "Liu", "first_name": "Jing"}, {"last_name": "Song", "first_name": "Shanshan"}, {"last_name": "Li", "first_name": "Jiangyun"}], "primary_category": "", "categories": ["", "CV"], "abstract": "  Recent works have shown that the computational efficiency of 3D medical image\n(e.g. CT and MRI) segmentation can be impressively improved by dynamic\ninference based on slice-wise complexity. As a pioneering work, a dynamic\narchitecture network for medical volumetric segmentation (i.e. Med-DANet) has\nachieved a favorable accuracy and efficiency trade-off by dynamically selecting\na suitable 2D candidate model from the pre-defined model bank for different\nslices. However, the issues of incomplete data analysis, high training costs,\nand the two-stage pipeline in Med-DANet require further improvement. To this\nend, this paper further explores a unified formulation of the dynamic inference\nframework from the perspective of both the data itself and the model structure.\nFor each slice of the input volume, our proposed method dynamically selects an\nimportant foreground region for segmentation based on the policy generated by\nour Decision Network and Crop Position Network. Besides, we propose to insert a\nstage-wise quantization selector to the employed segmentation model (e.g.\nU-Net) for dynamic architecture adapting. Extensive experiments on BraTS 2019\nand 2020 show that our method achieves comparable or better performance than\nprevious state-of-the-art methods with much less model complexity. Compared\nwith previous methods Med-DANet and TransBTS with dynamic and static\narchitecture respectively, our framework improves the model efficiency by up to\nnearly 4.1 and 17.3 times with comparable segmentation results on BraTS 2019.\n", "title": "Med-DANet V2: A Flexible Dynamic Architecture for Efficient Medical\n  Volumetric Segmentation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18659", "abstract_url": "http://arxiv.org/abs/2310.18659", "authors": [{"last_name": "Sun", "first_name": "Hongda"}, {"last_name": "Xu", "first_name": "Weikai"}, {"last_name": "Liu", "first_name": "Wei"}, {"last_name": "Luan", "first_name": "Jian"}, {"last_name": "Wang", "first_name": "Bin"}, {"last_name": "Shang", "first_name": "Shuo"}, {"last_name": "Wen", "first_name": "Ji-Rong"}, {"last_name": "Yan", "first_name": "Rui"}], "primary_category": "", "categories": ["", "CL"], "abstract": "  Recent advances in LLMs have revolutionized the landscape of reasoning tasks.\nTo enhance the capabilities of LLMs to emulate human reasoning, prior works\nfocus on modeling reasoning steps using specific thought structures like\nchains, trees, or graphs. However, LLM-based reasoning continues to encounter\nthree challenges: 1) Selecting appropriate reasoning structures for various\ntasks; 2) Exploiting known conditions sufficiently and efficiently to deduce\nnew insights; 3) Considering the impact of historical reasoning experience. To\naddress these challenges, we propose DetermLR, a novel reasoning framework that\nformulates the reasoning process as a transformational journey from\nindeterminate premises to determinate ones. This process is marked by the\nincremental accumulation of determinate premises, making the conclusion\nprogressively closer to clarity. DetermLR includes three essential components:\n1) Premise identification: We categorize premises into two distinct types:\ndeterminate and indeterminate. This empowers LLMs to customize reasoning\nstructures to match the specific task complexities. 2) Premise prioritization\nand exploration: We leverage quantitative measurements to assess the relevance\nof each premise to the target, prioritizing more relevant premises for\nexploring new insights. 3) Iterative process with reasoning memory: We\nintroduce a reasoning memory module to automate storage and extraction of\navailable premises and reasoning paths, preserving historical reasoning details\nfor more accurate premise prioritization. Comprehensive experimental results\nshow that DetermLR outperforms all baselines on four challenging logical\nreasoning tasks: LogiQA, ProofWriter, FOLIO, and LogicalDeduction. DetermLR can\nachieve better reasoning performance while requiring fewer visited states,\nhighlighting its superior efficiency and effectiveness in tackling logical\nreasoning tasks.\n", "title": "From Indeterminacy to Determinacy: Augmenting Logical Reasoning\n  Capabilities with Large Language Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18660", "abstract_url": "http://arxiv.org/abs/2310.18660", "authors": [{"last_name": "Jakubik", "first_name": "Johannes"}, {"last_name": "Roy", "first_name": "Sujit"}, {"last_name": "Phillips", "first_name": "C. E."}, {"last_name": "Fraccaro", "first_name": "Paolo"}, {"last_name": "Godwin", "first_name": "Denys"}, {"last_name": "Zadrozny", "first_name": "Bianca"}, {"last_name": "Szwarcman", "first_name": "Daniela"}, {"last_name": "Gomes", "first_name": "Carlos"}, {"last_name": "Nyirjesy", "first_name": "Gabby"}, {"last_name": "Edwards", "first_name": "Blair"}, {"last_name": "Kimura", "first_name": "Daiki"}, {"last_name": "Simumba", "first_name": "Naomi"}, {"last_name": "Chu", "first_name": "Linsong"}, {"last_name": "Mukkavilli", "first_name": "S. Karthik"}, {"last_name": "Lambhate", "first_name": "Devyani"}, {"last_name": "Das", "first_name": "Kamal"}, {"last_name": "Bangalore", "first_name": "Ranjini"}, {"last_name": "Oliveira", "first_name": "Dario"}, {"last_name": "Muszynski", "first_name": "Michal"}, {"last_name": "Ankur", "first_name": "Kumar"}, {"last_name": "Ramasubramanian", "first_name": "Muthukumaran"}, {"last_name": "Gurung", "first_name": "Iksha"}, {"last_name": "Khallaghi", "first_name": "Sam"}, {"last_name": "Hanxi", "first_name": ""}, {"last_name": "Li", "first_name": ""}, {"last_name": "Cecil", "first_name": "Michael"}, {"last_name": "Ahmadi", "first_name": "Maryam"}, {"last_name": "Kordi", "first_name": "Fatemeh"}, {"last_name": "Alemohammad", "first_name": "Hamed"}, {"last_name": "Maskey", "first_name": "Manil"}, {"last_name": "Ganti", "first_name": "Raghu"}, {"last_name": "Weldemariam", "first_name": "Kommy"}, {"last_name": "Ramachandran", "first_name": "Rahul"}], "primary_category": "CV", "categories": ["CV", "LG"], "abstract": "  Significant progress in the development of highly adaptable and reusable\nArtificial Intelligence (AI) models is expected to have a significant impact on\nEarth science and remote sensing. Foundation models are pre-trained on large\nunlabeled datasets through self-supervision, and then fine-tuned for various\ndownstream tasks with small labeled datasets. This paper introduces a\nfirst-of-a-kind framework for the efficient pre-training and fine-tuning of\nfoundational models on extensive geospatial data. We have utilized this\nframework to create Prithvi, a transformer-based geospatial foundational model\npre-trained on more than 1TB of multispectral satellite imagery from the\nHarmonized Landsat-Sentinel 2 (HLS) dataset. Our study demonstrates the\nefficacy of our framework in successfully fine-tuning Prithvi to a range of\nEarth observation tasks that have not been tackled by previous work on\nfoundation models involving multi-temporal cloud gap imputation, flood mapping,\nwildfire scar segmentation, and multi-temporal crop segmentation. Our\nexperiments show that the pre-trained model accelerates the fine-tuning process\ncompared to leveraging randomly initialized weights. In addition, pre-trained\nPrithvi compares well against the state-of-the-art, e.g., outperforming a\nconditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%)\nin the structural similarity index. Finally, due to the limited availability of\nlabeled data in the field of Earth observation, we gradually reduce the\nquantity of available labeled data for refining the model to evaluate data\nefficiency and demonstrate that data can be decreased significantly without\naffecting the model's accuracy. The pre-trained 100 million parameter model and\ncorresponding fine-tuning workflows have been released publicly as open source\ncontributions to the global Earth sciences community through Hugging Face.\n", "title": "Foundation Models for Generalist Geospatial Artificial Intelligence", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18662", "abstract_url": "http://arxiv.org/abs/2310.18662", "authors": [{"last_name": "Cao", "first_name": "Ruisheng"}, {"last_name": "Zhang", "first_name": "Hanchong"}, {"last_name": "Xu", "first_name": "Hongshen"}, {"last_name": "Li", "first_name": "Jieyu"}, {"last_name": "Ma", "first_name": "Da"}, {"last_name": "Chen", "first_name": "Lu"}, {"last_name": "Yu", "first_name": "Kai"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Text-to-SQL aims to generate an executable SQL program given the user\nutterance and the corresponding database schema. To ensure the well-formedness\nof output SQLs, one prominent approach adopts a grammar-based recurrent decoder\nto produce the equivalent SQL abstract syntax tree (AST). However, previous\nmethods mainly utilize an RNN-series decoder, which 1) is time-consuming and\ninefficient and 2) introduces very few structure priors. In this work, we\npropose an AST structure-aware Transformer decoder (ASTormer) to replace\ntraditional RNN cells. The structural knowledge, such as node types and\npositions in the tree, is seamlessly incorporated into the decoder via both\nabsolute and relative position embeddings. Besides, the proposed framework is\ncompatible with different traversing orders even considering adaptive node\nselection. Extensive experiments on five text-to-SQL benchmarks demonstrate the\neffectiveness and efficiency of our structured decoder compared to competitive\nbaselines.\n", "title": "ASTormer: An AST Structure-aware Transformer Decoder for Text-to-SQL", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18664", "abstract_url": "http://arxiv.org/abs/2310.18664", "authors": [{"last_name": "Page", "first_name": "Pranav S."}, {"last_name": "Siyote", "first_name": "Anand S."}, {"last_name": "Borkar", "first_name": "Vivek S."}, {"last_name": "Kasbekar", "first_name": "Gaurav S."}], "primary_category": "NI", "categories": ["NI"], "abstract": "  The Internet of Things (IoT) is emerging as a critical technology to connect\nresource-constrained devices such as sensors and actuators as well as\nappliances to the Internet. In this paper, we propose a novel methodology for\nnode cardinality estimation in wireless networks such as the IoT and\nRadio-Frequency IDentification (RFID) systems, which uses the privileged\nfeature distillation (PFD) technique and works using a neural network with a\nteacher-student model. The teacher is trained using both privileged and regular\nfeatures, and the student is trained with predictions from the teacher and\nregular features. We propose node cardinality estimation algorithms based on\nthe PFD technique for homogeneous as well as heterogeneous wireless networks.\nWe show via extensive simulations that the proposed PFD based algorithms for\nhomogeneous as well as heterogeneous networks achieve much lower mean squared\nerrors in the computed node cardinality estimates than state-of-the-art\nprotocols proposed in prior work, while taking the same number of time slots\nfor executing the node cardinality estimation process as the latter protocols.\n", "title": "Node Cardinality Estimation in the Internet of Things Using Privileged\n  Feature Distillation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18666", "abstract_url": "http://arxiv.org/abs/2310.18666", "authors": [{"last_name": "Lei", "first_name": "Zhengyang"}, {"last_name": "Shao", "first_name": "Sihong"}, {"last_name": "Xiong", "first_name": "Yunfeng"}], "primary_category": "", "categories": ["", ""], "abstract": "  Numerical resolution of high-dimensional nonlinear PDEs remains a huge\nchallenge due to the curse of dimensionality. Starting from the weak\nformulation of the Lawson-Euler scheme, this paper proposes a stochastic\nparticle method (SPM) by tracking the deterministic motion, random jump,\nresampling and reweighting of particles. Real-valued weighted particles are\nadopted by SPM to approximate the high-dimensional solution, which\nautomatically adjusts the point distribution to intimate the relevant feature\nof the solution. A piecewise constant reconstruction with virtual uniform grid\nis employed to evaluate the nonlinear terms, which fully exploits the intrinsic\nadaptive characteristic of SPM. Combining both can SPM achieve the goal of\nadaptive sampling in time. Numerical experiments on the 6-D Allen-Cahn equation\nand the 7-D Hamiltonian-Jacobi-Bellman equation demonstrate the potential of\nSPM in solving high-dimensional nonlinear PDEs efficiently while maintaining an\nacceptable accuracy.\n", "title": "An efficient stochastic particle method for high-dimensional nonlinear\n  PDEs", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18668", "abstract_url": "http://arxiv.org/abs/2310.18668", "authors": [{"last_name": "Laila", "first_name": "Prof N. Jeenath"}, {"last_name": "Tamilpavai", "first_name": "Dr G."}], "primary_category": "CR", "categories": ["CR", ""], "abstract": "  In the digital age, it is crucial to make sure that financial transactions\nare as secure and reliable as possible. This abstract offers a ground-breaking\nmethod that combines smart contracts, blockchain technology, FaceNet512 for\nimproved face recognition, and Gaussian Mixture Models (GMM) for speech\nauthentication to create a system for video and audio verification that is\nunmatched. Smart contracts and the immutable ledger of the blockchain are\ncombined to offer a safe and open environment for financial transactions.\nFaceNet512 and GMM offer multi-factor biometric authentication simultaneously,\nenhancing security to new heights. By combining cutting-edge technology, this\nsystem offers a strong defense against identity theft and illegal access,\nestablishing a new benchmark for safe financial transactions.\n", "title": "FinBTech: Blockchain-Based Video and Voice Authentication System for\n  Enhanced Security in Financial Transactions Utilizing FaceNet512 and Gaussian\n  Mixture Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18672", "abstract_url": "http://arxiv.org/abs/2310.18672", "authors": [{"last_name": "Brusca", "first_name": "Lorenzo"}, {"last_name": "Quaedvlieg", "first_name": "Lars C. P. M."}, {"last_name": "Skoulakis", "first_name": "Stratis"}, {"last_name": "Chrysos", "first_name": "Grigorios G"}, {"last_name": "Cevher", "first_name": "Volkan"}], "primary_category": "LG", "categories": ["LG", "DM"], "abstract": "  This work presents a graph neural network (GNN) framework for solving the\nmaximum independent set (MIS) problem, inspired by dynamic programming (DP).\nSpecifically, given a graph, we propose a DP-like recursive algorithm based on\nGNNs that firstly constructs two smaller sub-graphs, predicts the one with the\nlarger MIS, and then uses it in the next recursive call. To train our\nalgorithm, we require annotated comparisons of different graphs concerning\ntheir MIS size. Annotating the comparisons with the output of our algorithm\nleads to a self-training process that results in more accurate self-annotation\nof the comparisons and vice versa. We provide numerical evidence showing the\nsuperiority of our method vs prior methods in multiple synthetic and real-world\ndatasets.\n", "title": "Maximum Independent Set: Self-Training through Dynamic Programming", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18676", "abstract_url": "http://arxiv.org/abs/2310.18676", "authors": [{"last_name": "Shamsolmoali", "first_name": "Pourya"}, {"last_name": "Chanussot", "first_name": "Jocelyn"}, {"last_name": "Zhou", "first_name": "Huiyu"}, {"last_name": "Lu", "first_name": "Yue"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Efficient object detection methods have recently received great attention in\nremote sensing. Although deep convolutional networks often have excellent\ndetection accuracy, their deployment on resource-limited edge devices is\ndifficult. Knowledge distillation (KD) is a strategy for addressing this issue\nsince it makes models lightweight while maintaining accuracy. However, existing\nKD methods for object detection have encountered two constraints. First, they\ndiscard potentially important background information and only distill nearby\nforeground regions. Second, they only rely on the global context, which limits\nthe student detector's ability to acquire local information from the teacher\ndetector. To address the aforementioned challenges, we propose Attention-based\nFeature Distillation (AFD), a new KD approach that distills both local and\nglobal information from the teacher detector. To enhance local distillation, we\nintroduce a multi-instance attention mechanism that effectively distinguishes\nbetween background and foreground elements. This approach prompts the student\ndetector to focus on the pertinent channels and pixels, as identified by the\nteacher detector. Local distillation lacks global information, thus attention\nglobal distillation is proposed to reconstruct the relationship between various\npixels and pass it from teacher to student detector. The performance of AFD is\nevaluated on two public aerial image benchmarks, and the evaluation results\ndemonstrate that AFD in object detection can attain the performance of other\nstate-of-the-art models while being efficient.\n", "title": "Efficient Object Detection in Optical Remote Sensing Imagery via\n  Attention-based Feature Distillation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18677", "abstract_url": "http://arxiv.org/abs/2310.18677", "authors": [{"last_name": "Yoon", "first_name": "Sangwoong"}, {"last_name": "Jin", "first_name": "Young-Uk"}, {"last_name": "Noh", "first_name": "Yung-Kyun"}, {"last_name": "Park", "first_name": "Frank C."}], "primary_category": "LG", "categories": ["LG"], "abstract": "  We present a new method of training energy-based models (EBMs) for anomaly\ndetection that leverages low-dimensional structures within data. The proposed\nalgorithm, Manifold Projection-Diffusion Recovery (MPDR), first perturbs a data\npoint along a low-dimensional manifold that approximates the training dataset.\nThen, EBM is trained to maximize the probability of recovering the original\ndata. The training involves the generation of negative samples via MCMC, as in\nconventional EBM training, but from a different distribution concentrated near\nthe manifold. The resulting near-manifold negative samples are highly\ninformative, reflecting relevant modes of variation in data. An energy function\nof MPDR effectively learns accurate boundaries of the training data\ndistribution and excels at detecting out-of-distribution samples. Experimental\nresults show that MPDR exhibits strong performance across various anomaly\ndetection tasks involving diverse data types, such as images, vectors, and\nacoustic signals.\n", "title": "Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery\n  Approach", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18679", "abstract_url": "http://arxiv.org/abs/2310.18679", "authors": [{"last_name": "Mousavi", "first_name": "Sajad"}, {"last_name": "Guti\u00e9rrez", "first_name": "Ricardo Luna"}, {"last_name": "Rengarajan", "first_name": "Desik"}, {"last_name": "Gundecha", "first_name": "Vineet"}, {"last_name": "Babu", "first_name": "Ashwin Ramesh"}, {"last_name": "Naug", "first_name": "Avisek"}, {"last_name": "Guillen", "first_name": "Antonio"}, {"last_name": "Sarkar", "first_name": "Soumyendu"}], "primary_category": "CL", "categories": ["CL", "", "LG"], "abstract": "  We propose a self-correction mechanism for Large Language Models (LLMs) to\nmitigate issues such as toxicity and fact hallucination. This method involves\nrefining model outputs through an ensemble of critics and the model's own\nfeedback. Drawing inspiration from human behavior, we explore whether LLMs can\nemulate the self-correction process observed in humans who often engage in\nself-reflection and seek input from others to refine their understanding of\ncomplex topics. Our approach is model-agnostic and can be applied across\nvarious domains to enhance trustworthiness by addressing fairness, bias, and\nrobustness concerns. We consistently observe performance improvements in LLMs\nfor reducing toxicity and correcting factual errors.\n", "title": "N-Critics: Self-Refinement of Large Language Models with Ensemble of\n  Critics", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18681", "abstract_url": "http://arxiv.org/abs/2310.18681", "authors": [{"last_name": "Mesinovic", "first_name": "Munib"}, {"last_name": "Watkinson", "first_name": "Peter"}, {"last_name": "Zhu", "first_name": "Tingting"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Survival analysis helps approximate underlying distributions of\ntime-to-events which in the case of critical care like in the ICU can be a\npowerful tool for dynamic mortality risk prediction. Extending beyond the\nclassical Cox model, deep learning techniques have been leveraged over the last\nyears relaxing the many constraints of their counterparts from statistical\nmethods. In this work, we propose a novel conditional variational\nautoencoder-based method called DySurv which uses a combination of static and\ntime-series measurements from patient electronic health records in estimating\nrisk of death dynamically in the ICU. DySurv has been tested on standard\nbenchmarks where it outperforms most existing methods including other deep\nlearning methods and we evaluate it on a real-world patient database from\nMIMIC-IV. The predictive capacity of DySurv is consistent and the survival\nestimates remain disentangled across different datasets supporting the idea\nthat dynamic deep learning models based on conditional variational inference in\nmulti-task cases can be robust models for survival analysis.\n", "title": "DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18685", "abstract_url": "http://arxiv.org/abs/2310.18685", "authors": [{"last_name": "Kumar", "first_name": "Sandeep"}, {"last_name": "Ghosal", "first_name": "Tirthankar"}, {"last_name": "Ekbal", "first_name": "Asif"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  To this date, the efficacy of the scientific publishing enterprise\nfundamentally rests on the strength of the peer review process. The journal\neditor or the conference chair primarily relies on the expert reviewers'\nassessment, identify points of agreement and disagreement and try to reach a\nconsensus to make a fair and informed decision on whether to accept or reject a\npaper. However, with the escalating number of submissions requiring review,\nespecially in top-tier Artificial Intelligence (AI) conferences, the\neditor/chair, among many other works, invests a significant, sometimes\nstressful effort to mitigate reviewer disagreements. Here in this work, we\nintroduce a novel task of automatically identifying contradictions among\nreviewers on a given article. To this end, we introduce ContraSciView, a\ncomprehensive review-pair contradiction dataset on around 8.5k papers (with\naround 28k review pairs containing nearly 50k review pair comments) from the\nopen review-based ICLR and NeurIPS conferences. We further propose a baseline\nmodel that detects contradictory statements from the review pairs. To the best\nof our knowledge, we make the first attempt to identify disagreements among\npeer reviewers automatically. We make our dataset and code public for further\ninvestigations.\n", "title": "When Reviewers Lock Horn: Finding Disagreement in Scientific Peer\n  Reviews", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18687", "abstract_url": "http://arxiv.org/abs/2310.18687", "authors": [{"last_name": "Hu", "first_name": "Hao"}, {"last_name": "Yang", "first_name": "Yiqin"}, {"last_name": "Ye", "first_name": "Jianing"}, {"last_name": "Mai", "first_name": "Ziqing"}, {"last_name": "Zhang", "first_name": "Chongjie"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Reward-free data is abundant and contains rich prior knowledge of human\nbehaviors, but it is not well exploited by offline reinforcement learning (RL)\nalgorithms. In this paper, we propose UBER, an unsupervised approach to extract\nuseful behaviors from offline reward-free datasets via diversified rewards.\nUBER assigns different pseudo-rewards sampled from a given prior distribution\nto different agents to extract a diverse set of behaviors, and reuse them as\ncandidate policies to facilitate the learning of new tasks. Perhaps\nsurprisingly, we show that rewards generated from random neural networks are\nsufficient to extract diverse and useful behaviors, some even close to expert\nones. We provide both empirical and theoretical evidence to justify the use of\nrandom priors for the reward function. Experiments on multiple benchmarks\nshowcase UBER's ability to learn effective and diverse behavior sets that\nenhance sample efficiency for online RL, outperforming existing baselines. By\nreducing reliance on human supervision, UBER broadens the applicability of RL\nto real-world scenarios with abundant reward-free data.\n", "title": "Unsupervised Behavior Extraction via Random Intent Priors", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18688", "abstract_url": "http://arxiv.org/abs/2310.18688", "authors": [{"last_name": "Jarrett", "first_name": "Daniel"}, {"last_name": "Yoon", "first_name": "Jinsung"}, {"last_name": "Bica", "first_name": "Ioana"}, {"last_name": "Qian", "first_name": "Zhaozhi"}, {"last_name": "Ercole", "first_name": "Ari"}, {"last_name": "van der Schaar", "first_name": "Mihaela"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Time-series learning is the bread and butter of data-driven *clinical\ndecision support*, and the recent explosion in ML research has demonstrated\ngreat potential in various healthcare settings. At the same time, medical\ntime-series problems in the wild are challenging due to their highly\n*composite* nature: They entail design choices and interactions among\ncomponents that preprocess data, impute missing values, select features, issue\npredictions, estimate uncertainty, and interpret models. Despite exponential\ngrowth in electronic patient data, there is a remarkable gap between the\npotential and realized utilization of ML for clinical research and decision\nsupport. In particular, orchestrating a real-world project lifecycle poses\nchallenges in engineering (i.e. hard to build), evaluation (i.e. hard to\nassess), and efficiency (i.e. hard to optimize). Designed to address these\nissues simultaneously, Clairvoyance proposes a unified, end-to-end,\nautoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical\nstandard, and (iii) interface for optimization. Our ultimate goal lies in\nfacilitating transparent and reproducible experimentation with complex\ninference workflows, providing integrated pathways for (1) personalized\nprediction, (2) treatment-effect estimation, and (3) information acquisition.\nThrough illustrative examples on real-world data in outpatient, general wards,\nand intensive-care settings, we illustrate the applicability of the pipeline\nparadigm on core tasks in the healthcare journey. To the best of our knowledge,\nClairvoyance is the first to demonstrate viability of a comprehensive and\nautomatable pipeline for clinical time-series ML.\n", "title": "Clairvoyance: A Pipeline Toolkit for Medical Time Series", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18689", "abstract_url": "http://arxiv.org/abs/2310.18689", "authors": [{"last_name": "Azad", "first_name": "Bobby"}, {"last_name": "Azad", "first_name": "Reza"}, {"last_name": "Eskandari", "first_name": "Sania"}, {"last_name": "Bozorgpour", "first_name": "Afshin"}, {"last_name": "Kazerouni", "first_name": "Amirhossein"}, {"last_name": "Rekik", "first_name": "Islem"}, {"last_name": "Merhof", "first_name": "Dorit"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Foundation models, large-scale, pre-trained deep-learning models adapted to a\nwide range of downstream tasks have gained significant interest lately in\nvarious deep-learning problems undergoing a paradigm shift with the rise of\nthese models. Trained on large-scale dataset to bridge the gap between\ndifferent modalities, foundation models facilitate contextual reasoning,\ngeneralization, and prompt capabilities at test time. The predictions of these\nmodels can be adjusted for new tasks by augmenting the model input with\ntask-specific hints called prompts without requiring extensive labeled data and\nretraining. Capitalizing on the advances in computer vision, medical imaging\nhas also marked a growing interest in these models. To assist researchers in\nnavigating this direction, this survey intends to provide a comprehensive\noverview of foundation models in the domain of medical imaging. Specifically,\nwe initiate our exploration by providing an exposition of the fundamental\nconcepts forming the basis of foundation models. Subsequently, we offer a\nmethodical taxonomy of foundation models within the medical domain, proposing a\nclassification system primarily structured around training strategies, while\nalso incorporating additional facets such as application domains, imaging\nmodalities, specific organs of interest, and the algorithms integral to these\nmodels. Furthermore, we emphasize the practical use case of some selected\napproaches and then discuss the opportunities, applications, and future\ndirections of these large-scale pre-trained models, for analyzing medical\nimages. In the same vein, we address the prevailing challenges and research\npathways associated with foundational models in medical imaging. These\nencompass the areas of interpretability, data management, computational\nrequirements, and the nuanced issue of contextual comprehension.\n", "title": "Foundational Models in Medical Imaging: A Comprehensive Survey and\n  Future Vision", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18696", "abstract_url": "http://arxiv.org/abs/2310.18696", "authors": [{"last_name": "Starace", "first_name": "Giulio"}, {"last_name": "Papakostas", "first_name": "Konstantinos"}, {"last_name": "Choenni", "first_name": "Rochelle"}, {"last_name": "Panagiotopoulos", "first_name": "Apostolos"}, {"last_name": "Rosati", "first_name": "Matteo"}, {"last_name": "Leidinger", "first_name": "Alina"}, {"last_name": "Shutova", "first_name": "Ekaterina"}], "primary_category": "CL", "categories": ["CL", "", "LG"], "abstract": "  Large Language Models (LLMs) exhibit impressive performance on a range of NLP\ntasks, due to the general-purpose linguistic knowledge acquired during\npretraining. Existing model interpretability research (Tenney et al., 2019)\nsuggests that a linguistic hierarchy emerges in the LLM layers, with lower\nlayers better suited to solving syntactic tasks and higher layers employed for\nsemantic processing. Yet, little is known about how encodings of different\nlinguistic phenomena interact within the models and to what extent processing\nof linguistically-related categories relies on the same, shared model\nrepresentations. In this paper, we propose a framework for testing the joint\nencoding of linguistic categories in LLMs. Focusing on syntax, we find evidence\nof joint encoding both at the same (related part-of-speech (POS) classes) and\ndifferent (POS classes and related syntactic dependency relations) levels of\nlinguistic hierarchy. Our cross-lingual experiments show that the same patterns\nhold across languages in multilingual LLMs.\n", "title": "Probing LLMs for Joint Encoding of Linguistic Categories", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18697", "abstract_url": "http://arxiv.org/abs/2310.18697", "authors": [{"last_name": "Bai", "first_name": "Fang"}, {"last_name": "Wu", "first_name": "Kanzhi"}, {"last_name": "Bartoli", "first_name": "Adrien"}], "primary_category": "RO", "categories": ["RO", "", "", "", ""], "abstract": "  We study the generalized Procrustes analysis (GPA), as a minimal formulation\nto the simultaneous localization and mapping (SLAM) problem. We propose\nKernelGPA, a novel global registration technique to solve SLAM in the\ndeformable environment. We propose the concept of deformable transformation\nwhich encodes the entangled pose and deformation. We define deformable\ntransformations using a kernel method, and show that both the deformable\ntransformations and the environment map can be solved globally in closed-form,\nup to global scale ambiguities. We solve the scale ambiguities by an\noptimization formulation that maximizes rigidity. We demonstrate KernelGPA\nusing the Gaussian kernel, and validate the superiority of KernelGPA with\nvarious datasets. Code and data are available at\n\\url{https://bitbucket.org/FangBai/deformableprocrustes}.\n", "title": "KernelGPA: A Globally Optimal Solution to Deformable SLAM in Closed-form", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18698", "abstract_url": "http://arxiv.org/abs/2310.18698", "authors": [{"last_name": "Nie", "first_name": "Xuesong"}, {"last_name": "Chen", "first_name": "Xi"}, {"last_name": "Jin", "first_name": "Haoyuan"}, {"last_name": "Zhu", "first_name": "Zhihang"}, {"last_name": "Yan", "first_name": "Yunfeng"}, {"last_name": "Qi", "first_name": "Donglian"}], "primary_category": "CV", "categories": ["CV", "LG"], "abstract": "  Spatiotemporal predictive learning offers a self-supervised learning paradigm\nthat enables models to learn both spatial and temporal patterns by predicting\nfuture sequences based on historical sequences. Mainstream methods are\ndominated by recurrent units, yet they are limited by their lack of\nparallelization and often underperform in real-world scenarios. To improve\nprediction quality while maintaining computational efficiency, we propose an\ninnovative triplet attention transformer designed to capture both inter-frame\ndynamics and intra-frame static features. Specifically, the model incorporates\nthe Triplet Attention Module (TAM), which replaces traditional recurrent units\nby exploring self-attention mechanisms in temporal, spatial, and channel\ndimensions. In this configuration: (i) temporal tokens contain abstract\nrepresentations of inter-frame, facilitating the capture of inherent temporal\ndependencies; (ii) spatial and channel attention combine to refine the\nintra-frame representation by performing fine-grained interactions across\nspatial and channel dimensions. Alternating temporal, spatial, and\nchannel-level attention allows our approach to learn more complex short- and\nlong-range spatiotemporal dependencies. Extensive experiments demonstrate\nperformance surpassing existing recurrent-based and recurrent-free methods,\nachieving state-of-the-art under multi-scenario examination including moving\nobject trajectory prediction, traffic flow prediction, driving scene\nprediction, and human motion capture.\n", "title": "Triplet Attention Transformer for Spatiotemporal Predictive Learning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18700", "abstract_url": "http://arxiv.org/abs/2310.18700", "authors": [{"last_name": "Zhang", "first_name": "An"}, {"last_name": "Sheng", "first_name": "Leheng"}, {"last_name": "Cai", "first_name": "Zhibo"}, {"last_name": "Wang", "first_name": "Xiang"}, {"last_name": "Chua", "first_name": "Tat-Seng"}], "primary_category": "IR", "categories": ["IR"], "abstract": "  Contrastive Learning (CL) has achieved impressive performance in\nself-supervised learning tasks, showing superior generalization ability.\nInspired by the success, adopting CL into collaborative filtering (CF) is\nprevailing in semi-supervised top-K recommendations. The basic idea is to\nroutinely conduct heuristic-based data augmentation and apply contrastive\nlosses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges\nmake this adoption suboptimal, such as the issue of out-of-distribution, the\nrisk of false negatives, and the nature of top-K evaluation. They necessitate\nthe CL-based CF scheme to focus more on mining hard negatives and\ndistinguishing false negatives from the vast unlabeled user-item interactions,\nfor informative contrast signals. Worse still, there is limited understanding\nof contrastive loss in CF methods, especially w.r.t. its generalization\nability. To bridge the gap, we delve into the reasons underpinning the success\nof contrastive loss in CF, and propose a principled Adversarial InfoNCE loss\n(AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods.\nAdvInfoNCE adaptively explores and assigns hardness to each negative instance\nin an adversarial fashion and further utilizes a fine-grained hardness-aware\nranking criterion to empower the recommender's generalization ability. Training\nCF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both\nsynthetic and real-world benchmark datasets, thus showing its generalization\nability to mitigate out-of-distribution problems. Given the theoretical\nguarantees and empirical superiority of AdvInfoNCE over most contrastive loss\nfunctions, we advocate its adoption as a standard loss in recommender systems,\nparticularly for the out-of-distribution tasks. Codes are available at\nhttps://github.com/LehengTHU/AdvInfoNCE.\n", "title": "Empowering Collaborative Filtering with Principled Adversarial\n  Contrastive Loss", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18701", "abstract_url": "http://arxiv.org/abs/2310.18701", "authors": [{"last_name": "Xue", "first_name": "Bo"}, {"last_name": "Wang", "first_name": "Yimu"}, {"last_name": "Wan", "first_name": "Yuanyu"}, {"last_name": "Yi", "first_name": "Jinfeng"}, {"last_name": "Zhang", "first_name": "Lijun"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  This paper investigates the problem of generalized linear bandits with\nheavy-tailed rewards, whose $(1+\\epsilon)$-th moment is bounded for some\n$\\epsilon\\in (0,1]$. Although there exist methods for generalized linear\nbandits, most of them focus on bounded or sub-Gaussian rewards and are not\nwell-suited for many real-world scenarios, such as financial markets and\nweb-advertising. To address this issue, we propose two novel algorithms based\non truncation and mean of medians. These algorithms achieve an almost optimal\nregret bound of $\\widetilde{O}(dT^{\\frac{1}{1+\\epsilon}})$, where $d$ is the\ndimension of contextual information and $T$ is the time horizon. Our\ntruncation-based algorithm supports online learning, distinguishing it from\nexisting truncation-based approaches. Additionally, our mean-of-medians-based\nalgorithm requires only $O(\\log T)$ rewards and one estimator per epoch, making\nit more practical. Moreover, our algorithms improve the regret bounds by a\nlogarithmic factor compared to existing algorithms when $\\epsilon=1$. Numerical\nexperimental results confirm the merits of our algorithms.\n", "title": "Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed\n  Rewards", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18702", "abstract_url": "http://arxiv.org/abs/2310.18702", "authors": [{"last_name": "Pope", "first_name": "Phillip"}, {"last_name": "Jacobs", "first_name": "David"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  The Kohn-Sham equations underlie many important applications such as the\ndiscovery of new catalysts. Recent machine learning work on catalyst modeling\nhas focused on prediction of the energy, but has so far not yet demonstrated\nsignificant out-of-distribution generalization. Here we investigate another\napproach based on the pointwise learning of the Kohn-Sham charge-density. On a\nnew dataset of bulk catalysts with charge densities, we show density models can\ngeneralize to new structures with combinations of elements not seen at train\ntime, a form of combinatorial generalization. We show that over 80% of binary\nand ternary test cases achieve faster convergence than standard baselines in\nDensity Functional Theory, amounting to an average reduction of 13% in the\nnumber of iterations required to reach convergence, which may be of independent\ninterest. Our results suggest that density learning is a viable alternative,\ntrading greater inference costs for a step towards combinatorial\ngeneralization, a key property for applications.\n", "title": "Towards Combinatorial Generalization for Catalysts: A Kohn-Sham\n  Charge-Density Approach", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18706", "abstract_url": "http://arxiv.org/abs/2310.18706", "authors": [{"last_name": "Wang", "first_name": "Shengkun"}, {"last_name": "Bai", "first_name": "YangXiao"}, {"last_name": "Fu", "first_name": "Kaiqun"}, {"last_name": "Wang", "first_name": "Linhan"}, {"last_name": "Lu", "first_name": "Chang-Tien"}, {"last_name": "Ji", "first_name": "Taoran"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  For both investors and policymakers, forecasting the stock market is\nessential as it serves as an indicator of economic well-being. To this end, we\nharness the power of social media data, a rich source of public sentiment, to\nenhance the accuracy of stock market predictions. Diverging from conventional\nmethods, we pioneer an approach that integrates sentiment analysis,\nmacroeconomic indicators, search engine data, and historical prices within a\nmulti-attention deep learning model, masterfully decoding the complex patterns\ninherent in the data. We showcase the state-of-the-art performance of our\nproposed model using a dataset, specifically curated by us, for predicting\nstock market movements and volatility.\n", "title": "ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock\n  Movement and Volatility Prediction", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18709", "abstract_url": "http://arxiv.org/abs/2310.18709", "authors": [{"last_name": "Guo", "first_name": "Ruohao"}, {"last_name": "Chen", "first_name": "Yaru"}, {"last_name": "Qi", "first_name": "Yanyu"}, {"last_name": "Yue", "first_name": "Wenzhen"}, {"last_name": "Niu", "first_name": "Dantong"}, {"last_name": "Ying", "first_name": "Xianghua"}], "primary_category": "CV", "categories": ["CV", "LG", "MM", "SD", ""], "abstract": "  In this paper, we propose a new multi-modal task, namely audio-visual\ninstance segmentation (AVIS), in which the goal is to identify, segment, and\ntrack individual sounding object instances in audible videos, simultaneously.\nTo our knowledge, it is the first time that instance segmentation has been\nextended into the audio-visual domain. To better facilitate this research, we\nconstruct the first audio-visual instance segmentation benchmark (AVISeg).\nSpecifically, AVISeg consists of 1,258 videos with an average duration of 62.6\nseconds from YouTube and public audio-visual datasets, where 117 videos have\nbeen annotated by using an interactive semi-automatic labeling tool based on\nthe Segment Anything Model (SAM). In addition, we present a simple baseline\nmodel for the AVIS task. Our new model introduces an audio branch and a\ncross-modal fusion module to Mask2Former to locate all sounding objects.\nFinally, we evaluate the proposed method using two backbones on AVISeg. We\nbelieve that AVIS will inspire the community towards a more comprehensive\nmulti-modal understanding.\n", "title": "Audio-Visual Instance Segmentation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18713", "abstract_url": "http://arxiv.org/abs/2310.18713", "authors": [{"last_name": "Shen", "first_name": "Jiayi"}, {"last_name": "Zhen", "first_name": "Xiantong"}, {"last_name": "Qi", "first_name": ""}, {"last_name": "Wang", "first_name": ""}, {"last_name": "Worring", "first_name": "Marcel"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  This paper focuses on the data-insufficiency problem in multi-task learning\nwithin an episodic training setup. Specifically, we explore the potential of\nheterogeneous information across tasks and meta-knowledge among episodes to\neffectively tackle each task with limited data. Existing meta-learning methods\noften fail to take advantage of crucial heterogeneous information in a single\nepisode, while multi-task learning models neglect reusing experience from\nearlier episodes. To address the problem of insufficient data, we develop\nHeterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within\nthe framework of hierarchical Bayes, HNPs effectively capitalize on prior\nexperiences as meta-knowledge and capture task-relatedness among heterogeneous\ntasks, mitigating data-insufficiency. Meanwhile, transformer-structured\ninference modules are designed to enable efficient inferences toward\nmeta-knowledge and task-relatedness. In this way, HNPs can learn more powerful\nfunctional priors for adapting to novel heterogeneous tasks in each meta-test\nepisode. Experimental results show the superior performance of the proposed\nHNPs over typical baselines, and ablation studies verify the effectiveness of\nthe designed inference modules.\n", "title": "Episodic Multi-Task Learning with Heterogeneous Neural Processes", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18714", "abstract_url": "http://arxiv.org/abs/2310.18714", "authors": [{"last_name": "Guan", "first_name": "Quanlong"}, {"last_name": "Zhu", "first_name": "Tong"}, {"last_name": "Fang", "first_name": "Liangda"}, {"last_name": "Qiu", "first_name": "Junming"}, {"last_name": "Lai", "first_name": "Zhao-Rong"}, {"last_name": "Luo", "first_name": "Weiqi"}], "primary_category": "", "categories": [""], "abstract": "  Belief revision and update, two significant types of belief change, both\nfocus on how an agent modify her beliefs in presence of new information. The\nmost striking difference between them is that the former studies the change of\nbeliefs in a static world while the latter concentrates on a\ndynamically-changing world. The famous AGM and KM postulates were proposed to\ncapture rational belief revision and update, respectively. However, both of\nthem are too permissive to exclude some unreasonable changes in the iteration.\nIn response to this weakness, the DP postulates and its extensions for iterated\nbelief revision were presented. Furthermore, Rodrigues integrated these\npostulates in belief update. Unfortunately, his approach does not meet the\nbasic requirement of iterated belief update. This paper is intended to solve\nthis problem of Rodrigues's approach. Firstly, we present a modification of the\noriginal KM postulates based on belief states. Subsequently, we migrate several\nwell-known postulates for iterated belief revision to iterated belief update.\nMoreover, we provide the exact semantic characterizations based on partial\npreorders for each of the proposed postulates. Finally, we analyze the\ncompatibility between the above iterated postulates and the KM postulates for\nbelief update.\n", "title": "An Investigation of Darwiche and Pearl's Postulates for Iterated Belief\n  Update", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18715", "abstract_url": "http://arxiv.org/abs/2310.18715", "authors": [{"last_name": "Zhu", "first_name": "Jin"}, {"last_name": "Wan", "first_name": "Runzhe"}, {"last_name": "Qi", "first_name": "Zhengling"}, {"last_name": "Luo", "first_name": "Shikai"}, {"last_name": "Shi", "first_name": "Chengchun"}], "primary_category": "LG", "categories": ["LG", "", ""], "abstract": "  This paper endeavors to augment the robustness of offline reinforcement\nlearning (RL) in scenarios laden with heavy-tailed rewards, a prevalent\ncircumstance in real-world applications. We propose two algorithmic frameworks,\nROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy\noptimization (OPO), respectively. Central to our frameworks is the strategic\nincorporation of the median-of-means method with offline RL, enabling\nstraightforward uncertainty estimation for the value function estimator. This\nnot only adheres to the principle of pessimism in OPO but also adeptly manages\nheavy-tailed rewards. Theoretical results and extensive experiments demonstrate\nthat our two frameworks outperform existing methods on the logged dataset\nexhibits heavy-tailed reward distributions.\n", "title": "Robust Offline Policy Evaluation and Optimization with Heavy-Tailed\n  Rewards", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18716", "abstract_url": "http://arxiv.org/abs/2310.18716", "authors": [{"last_name": "Ma", "first_name": "Jiangyan"}, {"last_name": "Wang", "first_name": "Yifei"}, {"last_name": "Wang", "first_name": "Yisen"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Spectral embedding is a powerful graph embedding technique that has received\na lot of attention recently due to its effectiveness on Graph Transformers.\nHowever, from a theoretical perspective, the universal expressive power of\nspectral embedding comes at the price of losing two important invariance\nproperties of graphs, sign and basis invariance, which also limits its\neffectiveness on graph data. To remedy this issue, many previous methods\ndeveloped costly approaches to learn new invariants and suffer from high\ncomputation complexity. In this work, we explore a minimal approach that\nresolves the ambiguity issues by directly finding canonical directions for the\neigenvectors, named Laplacian Canonization (LC). As a pure pre-processing\nmethod, LC is light-weighted and can be applied to any existing GNNs. We\nprovide a thorough investigation, from theory to algorithm, on this approach,\nand discover an efficient algorithm named Maximal Axis Projection (MAP) that\nworks for both sign and basis invariance and successfully canonizes more than\n90% of all eigenvectors. Experiments on real-world benchmark datasets like\nZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing\nmethods while bringing minimal computation overhead. Code is available at\nhttps://github.com/PKU-ML/LaplacianCanonization.\n", "title": "Laplacian Canonization: A Minimalist Approach to Sign and Basis\n  Invariant Spectral Embedding", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18717", "abstract_url": "http://arxiv.org/abs/2310.18717", "authors": [{"last_name": "Seddik", "first_name": "Mohamed El Amine"}, {"last_name": "Guillaud", "first_name": "Maxime"}, {"last_name": "Decurninge", "first_name": "Alexis"}, {"last_name": "Goulart", "first_name": "Jos\u00e9 Henrique de Morais"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  This work introduces an asymptotic study of Hotelling-type tensor deflation\nin the presence of noise, in the regime of large tensor dimensions.\nSpecifically, we consider a low-rank asymmetric tensor model of the form\n$\\sum_{i=1}^r \\beta_i{\\mathcal{A}}_i + {\\mathcal{W}}$ where $\\beta_i\\geq 0$ and\nthe ${\\mathcal{A}}_i$'s are unit-norm rank-one tensors such that $\\left|\n\\langle {\\mathcal{A}}_i, {\\mathcal{A}}_j \\rangle \\right| \\in [0, 1]$ for $i\\neq\nj$ and ${\\mathcal{W}}$ is an additive noise term. Assuming that the dominant\ncomponents are successively estimated from the noisy observation and\nsubsequently subtracted, we leverage recent advances in random tensor theory in\nthe regime of asymptotically large tensor dimensions to analytically\ncharacterize the estimated singular values and the alignment of estimated and\ntrue singular vectors at each step of the deflation procedure. Furthermore,\nthis result can be used to construct estimators of the signal-to-noise ratios\n$\\beta_i$ and the alignments between the estimated and true rank-1 signal\ncomponents.\n", "title": "On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random\n  Tensor Analysis", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18718", "abstract_url": "http://arxiv.org/abs/2310.18718", "authors": [{"last_name": "Cla\u00dfen", "first_name": "Henrik"}, {"last_name": "Thierfeldt", "first_name": "Jonas"}, {"last_name": "Tochman-Szewc", "first_name": "Julian"}, {"last_name": "Wiesner", "first_name": "Philipp"}, {"last_name": "Kao", "first_name": "Odej"}], "primary_category": "DC", "categories": ["DC"], "abstract": "  While the environmental impact of digitalization is becoming more and more\nevident, the climate crisis has become a major issue for society. For instance,\ndata centers alone account for 2.7% of Europe's energy consumption today. A\nconsiderable part of this load is accounted for by cloud-based services for\nautomated software development, such as continuous integration and delivery\n(CI/CD) workflows.\n  In this paper, we discuss opportunities and challenges for greening CI/CD\nservices by better aligning their execution with the availability of low-carbon\nenergy. We propose a system architecture for carbon-aware CI/CD services, which\nuses historical runtime information and, optionally, user-provided information.\nWe examined the potential effectiveness of different scheduling strategies\nusing real carbon intensity data and 7,392 workflow executions of Github\nActions, a popular CI/CD service. Our results show, that user-provided\ninformation on workflow deadlines can effectively improve carbon-aware\nscheduling.\n", "title": "Carbon-Awareness in CI/CD", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18720", "abstract_url": "http://arxiv.org/abs/2310.18720", "authors": [{"last_name": "ter Beek", "first_name": "Maurice H."}, {"last_name": "Dubslaff", "first_name": "Clemens"}], "primary_category": "SE", "categories": ["SE", "FL", "LO"], "abstract": "  The analysis of configurable systems, i.e., systems those behaviors depend on\nparameters or support various features, is challenging due to the exponential\nblowup arising in the number of configuration options. This volume contains the\npost-proceedings of TiCSA 2023, the first workshop on Trends in Configurable\nSystems Analysis, where current challenges and solutions in configurable\nsystems analysis were presented and discussed.\n", "title": "Proceedings of the First Workshop on Trends in Configurable Systems\n  Analysis", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18722", "abstract_url": "http://arxiv.org/abs/2310.18722", "authors": [{"last_name": "Denysiuk", "first_name": "Volodymyr"}, {"last_name": "Hryshko", "first_name": "Olena"}], "primary_category": "", "categories": [""], "abstract": "  This article focuses on trigonometric Riemann B-splines and Riemann kernels\nof trigonometric interpolation splines of arbitrary order; it is shown that\ntrigonometric interpolation splines are a convolution of trigonometric\nB-splines with corresponding kernels. Theoretical statements are followed by\nexamples, and the results are applicable in many practical areas.\n", "title": "B-splines and kernels of trigonometric interpolation splines", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18724", "abstract_url": "http://arxiv.org/abs/2310.18724", "authors": [{"last_name": "Ash", "first_name": "Elliott"}, {"last_name": "Goel", "first_name": "Naman"}, {"last_name": "Li", "first_name": "Nianyun"}, {"last_name": "Marangon", "first_name": "Claudia"}, {"last_name": "Sun", "first_name": "Peiyao"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Machine learning based decision-support tools in criminal justice systems are\nsubjects of intense discussions and academic research. There are important open\nquestions about the utility and fairness of such tools. Academic researchers\noften rely on a few small datasets that are not sufficient to empirically study\nvarious real-world aspects of these questions. In this paper, we contribute\nWCLD, a curated large dataset of 1.5 million criminal cases from circuit courts\nin the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020\nto curate attributes like prior criminal counts and recidivism outcomes. The\ndataset contains large number of samples from five racial groups, in addition\nto information like sex and age (at judgment and first offense). Other\nattributes in this dataset include neighborhood characteristics obtained from\ncensus data, detailed types of offense, charge severity, case decisions,\nsentence lengths, year of filing etc. We also provide pseudo-identifiers for\njudge, county and zipcode. The dataset will not only enable researchers to more\nrigorously study algorithmic fairness in the context of criminal justice, but\nalso relate algorithmic challenges with various systemic issues. We also\ndiscuss in detail the process of constructing the dataset and provide a\ndatasheet. The WCLD dataset is available at\n\\url{https://clezdata.github.io/wcld/}.\n", "title": "WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit\n  Courts", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18725", "abstract_url": "http://arxiv.org/abs/2310.18725", "authors": [{"last_name": "Qi", "first_name": "Xuan"}, {"last_name": "Wei", "first_name": "Yi"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  It is commonly recognized that the expressiveness of deep neural networks is\ncontingent upon a range of factors, encompassing their depth, width, and other\nrelevant considerations. Currently, the practical performance of the majority\nof deep neural networks remains uncertain. For ReLU (Rectified Linear Unit)\nnetworks with piecewise linear activations, the number of linear convex regions\nserves as a natural metric to gauge the network's expressivity. In this paper,\nwe count the number of linear convex regions in deep neural networks based on\nReLU. In particular, we prove that for any one-dimensional input, there exists\na minimum threshold for the number of neurons required to express it. We also\nempirically observe that for the same network, intricate inputs hinder its\ncapacity to express linear regions. Furthermore, we unveil the iterative\nrefinement process of decision boundaries in ReLU networks during training. We\naspire for our research to serve as an inspiration for network optimization\nendeavors and aids in the exploration and analysis of the behaviors exhibited\nby deep networks.\n", "title": "The Evolution of the Interplay Between Input Distributions and Linear\n  Regions in Networks", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18727", "abstract_url": "http://arxiv.org/abs/2310.18727", "authors": [{"last_name": "Qing", "first_name": "Huan"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  The latent class model is a powerful tool for identifying latent classes\nwithin populations that share common characteristics for categorical data in\nsocial, psychological, and behavioral sciences. In this article, we propose two\nnew algorithms to estimate a latent class model for categorical data. Our\nalgorithms are developed by using a newly defined regularized Laplacian matrix\ncalculated from the response matrix. We provide theoretical convergence rates\nof our algorithms by considering a sparsity parameter and show that our\nalgorithms stably yield consistent latent class analysis under mild conditions.\nAdditionally, we propose a metric to capture the strength of latent class\nanalysis and several procedures designed based on this metric to infer how many\nlatent classes one should use for real-world categorical data. The efficiency\nand accuracy of our algorithms are verified by extensive simulated experiments,\nand we further apply our algorithms to real-world categorical data with\npromising results.\n", "title": "Latent class analysis by regularized spectral clustering", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18728", "abstract_url": "http://arxiv.org/abs/2310.18728", "authors": [{"last_name": "Wang", "first_name": "Hao"}, {"last_name": "Cheng", "first_name": "Zhi-Qi"}, {"last_name": "Sun", "first_name": "Jingdong"}, {"last_name": "Yang", "first_name": "Xin"}, {"last_name": "Wu", "first_name": "Xiao"}, {"last_name": "Chen", "first_name": "Hongyang"}, {"last_name": "Yang", "first_name": "Yan"}], "primary_category": "LG", "categories": ["LG", "CV", "MM"], "abstract": "  Multi-view or even multi-modal data is appealing yet challenging for\nreal-world applications. Detecting anomalies in multi-view data is a prominent\nrecent research topic. However, most of the existing methods 1) are only\nsuitable for two views or type-specific anomalies, 2) suffer from the issue of\nfusion disentanglement, and 3) do not support online detection after model\ndeployment. To address these challenges, our main ideas in this paper are\nthree-fold: multi-view learning, disentangled representation learning, and\ngenerative model. To this end, we propose dPoE, a novel multi-view variational\nautoencoder model that involves (1) a Product-of-Experts (PoE) layer in\ntackling multi-view data, (2) a Total Correction (TC) discriminator in\ndisentangling view-common and view-specific representations, and (3) a joint\nloss function in wrapping up all components. In addition, we devise theoretical\ninformation bounds to control both view-common and view-specific\nrepresentations. Extensive experiments on six real-world datasets demonstrate\nthat the proposed dPoE outperforms baselines markedly.\n", "title": "Online Multi-view Anomaly Detection with Disentangled Product-of-Experts\n  Modeling", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18729", "abstract_url": "http://arxiv.org/abs/2310.18729", "authors": [{"last_name": "Dr\u00e1pal", "first_name": "Jakub"}, {"last_name": "Westermann", "first_name": "Hannes"}, {"last_name": "Savelka", "first_name": "Jaromir"}], "primary_category": "", "categories": ["", "CL", "HC"], "abstract": "  Thematic analysis and other variants of inductive coding are widely used\nqualitative analytic methods within empirical legal studies (ELS). We propose a\nnovel framework facilitating effective collaboration of a legal expert with a\nlarge language model (LLM) for generating initial codes (phase 2 of thematic\nanalysis), searching for themes (phase 3), and classifying the data in terms of\nthe themes (to kick-start phase 4). We employed the framework for an analysis\nof a dataset (n=785) of facts descriptions from criminal court opinions\nregarding thefts. The goal of the analysis was to discover classes of typical\nthefts. Our results show that the LLM, namely OpenAI's GPT-4, generated\nreasonable initial codes, and it was capable of improving the quality of the\ncodes based on expert feedback. They also suggest that the model performed well\nin zero-shot classification of facts descriptions in terms of the themes.\nFinally, the themes autonomously discovered by the LLM appear to map fairly\nwell to the themes arrived at by legal experts. These findings can be leveraged\nby legal researchers to guide their decisions in integrating LLMs into their\nthematic analyses, as well as other inductive coding projects.\n", "title": "Using Large Language Models to Support Thematic Analysis in Empirical\n  Legal Studies", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18735", "abstract_url": "http://arxiv.org/abs/2310.18735", "authors": [{"last_name": "Zhang", "first_name": "Zheng"}, {"last_name": "Wang", "first_name": "Junxiang"}, {"last_name": "Zhao", "first_name": "Liang"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Graph Neural Networks (GNNs) have achieved great success in representing data\nwith dependencies by recursively propagating and aggregating messages along the\nedges. However, edges in real-world graphs often have varying degrees of\ndifficulty, and some edges may even be noisy to the downstream tasks.\nTherefore, existing GNNs may lead to suboptimal learned representations because\nthey usually treat every edge in the graph equally. On the other hand,\nCurriculum Learning (CL), which mimics the human learning principle of learning\ndata samples in a meaningful order, has been shown to be effective in improving\nthe generalization ability and robustness of representation learners by\ngradually proceeding from easy to more difficult samples during training.\nUnfortunately, existing CL strategies are designed for independent data samples\nand cannot trivially generalize to handle data dependencies. To address these\nissues, we propose a novel CL strategy to gradually incorporate more edges into\ntraining according to their difficulty from easy to hard, where the degree of\ndifficulty is measured by how well the edges are expected given the model\ntraining status. We demonstrate the strength of our proposed method in\nimproving the generalization ability and robustness of learned representations\nthrough extensive experiments on nine synthetic datasets and nine real-world\ndatasets. The code for our proposed method is available at\nhttps://github.com/rollingstonezz/Curriculum_learning_for_GNNs.\n", "title": "Curriculum Learning for Graph Neural Networks: Which Edges Should We\n  Learn First", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18736", "abstract_url": "http://arxiv.org/abs/2310.18736", "authors": [{"last_name": "Gokhale", "first_name": "Kartik"}, {"last_name": "Mallik", "first_name": "Amit Kumar"}, {"last_name": "Misra", "first_name": "Ankit Kumar"}, {"last_name": "Nath", "first_name": "Swaprava"}], "primary_category": "GT", "categories": ["GT", ""], "abstract": "  Stable marriage of a two-sided market with unit demand is a classic problem\nthat arises in many real-world scenarios. In addition, a unique stable marriage\nin this market simplifies a host of downstream desiderata. In this paper, we\nexplore a new set of sufficient conditions for unique stable matching (USM)\nunder this setup. Unlike other approaches that also address this question using\nthe structure of preference profiles, we use an algorithmic viewpoint and\ninvestigate if this question can be answered using the lens of the deferred\nacceptance (DA) algorithm (Gale and Shapley, 1962). Our results yield a set of\nsufficient conditions for USM (viz., MaxProp and MaxRou) and show that these\nare disjoint from the previously known sufficiency conditions like sequential\npreference and no crossing. We also provide a characterization of MaxProp that\nmakes it efficiently verifiable, and shows the gap between MaxProp and the\nentire USM class. These results give a more detailed view of the sub-structures\nof the USM class.\n", "title": "A Gale-Shapley View of Unique Stable Marriages", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18737", "abstract_url": "http://arxiv.org/abs/2310.18737", "authors": [{"last_name": "Haghighat", "first_name": "Maryam"}, {"last_name": "Moghadam", "first_name": "Peyman"}, {"last_name": "Mohamed", "first_name": "Shaheer"}, {"last_name": "Koniusz", "first_name": "Piotr"}], "primary_category": "CV", "categories": ["CV", "", "LG"], "abstract": "  Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual\npre-training without the use of labels. MIM applies random crops to input\nimages, processes them with an encoder, and then recovers the masked inputs\nwith a decoder, which encourages the network to capture and learn structural\ninformation about objects and scenes. The intermediate feature representations\nobtained from MIM are suitable for fine-tuning on downstream tasks. In this\npaper, we propose an Image Modeling framework based on random orthogonal\nprojection instead of binary masking as in MIM. Our proposed Random Orthogonal\nProjection Image Modeling (ROPIM) reduces spatially-wise token information\nunder guaranteed bound on the noise variance and can be considered as masking\nentire spatial image area under locally varying masking degrees. Since ROPIM\nuses a random subspace for the projection that realizes the masking step, the\nreadily available complement of the subspace can be used during unmasking to\npromote recovery of removed information. In this paper, we show that using\nrandom orthogonal projection leads to superior performance compared to\ncrop-based masking. We demonstrate state-of-the-art results on several popular\nbenchmarks.\n", "title": "Pre-training with Random Orthogonal Projection Image Modeling", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18738", "abstract_url": "http://arxiv.org/abs/2310.18738", "authors": [{"last_name": "Wu", "first_name": "Yangjun"}, {"last_name": "Fang", "first_name": "Kebin"}, {"last_name": "Zhang", "first_name": "Dongxiang"}, {"last_name": "Wang", "first_name": "Han"}, {"last_name": "Zhang", "first_name": "Hao"}, {"last_name": "Chen", "first_name": "Gang"}], "primary_category": "CL", "categories": ["CL", "LG"], "abstract": "  Structured dropout approaches, such as attention dropout and DropHead, have\nbeen investigated to regularize the multi-head attention mechanism in\nTransformers. In this paper, we propose a new regularization scheme based on\ntoken-level rather than structure-level to reduce overfitting. Specifically, we\ndevise a novel Token-Level Masking (TLM) training strategy for Transformers to\nregularize the connections of self-attention, which consists of two masking\ntechniques that are effective and easy to implement. The underlying idea is to\nmanipulate the connections between tokens in the multi-head attention via\nmasking, where the networks are forced to exploit partial neighbors'\ninformation to produce a meaningful representation. The generality and\neffectiveness of TLM are thoroughly evaluated via extensive experiments on 4\ndiversified NLP tasks across 18 datasets, including natural language\nunderstanding benchmark GLUE, ChineseGLUE, Chinese Grammatical Error\nCorrection, and data-to-text generation. The results indicate that TLM can\nconsistently outperform attention dropout and DropHead, e.g., it increases by\n0.5 points relative to DropHead with BERT-large on GLUE. Moreover, TLM can\nestablish a new record on the data-to-text benchmark Rotowire (18.93 BLEU). Our\ncode will be publicly available at https://github.com/Young1993/tlm.\n", "title": "TLM: Token-Level Masking for Transformers", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18740", "abstract_url": "http://arxiv.org/abs/2310.18740", "authors": [{"last_name": "Ding", "first_name": "Ruomeng"}, {"last_name": "Zhang", "first_name": "Chaoyun"}, {"last_name": "Wang", "first_name": "Lu"}, {"last_name": "Xu", "first_name": "Yong"}, {"last_name": "Ma", "first_name": "Minghua"}, {"last_name": "Wu", "first_name": "Xiaomin"}, {"last_name": "Zhang", "first_name": "Meng"}, {"last_name": "Chen", "first_name": "Qingjun"}, {"last_name": "Gao", "first_name": "Xin"}, {"last_name": "Gao", "first_name": "Xuedong"}, {"last_name": "Fan", "first_name": "Hao"}, {"last_name": "Rajmohan", "first_name": "Saravan"}, {"last_name": "Lin", "first_name": "Qingwei"}, {"last_name": "Zhang", "first_name": "Dongmei"}], "primary_category": "SE", "categories": ["SE"], "abstract": "  Root Cause Analysis (RCA) is becoming increasingly crucial for ensuring the\nreliability of microservice systems. However, performing RCA on modern\nmicroservice systems can be challenging due to their large scale, as they\nusually comprise hundreds of components, leading significant human effort. This\npaper proposes TraceDiag, an end-to-end RCA framework that addresses the\nchallenges for large-scale microservice systems. It leverages reinforcement\nlearning to learn a pruning policy for the service dependency graph to\nautomatically eliminates redundant components, thereby significantly improving\nthe RCA efficiency. The learned pruning policy is interpretable and fully\nadaptive to new RCA instances. With the pruned graph, a causal-based method can\nbe executed with high accuracy and efficiency. The proposed TraceDiag framework\nis evaluated on real data traces collected from the Microsoft Exchange system,\nand demonstrates superior performance compared to state-of-the-art RCA\napproaches. Notably, TraceDiag has been integrated as a critical component in\nthe Microsoft M365 Exchange, resulting in a significant improvement in the\nsystem's reliability and a considerable reduction in the human effort required\nfor RCA.\n", "title": "TraceDiag: Adaptive, Interpretable, and Efficient Root Cause Analysis on\n  Large-Scale Microservice Systems", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18741", "abstract_url": "http://arxiv.org/abs/2310.18741", "authors": [{"last_name": "Rezk", "first_name": "Fady"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Meta-learning that uses implicit gradient have provided an exciting\nalternative to standard techniques which depend on the trajectory of the inner\nloop training. Implicit meta-learning (IML), however, require computing\n$2^{nd}$ order gradients, particularly the Hessian which is impractical to\ncompute for modern deep learning models. Various approximations for the Hessian\nwere proposed but a systematic comparison of their compute cost, stability,\ngeneralization of solution found and estimation accuracy were largely\noverlooked. In this study, we start by conducting a systematic comparative\nanalysis of the various approximation methods and their effect when\nincorporated into IML training routines. We establish situations where\ncatastrophic forgetting is exhibited in IML and explain their cause in terms of\nthe inability of the approximations to estimate the curvature at convergence\npoints. Sources of IML training instability are demonstrated and remedied. A\ndetailed analysis of the effeciency of various inverse Hessian-vector product\napproximation methods is also provided. Subsequently, we use the insights\ngained to propose and evaluate a novel semi-supervised learning algorithm that\nlearns to inductively weigh consistency regularization losses. We show how\ntraining a \"Confidence Network\" to extract domain specific features can learn\nto up-weigh useful images and down-weigh out-of-distribution samples. Results\noutperform the baseline FixMatch performance.\n", "title": "On Training Implicit Meta-Learning With Applications to Inductive\n  Weighing in Consistency Regularization", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18742", "abstract_url": "http://arxiv.org/abs/2310.18742", "authors": [{"last_name": "Huang", "first_name": "Zezhou"}, {"last_name": "Damalapati", "first_name": "Pavan Kalyan"}, {"last_name": "Wu", "first_name": "Eugene"}], "primary_category": "DB", "categories": ["DB"], "abstract": "  Text-to-SQL allows experts to use databases without in-depth knowledge of\nthem. However, real-world tasks have both query and data ambiguities. Most\nworks on Text-to-SQL focused on query ambiguities and designed chat interfaces\nfor experts to provide clarifications. In contrast, the data management\ncommunity has long studied data ambiguities, but mainly addresses error\ndetection and correction, rather than documenting them for disambiguation in\ndata tasks. This work delves into these data ambiguities in real-world\ndatasets. We have identified prevalent data ambiguities of value consistency,\ndata coverage, and data granularity that affect tasks. We examine how\ndocumentation, originally made to help humans to disambiguate data, can help\nGPT-4 with Text-to-SQL tasks. By offering documentation on these, we found\nGPT-4's performance improved by 28.9%.\n", "title": "Data Ambiguity Strikes Back: How Documentation Improves GPT's\n  Text-to-SQL", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18743", "abstract_url": "http://arxiv.org/abs/2310.18743", "authors": [{"last_name": "Gupte", "first_name": "Sumedh"}, {"last_name": "A.", "first_name": "Prashanth L."}, {"last_name": "Bhat", "first_name": "Sanjay P."}], "primary_category": "LG", "categories": ["LG"], "abstract": "  We consider the problems of estimation and optimization of utility-based\nshortfall risk (UBSR), which is a popular risk measure in finance. In the\ncontext of UBSR estimation, we derive a non-asymptotic bound on the\nmean-squared error of the classical sample average approximation (SAA) of UBSR.\nNext, in the context of UBSR optimization, we derive an expression for the UBSR\ngradient under a smooth parameterization. This expression is a ratio of\nexpectations, both of which involve the UBSR. We use SAA for the numerator as\nwell as denominator in the UBSR gradient expression to arrive at a biased\ngradient estimator. We derive non-asymptotic bounds on the estimation error,\nwhich show that our gradient estimator is asymptotically unbiased. We\nincorporate the aforementioned gradient estimator into a stochastic gradient\n(SG) algorithm for UBSR optimization. Finally, we derive non-asymptotic bounds\nthat quantify the rate of convergence of our SG algorithm for UBSR\noptimization.\n", "title": "Optimization of utility-based shortfall risk: A non-asymptotic viewpoint", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18750", "abstract_url": "http://arxiv.org/abs/2310.18750", "authors": [{"last_name": "Kulikova", "first_name": "Maria"}], "primary_category": "", "categories": ["", "CE"], "abstract": "  This paper suggests a few novel Cholesky-based square-root algorithms for the\nmaximum correntropy criterion Kalman filtering. In contrast to the previously\nobtained results, new algorithms are developed in the so-called {\\it condensed}\nform that corresponds to the {\\it a priori} filtering. Square-root filter\nimplementations are known to possess a better conditioning and improved\nnumerical robustness when solving ill-conditioned estimation problems.\nAdditionally, the new algorithms permit easier propagation of the state\nestimate and do not require a back-substitution for computing the estimate.\nPerformance of novel filtering methods is examined by using a fourth order\nbenchmark navigation system example.\n", "title": "One-step condensed forms for square-root maximum correntropy criterion\n  Kalman filtering", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18752", "abstract_url": "http://arxiv.org/abs/2310.18752", "authors": [{"last_name": "Sui", "first_name": "Guanghu"}, {"last_name": "Li", "first_name": "Zhishuai"}, {"last_name": "Li", "first_name": "Ziyue"}, {"last_name": "Yang", "first_name": "Sun"}, {"last_name": "Ruan", "first_name": "Jingqing"}, {"last_name": "Mao", "first_name": "Hangyu"}, {"last_name": "Zhao", "first_name": "Rui"}], "primary_category": "", "categories": [""], "abstract": "  Previous state-of-the-art (SOTA) method achieved a remarkable execution\naccuracy on the Spider dataset, which is one of the largest and most diverse\ndatasets in the Text-to-SQL domain. However, during our reproduce of the\nbusiness dataset, we observed a significant drop in performance. We examined\nthe differences in dataset complexity, as well as the clarity of questions'\nintentions, and assessed how those differences could impact the performance of\nprompting methods. Subsequently, We develop a more adaptable and more general\nprompting method, involving mainly query rewriting and SQL boosting, which\nrespectively transform vague information into exact and precise information and\nenhance the SQL itself by incorporating execution feedback and the query\nresults from the database content. In order to prevent information gaps, we\ninclude the comments, value types, and value samples for columns as part of the\ndatabase description in the prompt. Our experiments with Large Language Models\n(LLMs) illustrate the significant performance improvement on the business\ndataset and prove the substantial potential of our method. In terms of\nexecution accuracy on the business dataset, the SOTA method scored 21.05, while\nour approach scored 65.79. As a result, our approach achieved a notable\nperformance improvement even when using a less capable pre-trained language\nmodel. Last but not the least, we also explore the Text-to-Python and\nText-to-Function options, and we deeply analyze the pros and cons among them,\noffering valuable insights to the community.\n", "title": "Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and\n  Text-to-Function -- with Real Applications in Traffic Domain", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18753", "abstract_url": "http://arxiv.org/abs/2310.18753", "authors": [{"last_name": "Zarrouki", "first_name": "Baha"}, {"last_name": "Wang", "first_name": "Chenyang"}, {"last_name": "Betz", "first_name": "Johannes"}], "primary_category": "", "categories": ["", "RO"], "abstract": "  Employing Stochastic Nonlinear Model Predictive Control (SNMPC) for real-time\napplications is challenging due to the complex task of propagating\nuncertainties through nonlinear systems. This difficulty becomes more\npronounced in high-dimensional systems with extended prediction horizons, such\nas autonomous vehicles. To enhance closed-loop performance in and feasibility\nin SNMPCs, we introduce the concept of the Uncertainty Propagation Horizon\n(UPH). The UPH limits the time for uncertainty propagation through system\ndynamics, preventing trajectory divergence, optimizing feedback loop\nadvantages, and reducing computational overhead. Our SNMPC approach utilizes\nPolynomial Chaos Expansion (PCE) to propagate uncertainties and incorporates\nnonlinear hard constraints on state expectations and nonlinear probabilistic\nconstraints. We transform the probabilistic constraints into deterministic\nconstraints by estimating the nonlinear constraints' expectation and variance.\nWe then showcase our algorithm's effectiveness in real-time control of a\nhigh-dimensional, highly nonlinear system-the trajectory following of an\nautonomous passenger vehicle, modeled with a dynamic nonlinear single-track\nmodel. Experimental results demonstrate our approach's robust capability to\nfollow an optimal racetrack trajectory at speeds of up to 37.5m/s while dealing\nwith state estimation disturbances, achieving a minimum solving frequency of\n97Hz. Additionally, our experiments illustrate that limiting the UPH renders\npreviously infeasible SNMPC problems feasible, even when incorrect uncertainty\nassumptions or strong disturbances are present.\n", "title": "A Stochastic Nonlinear Model Predictive Control with an Uncertainty\n  Propagation Horizon for Autonomous Vehicle Motion Control", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18762", "abstract_url": "http://arxiv.org/abs/2310.18762", "authors": [{"last_name": "Zhang", "first_name": "Boya"}, {"last_name": "Luo", "first_name": "Weijian"}, {"last_name": "Zhang", "first_name": "Zhihua"}], "primary_category": "LG", "categories": ["LG", "CR"], "abstract": "  Adversarial attacks can mislead neural network classifiers. The defense\nagainst adversarial attacks is important for AI safety. Adversarial\npurification is a family of approaches that defend adversarial attacks with\nsuitable pre-processing. Diffusion models have been shown to be effective for\nadversarial purification. Despite their success, many aspects of diffusion\npurification still remain unexplored. In this paper, we investigate and improve\nupon three limiting designs of diffusion purification: the use of an improved\ndiffusion model, advanced numerical simulation techniques, and optimal control\nof randomness. Based on our findings, we propose Purify++, a new diffusion\npurification algorithm that is now the state-of-the-art purification method\nagainst several adversarial attacks. Our work presents a systematic exploration\nof the limits of diffusion purification methods.\n", "title": "Purify++: Improving Diffusion-Purification with Advanced Diffusion\n  Models and Control of Randomness", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18765", "abstract_url": "http://arxiv.org/abs/2310.18765", "authors": [{"last_name": "Yan", "first_name": "Divin"}, {"last_name": "Wei", "first_name": "Gengchen"}, {"last_name": "Yang", "first_name": "Chen"}, {"last_name": "Zhang", "first_name": "Shengzhong"}, {"last_name": "Huang", "first_name": "Zengfeng"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  This paper introduces a new approach to address the issue of class imbalance\nin graph neural networks (GNNs) for learning on graph-structured data. Our\napproach integrates imbalanced node classification and Bias-Variance\nDecomposition, establishing a theoretical framework that closely relates data\nimbalance to model variance. We also leverage graph augmentation technique to\nestimate the variance, and design a regularization term to alleviate the impact\nof imbalance. Exhaustive tests are conducted on multiple benchmarks, including\nnaturally imbalanced datasets and public-split class-imbalanced datasets,\ndemonstrating that our approach outperforms state-of-the-art methods in various\nimbalanced scenarios. This work provides a novel theoretical perspective for\naddressing the problem of imbalanced node classification in GNNs.\n", "title": "Rethinking Semi-Supervised Imbalanced Node Classification from\n  Bias-Variance Decomposition", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18768", "abstract_url": "http://arxiv.org/abs/2310.18768", "authors": [{"last_name": "Zou", "first_name": "Kaijian"}, {"last_name": "Zhang", "first_name": "Xinliang Frederick"}, {"last_name": "Wu", "first_name": "Winston"}, {"last_name": "Beauchamp", "first_name": "Nick"}, {"last_name": "Wang", "first_name": "Lu"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  News media is expected to uphold unbiased reporting. Yet they may still\naffect public opinion by selectively including or omitting events that support\nor contradict their ideological positions. Prior work in NLP has only studied\nmedia bias via linguistic style and word usage. In this paper, we study to\nwhich degree media balances news reporting and affects consumers through event\ninclusion or omission. We first introduce the task of detecting both partisan\nand counter-partisan events: events that support or oppose the author's\npolitical ideology. To conduct our study, we annotate a high-quality dataset,\nPAC, containing 8,511 (counter-)partisan event annotations in 304 news articles\nfrom ideologically diverse media outlets. We benchmark PAC to highlight the\nchallenges of this task. Our findings highlight both the ways in which the news\nsubtly shapes opinion and the need for large language models that better\nunderstand events within a broader context. Our dataset can be found at\nhttps://github.com/launchnlp/Partisan-Event-Dataset.\n", "title": "Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in\n  News Reporting", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18769", "abstract_url": "http://arxiv.org/abs/2310.18769", "authors": [{"last_name": "McDermott", "first_name": "Luke"}, {"last_name": "Cummings", "first_name": "Daniel"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  With the rise in interest of sparse neural networks, we study how neural\nnetwork pruning with synthetic data leads to sparse networks with unique\ntraining properties. We find that distilled data, a synthetic summarization of\nthe real data, paired with Iterative Magnitude Pruning (IMP) unveils a new\nclass of sparse networks that are more stable to SGD noise on the real data,\nthan either the dense model, or subnetworks found with real data in IMP. That\nis, synthetically chosen subnetworks often train to the same minima, or exhibit\nlinear mode connectivity. We study this through linear interpolation, loss\nlandscape visualizations, and measuring the diagonal of the hessian. While\ndataset distillation as a field is still young, we find that these properties\nlead to synthetic subnetworks matching the performance of traditional IMP with\nup to 150x less training points in settings where distilled data applies.\n", "title": "Linear Mode Connectivity in Sparse Neural Networks", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18770", "abstract_url": "http://arxiv.org/abs/2310.18770", "authors": [{"last_name": "Ma", "first_name": "Yunshan"}, {"last_name": "Liu", "first_name": "Xiaohao"}, {"last_name": "Wei", "first_name": "Yinwei"}, {"last_name": "Tao", "first_name": "Zhulin"}, {"last_name": "Wang", "first_name": "Xiang"}, {"last_name": "Chua", "first_name": "Tat-Seng"}], "primary_category": "IR", "categories": ["IR", "MM", ""], "abstract": "  Automatic bundle construction is a crucial prerequisite step in various\nbundle-aware online services. Previous approaches are mostly designed to model\nthe bundling strategy of existing bundles. However, it is hard to acquire\nlarge-scale well-curated bundle dataset, especially for those platforms that\nhave not offered bundle services before. Even for platforms with mature bundle\nservices, there are still many items that are included in few or even zero\nbundles, which give rise to sparsity and cold-start challenges in the bundle\nconstruction models. To tackle these issues, we target at leveraging multimodal\nfeatures, item-level user feedback signals, and the bundle composition\ninformation, to achieve a comprehensive formulation of bundle construction.\nNevertheless, such formulation poses two new technical challenges: 1) how to\nlearn effective representations by optimally unifying multiple features, and 2)\nhow to address the problems of modality missing, noise, and sparsity problems\ninduced by the incomplete query bundles. In this work, to address these\ntechnical challenges, we propose a Contrastive Learning-enhanced Hierarchical\nEncoder method (CLHE). Specifically, we use self-attention modules to combine\nthe multimodal and multi-item features, and then leverage both item- and\nbundle-level contrastive learning to enhance the representation learning, thus\nto counter the modality missing, noise, and sparsity problems. Extensive\nexperiments on four datasets in two application domains demonstrate that our\nmethod outperforms a list of SOTA methods. The code and dataset are available\nat https://github.com/Xiaohao-Liu/CLHE.\n", "title": "Leveraging Multimodal Features and Item-level User Feedback for Bundle\n  Construction", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18771", "abstract_url": "http://arxiv.org/abs/2310.18771", "authors": [{"last_name": "Nah", "first_name": "Moses C."}, {"last_name": "Lachner", "first_name": "Johannes"}, {"last_name": "Hogan", "first_name": "Neville"}], "primary_category": "RO", "categories": ["RO"], "abstract": "  Motor primitives are fundamental building blocks of a controller which enable\ndynamic robot behavior with minimal high-level intervention. By treating motor\nprimitives as basic \"modules,\" different modules can be sequenced or\nsuperimposed to generate a rich repertoire of motor behavior. In robotics, two\ndistinct approaches have been proposed: Dynamic Movement Primitives (DMPs) and\nElementary Dynamic Actions (EDAs). While both approaches instantiate similar\nideas, significant differences also exist. This paper attempts to clarify the\ndistinction and provide a unifying view by delineating the similarities and\ndifferences between DMPs and EDAs. We provide eight robot control examples,\nincluding sequencing or superimposing movements, managing kinematic redundancy\nand singularity, obstacle avoidance, and managing physical interaction. We show\nthat the two approaches clearly diverge in their implementation. We also\ndiscuss how DMPs and EDAs might be combined to get the best of both approaches.\nWith this detailed comparison, we enable researchers to make informed decisions\nto select the most suitable approach for specific robot tasks and applications.\n", "title": "Robot Control based on Motor Primitives -- A Comparison of Two\n  Approaches", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18772", "abstract_url": "http://arxiv.org/abs/2310.18772", "authors": [{"last_name": "Narayanan", "first_name": "Advaith"}], "primary_category": "LG", "categories": ["LG", "NE"], "abstract": "  The rapidly advancing fields of statistical modeling and machine learning\nhave significantly enhanced data-driven design and optimization. This paper\nfocuses on leveraging these design algorithms to optimize a medical walker, an\nintegral part of gait rehabilitation and physiological therapy of the lower\nextremities. To achieve the desirable qualities of a walker, we train a\npredictive machine-learning model to identify trade-offs between performance\nobjectives, thus enabling the use of efficient optimization algorithms. To do\nthis, we use an Automated Machine Learning model utilizing a stacked-ensemble\napproach shown to outperform traditional ML models. However, training a\npredictive model requires vast amounts of data for accuracy. Due to limited\npublicly available walker designs, this paper presents a dataset of more than\n5,000 parametric walker designs with performance values to assess mass,\nstructural integrity, and stability. These performance values include\ndisplacement vectors for the given load case, stress coefficients, mass, and\nother physical properties. We also introduce a novel method of systematically\ncalculating the stability index of a walker. We use MultiObjective\nCounterfactuals for Design (MCD), a novel genetic-based optimization algorithm,\nto explore the diverse 16-dimensional design space and search for\nhigh-performing designs based on numerous objectives. This paper presents\npotential walker designs that demonstrate up to a 30% mass reduction while\nincreasing structural stability and integrity. This work takes a step toward\nthe improved development of assistive mobility devices.\n", "title": "A Data-driven Recommendation Framework for Optimal Walker Designs", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18773", "abstract_url": "http://arxiv.org/abs/2310.18773", "authors": [{"last_name": "Miyanishi", "first_name": "Taiki"}, {"last_name": "Kitamori", "first_name": "Fumiya"}, {"last_name": "Kurita", "first_name": "Shuhei"}, {"last_name": "Lee", "first_name": "Jungdae"}, {"last_name": "Kawanabe", "first_name": "Motoaki"}, {"last_name": "Inoue", "first_name": "Nakamasa"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  City-scale 3D point cloud is a promising way to express detailed and\ncomplicated outdoor structures. It encompasses both the appearance and geometry\nfeatures of segmented city components, including cars, streets, and buildings,\nthat can be utilized for attractive applications such as user-interactive\nnavigation of autonomous vehicles and drones. However, compared to the\nextensive text annotations available for images and indoor scenes, the scarcity\nof text annotations for outdoor scenes poses a significant challenge for\nachieving these applications. To tackle this problem, we introduce the\nCityRefer dataset for city-level visual grounding. The dataset consists of 35k\nnatural language descriptions of 3D objects appearing in SensatUrban city\nscenes and 5k landmarks labels synchronizing with OpenStreetMap. To ensure the\nquality and accuracy of the dataset, all descriptions and labels in the\nCityRefer dataset are manually verified. We also have developed a baseline\nsystem that can learn encoded language descriptions, 3D object instances, and\ngeographical information about the city's landmarks to perform visual grounding\non the CityRefer dataset. To the best of our knowledge, the CityRefer dataset\nis the largest city-level visual grounding dataset for localizing specific 3D\nobjects.\n", "title": "CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale\n  Point Cloud Data", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18776", "abstract_url": "http://arxiv.org/abs/2310.18776", "authors": [{"last_name": "Nice", "first_name": "Matthew"}, {"last_name": "Bunting", "first_name": "Matt"}, {"last_name": "Richardson", "first_name": "Alex"}, {"last_name": "Zachar", "first_name": "Gergely"}, {"last_name": "Lee", "first_name": "Jonathan W."}, {"last_name": "Bayen", "first_name": "Alexandre"}, {"last_name": "Monache", "first_name": "Maria Laura Delle"}, {"last_name": "Seibold", "first_name": "Benjamin"}, {"last_name": "Piccoli", "first_name": "Benedetto"}, {"last_name": "Sprinkle", "first_name": "Jonathan"}, {"last_name": "Work", "first_name": "Dan"}], "primary_category": "RO", "categories": ["RO"], "abstract": "  We demonstrate a new capability of automated vehicles: mixed autonomy traffic\ncontrol. With this new capability, automated vehicles can shape the traffic\nflows composed of other non-automated vehicles, which has the promise to\nimprove safety, efficiency, and energy outcomes in transportation systems at a\nsocietal scale. Investigating mixed autonomy mobile traffic control must be\ndone in situ given that the complex dynamics of other drivers and their\nresponse to a team of automated vehicles cannot be effectively modeled. This\ncapability has been blocked because there is no existing scalable and\naffordable platform for experimental control. This paper introduces an\nextensible open-source hardware and software platform, enabling a team of 100\nvehicles to execute several different vehicular control algorithms as a\ncollaborative fleet, composed of three different makes and models, which drove\n22752 miles in a combined 1022 hours, over 5 days in Nashville, TN in November\n2022.\n", "title": "Enabling Mixed Autonomy Traffic Control", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18777", "abstract_url": "http://arxiv.org/abs/2310.18777", "authors": [{"last_name": "Ren", "first_name": "Yi"}, {"last_name": "Lavoie", "first_name": "Samuel"}, {"last_name": "Galkin", "first_name": "Mikhail"}, {"last_name": "Sutherland", "first_name": "Danica J."}, {"last_name": "Courville", "first_name": "Aaron"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Compositional generalization, the ability of an agent to generalize to unseen\ncombinations of latent factors, is easy for humans but hard for deep neural\nnetworks. A line of research in cognitive science has hypothesized a process,\n``iterated learning,'' to help explain how human language developed this\nability; the theory rests on simultaneous pressures towards compressibility\n(when an ignorant agent learns from an informed one) and expressivity (when it\nuses the representation for downstream tasks). Inspired by this process, we\npropose to improve the compositional generalization of deep networks by using\niterated learning on models with simplicial embeddings, which can approximately\ndiscretize representations. This approach is further motivated by an analysis\nof compositionality based on Kolmogorov complexity. We show that this\ncombination of changes improves compositional generalization over other\napproaches, demonstrating these improvements both on vision tasks with\nwell-understood latent factors and on real molecular graph prediction tasks\nwhere the latent structure is unknown.\n", "title": "Improving Compositional Generalization Using Iterated Learning and\n  Simplicial Embeddings", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18778", "abstract_url": "http://arxiv.org/abs/2310.18778", "authors": [{"last_name": "Mekki", "first_name": "Abdellah El"}, {"last_name": "Abdul-Mageed", "first_name": "Muhammad"}, {"last_name": "Nagoudi", "first_name": "ElMoatez Billah"}, {"last_name": "Berrada", "first_name": "Ismail"}, {"last_name": "Khoumsi", "first_name": "Ahmed"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Bilingual Lexicon Induction (BLI), where words are translated between two\nlanguages, is an important NLP task. While noticeable progress on BLI in rich\nresource languages using static word embeddings has been achieved. The word\ntranslation performance can be further improved by incorporating information\nfrom contextualized word embeddings. In this paper, we introduce ProMap, a\nnovel approach for BLI that leverages the power of prompting pretrained\nmultilingual and multidialectal language models to address these challenges. To\novercome the employment of subword tokens in these models, ProMap relies on an\neffective padded prompting of language models with a seed dictionary that\nachieves good performance when used independently. We also demonstrate the\neffectiveness of ProMap in re-ranking results from other BLI methods such as\nwith aligned static word embeddings. When evaluated on both rich-resource and\nlow-resource languages, ProMap consistently achieves state-of-the-art results.\nFurthermore, ProMap enables strong performance in few-shot scenarios (even with\nless than 10 training examples), making it a valuable tool for low-resource\nlanguage translation. Overall, we believe our method offers both exciting and\npromising direction for BLI in general and low-resource languages in\nparticular. ProMap code and data are available at\n\\url{https://github.com/4mekki4/promap}.\n", "title": "ProMap: Effective Bilingual Lexicon Induction via Language Model\n  Prompting", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18780", "abstract_url": "http://arxiv.org/abs/2310.18780", "authors": [{"last_name": "Massaroli", "first_name": "Stefano"}, {"last_name": "Poli", "first_name": "Michael"}, {"last_name": "Fu", "first_name": "Daniel Y."}, {"last_name": "Kumbong", "first_name": "Hermann"}, {"last_name": "Parnichkun", "first_name": "Rom N."}, {"last_name": "Timalsina", "first_name": "Aman"}, {"last_name": "Romero", "first_name": "David W."}, {"last_name": "McIntyre", "first_name": "Quinn"}, {"last_name": "Chen", "first_name": "Beidi"}, {"last_name": "Rudra", "first_name": "Atri"}, {"last_name": "Zhang", "first_name": "Ce"}, {"last_name": "Re", "first_name": "Christopher"}, {"last_name": "Ermon", "first_name": "Stefano"}, {"last_name": "Bengio", "first_name": "Yoshua"}], "primary_category": "LG", "categories": ["LG", "", ""], "abstract": "  Recent advances in attention-free sequence models rely on convolutions as\nalternatives to the attention operator at the core of Transformers. In\nparticular, long convolution sequence models have achieved state-of-the-art\nperformance in many domains, but incur a significant cost during\nauto-regressive inference workloads -- naively requiring a full pass (or\ncaching of activations) over the input sequence for each generated token --\nsimilarly to attention-based models. In this paper, we seek to enable $\\mathcal\nO(1)$ compute and memory cost per token in any pre-trained long convolution\narchitecture to reduce memory footprint and increase throughput during\ngeneration. Concretely, our methods consist in extracting low-dimensional\nlinear state-space models from each convolution layer, building upon rational\ninterpolation and model-order reduction techniques. We further introduce\narchitectural improvements to convolution-based layers such as Hyena: by\nweight-tying the filters across channels into heads, we achieve higher\npre-training quality and reduce the number of filters to be distilled. The\nresulting model achieves 10x higher throughput than Transformers and 1.5x\nhigher than Hyena at 1.3B parameters, without any loss in quality after\ndistillation.\n", "title": "Laughing Hyena Distillery: Extracting Compact Recurrences From\n  Convolutions", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18783", "abstract_url": "http://arxiv.org/abs/2310.18783", "authors": [{"last_name": "Zhu", "first_name": "Lixing"}, {"last_name": "Zhao", "first_name": "Runcong"}, {"last_name": "Gui", "first_name": "Lin"}, {"last_name": "He", "first_name": "Yulan"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Narrative understanding involves capturing the author's cognitive processes,\nproviding insights into their knowledge, intentions, beliefs, and desires.\nAlthough large language models (LLMs) excel in generating grammatically\ncoherent text, their ability to comprehend the author's thoughts remains\nuncertain. This limitation hinders the practical applications of narrative\nunderstanding. In this paper, we conduct a comprehensive survey of narrative\nunderstanding tasks, thoroughly examining their key features, definitions,\ntaxonomy, associated datasets, training objectives, evaluation metrics, and\nlimitations. Furthermore, we explore the potential of expanding the\ncapabilities of modularized LLMs to address novel narrative understanding\ntasks. By framing narrative understanding as the retrieval of the author's\nimaginative cues that outline the narrative structure, our study introduces a\nfresh perspective on enhancing narrative comprehension.\n", "title": "Are NLP Models Good at Tracing Thoughts: An Overview of Narrative\n  Understanding", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18784", "abstract_url": "http://arxiv.org/abs/2310.18784", "authors": [{"last_name": "Armacki", "first_name": "Aleksandar"}, {"last_name": "Sharma", "first_name": "Pranay"}, {"last_name": "Joshi", "first_name": "Gauri"}, {"last_name": "Bajovic", "first_name": "Dragana"}, {"last_name": "Jakovetic", "first_name": "Dusan"}, {"last_name": "Kar", "first_name": "Soummya"}], "primary_category": "LG", "categories": ["LG", "", "", ""], "abstract": "  Several recent works have studied the convergence \\textit{in high\nprobability} of stochastic gradient descent (SGD) and its clipped variant.\nCompared to vanilla SGD, clipped SGD is practically more stable and has the\nadditional theoretical benefit of logarithmic dependence on the failure\nprobability. However, the convergence of other practical nonlinear variants of\nSGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved\ncommunication efficiency or accelerated convergence is much less understood. In\nthis work, we study the convergence bounds \\textit{in high probability} of a\nbroad class of nonlinear SGD methods. For strongly convex loss functions with\nLipschitz continuous gradients, we prove a logarithmic dependence on the\nfailure probability, even when the noise is heavy-tailed. Strictly more general\nthan the results for clipped SGD, our results hold for any nonlinearity with\nbounded (component-wise or joint) outputs, such as clipping, normalization, and\nquantization. Further, existing results with heavy-tailed noise assume bounded\n$\\eta$-th central moments, with $\\eta \\in (1,2]$. In contrast, our refined\nanalysis works even for $\\eta=1$, strictly relaxing the noise moment\nassumptions in the literature.\n", "title": "High-probability Convergence Bounds for Nonlinear Stochastic Gradient\n  Descent Under Heavy-tailed Noise", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18786", "abstract_url": "http://arxiv.org/abs/2310.18786", "authors": [{"last_name": "Price", "first_name": "Eric"}, {"last_name": "Zhou", "first_name": "Yihan"}], "primary_category": "LG", "categories": ["LG", "DS"], "abstract": "  For some hypothesis classes and input distributions, active agnostic learning\nneeds exponentially fewer samples than passive learning; for other classes and\ndistributions, it offers little to no improvement. The most popular algorithms\nfor agnostic active learning express their performance in terms of a parameter\ncalled the disagreement coefficient, but it is known that these algorithms are\ninefficient on some inputs.\n  We take a different approach to agnostic active learning, getting an\nalgorithm that is competitive with the optimal algorithm for any binary\nhypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any\nalgorithm can use $m^*$ queries to get $O(\\eta)$ error, then our algorithm uses\n$O(m^* \\log |H|)$ queries to get $O(\\eta)$ error. Our algorithm lies in the\nvein of the splitting-based approach of Dasgupta [2004], which gets a similar\nresult for the realizable ($\\eta = 0$) setting.\n  We also show that it is NP-hard to do better than our algorithm's $O(\\log\n|H|)$ overhead in general.\n", "title": "A Competitive Algorithm for Agnostic Active Learning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18788", "abstract_url": "http://arxiv.org/abs/2310.18788", "authors": [{"last_name": "Asnani", "first_name": "Vishal"}, {"last_name": "Kumar", "first_name": "Abhinav"}, {"last_name": "You", "first_name": "Suya"}, {"last_name": "Liu", "first_name": "Xiaoming"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Previous research in $2D$ object detection focuses on various tasks,\nincluding detecting objects in generic and camouflaged images. These works are\nregarded as passive works for object detection as they take the input image as\nis. However, convergence to global minima is not guaranteed to be optimal in\nneural networks; therefore, we argue that the trained weights in the object\ndetector are not optimal. To rectify this problem, we propose a wrapper based\non proactive schemes, PrObeD, which enhances the performance of these object\ndetectors by learning a signal. PrObeD consists of an encoder-decoder\narchitecture, where the encoder network generates an image-dependent signal\ntermed templates to encrypt the input images, and the decoder recovers this\ntemplate from the encrypted images. We propose that learning the optimum\ntemplate results in an object detector with an improved detection performance.\nThe template acts as a mask to the input images to highlight semantics useful\nfor the object detector. Finetuning the object detector with these encrypted\nimages enhances the detection performance for both generic and camouflaged. Our\nexperiments on MS-COCO, CAMO, COD$10$K, and NC$4$K datasets show improvement\nover different detectors after applying PrObeD. Our models/codes are available\nat https://github.com/vishal3477/Proactive-Object-Detection.\n", "title": "PrObeD: Proactive Object Detection Wrapper", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18789", "abstract_url": "http://arxiv.org/abs/2310.18789", "authors": [{"last_name": "Ponce", "first_name": "Ignacio"}, {"last_name": "Milano", "first_name": "Federico"}], "primary_category": "", "categories": [""], "abstract": "  The concept of complex frequency has been recently introduced on the IEEE\nTransactions on Power Systems to study bus voltage variations in magnitude and\nfrequency and their link with complex power injections of a power system. In\nthis paper, the complex frequency is applied to time-varying series\nconnections, namely, RLC dynamic branches, regulating transformers and AC/DC\nconverters. The proposed modeling approach allows deriving an explicit\nexpression for the complex frequency of the voltage of a certain bus as a\nlinear combination of three elements: net current injected by the devices\nconnected to the bus, adjacent voltages, and time-varying series branches. The\nproposed formulation unifies the link between voltage and frequency dynamics in\nAC, DC, as well as hybrid AC/DC power systems. A variety of static and dynamic\nexamples are presented to show the potential of the proposed formulation.\nRelevant applications of the proposed modeling approach are outlined.\n", "title": "Modeling Hybrid AC/DC Power Systems with the Complex Frequency Concept", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18791", "abstract_url": "http://arxiv.org/abs/2310.18791", "authors": [{"last_name": "Kapoor", "first_name": "Parv"}, {"last_name": "Chu", "first_name": "Simon"}, {"last_name": "Chen", "first_name": "Angela"}], "primary_category": "RO", "categories": ["RO", "", "HC", ""], "abstract": "  Trust has been shown to be a key factor in effective human-robot\ncollaboration. In the context of assistive robotics, the effect of trust\nfactors on human experience is further pronounced. Personalization of assistive\nrobots is an orthogonal factor positively correlated with robot adoption and\nuser perceptions. In this work, we investigate the relationship between these\nfactors through a within-subjects study (N=17). We provide different levels of\ncustomization possibilities over baseline autonomous robot behavior and\ninvestigate its impact on trust. Our findings indicate that increased levels of\ncustomization was associated with higher trust and comfort perceptions. The\nassistive robot design process can benefit significantly from our insights for\ndesigning trustworthy and customized robots.\n", "title": "\"Do it my way!\": Impact of Customizations on Trust perceptions in\n  Human-Robot Collaboration", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18792", "abstract_url": "http://arxiv.org/abs/2310.18792", "authors": [{"last_name": "Chantal", "first_name": "Mutimukwe"}, {"last_name": "Shengnan", "first_name": "Han"}, {"last_name": "Olga", "first_name": "Viberg"}, {"last_name": "Teresa", "first_name": "Cerratto-Pargman"}], "primary_category": "CY", "categories": ["CY"], "abstract": "  Privacy is one of the key challenges to the adoption and implementation of\nonline proctoring systems in higher education. To better understand this\nchallenge, we adopt privacy as contextual integrity theory to conduct a scoping\nreview of 17 papers. The results show different types of students' personal and\nsensitive information are collected and disseminated; this raises considerable\nprivacy concerns. As well as the governing principles including transparency\nand fairness, consent and choice, information minimization, accountability, and\ninformation security and accuracy have been identified to address privacy\nproblems. This study notifies a need to clarify how these principles should be\nimplemented and sustained, and what privacy concerns and actors they relate to.\nFurther, it calls for the need to clarify the responsibility of key actors in\nenacting and sustaining responsible adoption and use of OPS in higher\neducation.\n", "title": "Privacy as Contextual Integrity in Online Proctoring Systems in Higher\n  Education: A Scoping Review", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18794", "abstract_url": "http://arxiv.org/abs/2310.18794", "authors": [{"last_name": "Wan", "first_name": "Yixin"}, {"last_name": "Wu", "first_name": "Fanyou"}, {"last_name": "Xu", "first_name": "Weijie"}, {"last_name": "Sengamedu", "first_name": "Srinivasan H."}], "primary_category": "CL", "categories": ["CL", ""], "abstract": "  Model hallucination has been a crucial interest of research in Natural\nLanguage Generation (NLG). In this work, we propose sequence-level certainty as\na common theme over hallucination in NLG, and explore the correlation between\nsequence-level certainty and the level of hallucination in model responses. We\ncategorize sequence-level certainty into two aspects: probabilistic certainty\nand semantic certainty, and reveal through experiments on Knowledge-Grounded\nDialogue Generation (KGDG) task that both a higher level of probabilistic\ncertainty and a higher level of semantic certainty in model responses are\nsignificantly correlated with a lower level of hallucination. What's more, we\nprovide theoretical proof and analysis to show that semantic certainty is a\ngood estimator of probabilistic certainty, and therefore has the potential as\nan alternative to probability-based certainty estimation in black-box\nscenarios. Based on the observation on the relationship between certainty and\nhallucination, we further propose Certainty-based Response Ranking (CRR), a\ndecoding-time method for mitigating hallucination in NLG. Based on our\ncategorization of sequence-level certainty, we propose 2 types of CRR approach:\nProbabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually\nsampled model responses using their arithmetic mean log-probability of the\nentire sequence. S-CRR approaches certainty estimation from meaning-space, and\nranks a number of model response candidates based on their semantic certainty\nlevel, which is estimated by the entailment-based Agreement Score (AS). Through\nextensive experiments across 3 KGDG datasets, 3 decoding methods, and on 4\ndifferent models, we validate the effectiveness of our 2 proposed CRR methods\nto reduce model hallucination.\n", "title": "Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded\n  Dialogue Generation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18795", "abstract_url": "http://arxiv.org/abs/2310.18795", "authors": [{"last_name": "Ramezani", "first_name": "Farzaneh"}, {"last_name": "Bolhasani", "first_name": "Hamidreza"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Tinnitus is a prevalent hearing disorder that can be caused by various\nfactors such as age, hearing loss, exposure to loud noises, ear infections or\ntumors, certain medications, head or neck injuries, and psychological\nconditions like anxiety and depression. While not every patient requires\nmedical attention, about 20% of sufferers seek clinical intervention. Early\ndiagnosis is crucial for effective treatment. New developments have been made\nin tinnitus detection to aid in early detection of this illness. Over the past\nfew years, there has been a notable growth in the usage of\nelectroencephalography (EEG) to study variations in oscillatory brain activity\nrelated to tinnitus. However, the results obtained from numerous studies vary\ngreatly, leading to conflicting conclusions. Currently, clinicians rely solely\non their expertise to identify individuals with tinnitus. Researchers in this\nfield have incorporated various data modalities and machine-learning techniques\nto aid clinicians in identifying tinnitus characteristics and classifying\npeople with tinnitus. The purpose of writing this article is to review articles\nthat focus on using machine learning (ML) to identify or predict tinnitus\npatients using EEG signals as input data. We have evaluated 11 articles\npublished between 2016 and 2023 using a systematic literature review (SLR)\nmethod. This article arranges perfect summaries of all the research reviewed\nand compares the significant aspects of each. Additionally, we performed\nstatistical analyses to gain a deeper comprehension of the most recent research\nin this area. Almost all of the reviewed articles followed a five-step\nprocedure to achieve the goal of tinnitus. Disclosure. Finally, we discuss the\nopen affairs and challenges in this method of tinnitus recognition or\nprediction and suggest future directions for research.\n", "title": "A Review on the Applications of Machine Learning for Tinnitus Diagnosis\n  Using EEG Signals", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18801", "abstract_url": "http://arxiv.org/abs/2310.18801", "authors": [{"last_name": "Fang", "first_name": "Xu"}, {"last_name": "Xie", "first_name": "Lihua"}, {"last_name": "Li", "first_name": "Xiaolei"}], "primary_category": "", "categories": [""], "abstract": "  This paper studies the problem of integrated distributed network localization\nand formation maneuver control. We develop an integrated\nrelative-measurement-based scheme, which only uses relative positions,\ndistances, bearings, angles, ratio-of-distances, or their combination to\nachieve distributed network localization and formation maneuver control in\n$\\mathbb{R}^d (d \\ge 2)$. By exploring the localizability and invariance of the\ntarget formation, the scale, rotation, and translation of the formation can be\ncontrolled simultaneously by only tuning the leaders' positions, i.e., the\nfollowers do not need to know parameters of the scale, rotation, and\ntranslation of the target formation. The proposed method can globally drive the\nformation errors to zero in finite time over multi-layer $d\\!+\\!1$-rooted\ngraphs. A simulation example is given to illustrate the theoretical results.\n", "title": "Integrated Relative-Measurement-Based Network Localization and Formation\n  Maneuver Control", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18802", "abstract_url": "http://arxiv.org/abs/2310.18802", "authors": [{"last_name": "Gawlik", "first_name": "Evan S."}, {"last_name": "Neunteufel", "first_name": "Michael"}], "primary_category": "", "categories": ["", "", ""], "abstract": "  We construct and analyze finite element approximations of the Einstein tensor\nin dimension $N \\ge 3$. We focus on the setting where a smooth Riemannian\nmetric tensor $g$ on a polyhedral domain $\\Omega \\subset \\mathbb{R}^N$ has been\napproximated by a piecewise polynomial metric $g_h$ on a simplicial\ntriangulation $\\mathcal{T}$ of $\\Omega$ having maximum element diameter $h$. We\nassume that $g_h$ possesses single-valued tangential-tangential components on\nevery codimension-1 simplex in $\\mathcal{T}$. Such a metric is not classically\ndifferentiable in general, but it turns out that one can still attribute\nmeaning to its Einstein curvature in a distributional sense. We study the\nconvergence of the distributional Einstein curvature of $g_h$ to the Einstein\ncurvature of $g$ under refinement of the triangulation. We show that in the\n$H^{-2}(\\Omega)$-norm, this convergence takes place at a rate of $O(h^{r+1})$\nwhen $g_h$ is an optimal-order interpolant of $g$ that is piecewise polynomial\nof degree $r \\ge 1$. We provide numerical evidence to support this claim.\n", "title": "Finite element approximation of the Einstein tensor", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18803", "abstract_url": "http://arxiv.org/abs/2310.18803", "authors": [{"last_name": "Shar", "first_name": "Ibrahim El"}, {"last_name": "Jiang", "first_name": "Daniel R."}], "primary_category": "LG", "categories": ["LG"], "abstract": "  We propose weakly coupled deep Q-networks (WCDQN), a novel deep reinforcement\nlearning algorithm that enhances performance in a class of structured problems\ncalled weakly coupled Markov decision processes (WCMDP). WCMDPs consist of\nmultiple independent subproblems connected by an action space constraint, which\nis a structural property that frequently emerges in practice. Despite this\nappealing structure, WCMDPs quickly become intractable as the number of\nsubproblems grows. WCDQN employs a single network to train multiple DQN\n\"subagents\", one for each subproblem, and then combine their solutions to\nestablish an upper bound on the optimal action value. This guides the main DQN\nagent towards optimality. We show that the tabular version, weakly coupled\nQ-learning (WCQL), converges almost surely to the optimal action value.\nNumerical experiments show faster convergence compared to DQN and related\ntechniques in settings with as many as 10 subproblems, $3^{10}$ total actions,\nand a continuous state space.\n", "title": "Weakly Coupled Deep Q-Networks", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18804", "abstract_url": "http://arxiv.org/abs/2310.18804", "authors": [{"last_name": "Cui", "first_name": "Hejie"}, {"last_name": "Fang", "first_name": "Xinyu"}, {"last_name": "Zhang", "first_name": "Zihan"}, {"last_name": "Xu", "first_name": "Ran"}, {"last_name": "Kan", "first_name": "Xuan"}, {"last_name": "Liu", "first_name": "Xin"}, {"last_name": "Yu", "first_name": "Yue"}, {"last_name": "Li", "first_name": "Manling"}, {"last_name": "Song", "first_name": "Yangqiu"}, {"last_name": "Yang", "first_name": "Carl"}], "primary_category": "CL", "categories": ["CL", "", "CV", "LG"], "abstract": "  Images contain rich relational knowledge that can help machines understand\nthe world. Existing methods on visual knowledge extraction often rely on the\npre-defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation\ntypes), restricting the expressiveness of the extracted knowledge. In this\nwork, we take a first exploration to a new paradigm of open visual knowledge\nextraction. To achieve this, we present OpenVik which consists of an open\nrelational region detector to detect regions potentially containing relational\nknowledge and a visual knowledge generator that generates format-free knowledge\nby prompting the large multimodality model with the detected region of\ninterest. We also explore two data enhancement techniques for diversifying the\ngenerated format-free visual knowledge. Extensive knowledge quality evaluations\nhighlight the correctness and uniqueness of the extracted open visual knowledge\nby OpenVik. Moreover, integrating our extracted knowledge across various visual\nreasoning applications shows consistent improvements, indicating the real-world\napplicability of OpenVik.\n", "title": "Open Visual Knowledge Extraction via Relation-Oriented Multimodality\n  Model Prompting", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18805", "abstract_url": "http://arxiv.org/abs/2310.18805", "authors": [{"last_name": "McCarter", "first_name": "Calvin"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  We report the effects of replacing the scaled dot-product (within softmax)\nattention with the negative-log of Euclidean distance. This form of attention\nsimplifies to inverse distance weighting interpolation. Used in simple one\nhidden layer networks and trained with vanilla cross-entropy loss on\nclassification problems, it tends to produce a key matrix containing prototypes\nand a value matrix with corresponding logits. We also show that the resulting\ninterpretable networks can be augmented with manually-constructed prototypes to\nperform low-impact handling of special cases.\n", "title": "Inverse distance weighting attention", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18807", "abstract_url": "http://arxiv.org/abs/2310.18807", "authors": [{"last_name": "Assouel", "first_name": "Rim"}, {"last_name": "Rodriguez", "first_name": "Pau"}, {"last_name": "Taslakian", "first_name": "Perouz"}, {"last_name": "Vazquez", "first_name": "David"}, {"last_name": "Bengio", "first_name": "Yoshua"}], "primary_category": "", "categories": ["", "CV"], "abstract": "  A key aspect of human intelligence is the ability to imagine -- composing\nlearned concepts in novel ways -- to make sense of new scenarios. Such capacity\nis not yet attained for machine learning systems. In this work, in the context\nof visual reasoning, we show how modularity can be leveraged to derive a\ncompositional data augmentation framework inspired by imagination. Our method,\ndenoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes\nvisual generative reasoning tasks into a series of primitives applied to\nobjects without using a domain-specific language. We show that our modular\narchitectural choices can be used to generate new training tasks that lead to\nbetter out-of-distribution generalization. We compare our model to existing and\nnew baselines in proposed visual reasoning benchmark that consists of applying\narithmetic operations to MNIST digits.\n", "title": "OC-NMN: Object-centric Compositional Neural Module Network for\n  Generative Visual Analogical Reasoning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18811", "abstract_url": "http://arxiv.org/abs/2310.18811", "authors": [{"last_name": "Abbas", "first_name": "Ammar N."}, {"last_name": "Chasparis", "first_name": "Georgios C."}, {"last_name": "Kelleher", "first_name": "John D."}], "primary_category": "", "categories": ["", "LG", ""], "abstract": "  The difficulty of identifying the physical model of complex systems has led\nto exploring methods that do not rely on such complex modeling of the systems.\nDeep reinforcement learning has been the pioneer for solving this problem\nwithout the need for relying on the physical model of complex systems by just\ninteracting with it. However, it uses a black-box learning approach that makes\nit difficult to be applied within real-world and safety-critical systems\nwithout providing explanations of the actions derived by the model.\nFurthermore, an open research question in deep reinforcement learning is how to\nfocus the policy learning of critical decisions within a sparse domain. This\npaper proposes a novel approach for the use of deep reinforcement learning in\nsafety-critical systems. It combines the advantages of probabilistic modeling\nand reinforcement learning with the added benefits of interpretability and\nworks in collaboration and synchronization with conventional decision-making\nstrategies. The BC-SRLA is activated in specific situations which are\nidentified autonomously through the fused information of probabilistic model\nand reinforcement learning, such as abnormal conditions or when the system is\nnear-to-failure. Further, it is initialized with a baseline policy using policy\ncloning to allow minimum interactions with the environment to address the\nchallenges associated with using RL in safety-critical industries. The\neffectiveness of the BC-SRLA is demonstrated through a case study in\nmaintenance applied to turbofan engines, where it shows superior performance to\nthe prior art and other baselines.\n", "title": "Hierarchical Framework for Interpretable and Probabilistic Model-Based\n  Safe Reinforcement Learning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18812", "abstract_url": "http://arxiv.org/abs/2310.18812", "authors": [{"last_name": "Crawford", "first_name": "Jennifer"}, {"last_name": "Yin", "first_name": "Haoli"}, {"last_name": "McDermott", "first_name": "Luke"}, {"last_name": "Cummings", "first_name": "Daniel"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Multimodal Re-Identification (ReID) is a popular retrieval task that aims to\nre-identify objects across diverse data streams, prompting many researchers to\nintegrate multiple modalities into a unified representation. While such fusion\npromises a holistic view, our investigations shed light on potential pitfalls.\nWe uncover that prevailing late-fusion techniques often produce suboptimal\nlatent representations when compared to methods that train modalities in\nisolation. We argue that this effect is largely due to the inadvertent\nrelaxation of the training objectives on individual modalities when using\nfusion, what others have termed modality laziness. We present a nuanced\npoint-of-view that this relaxation can lead to certain modalities failing to\nfully harness available task-relevant information, and yet, offers a protective\nveil to noisy modalities, preventing them from overfitting to task-irrelevant\ndata. Our findings also show that unimodal concatenation (UniCat) and other\nlate-fusion ensembling of unimodal backbones, when paired with best-known\ntraining techniques, exceed the current state-of-the-art performance across\nseveral multimodal ReID benchmarks. By unveiling the double-edged sword of\n\"modality laziness\", we motivate future research in balancing local modality\nstrengths with global representations.\n", "title": "UniCat: Crafting a Stronger Fusion Baseline for Multimodal\n  Re-Identification", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18813", "abstract_url": "http://arxiv.org/abs/2310.18813", "authors": [{"last_name": "Su", "first_name": "Qidong"}, {"last_name": "Giannoula", "first_name": "Christina"}, {"last_name": "Pekhimenko", "first_name": "Gennady"}], "primary_category": "LG", "categories": ["LG", "DC"], "abstract": "  Large Language Models (LLMs) like GPT are state-of-the-art text generation\nmodels that provide significant assistance in daily routines. However, LLM\nexecution is inherently sequential, since they only produce one token at a\ntime, thus incurring low hardware utilization on modern GPUs. Batching and\nspeculative decoding are two techniques to improve GPU hardware utilization in\nLLM inference. To study their synergy, we implement a prototype implementation\nand perform an extensive characterization analysis on various LLM models and\nGPU architectures. We observe that the optimal speculation length depends on\nthe batch size used. We analyze the key observation and build a quantitative\nmodel to explain it. Based on our analysis, we propose a new adaptive\nspeculative decoding strategy that chooses the optimal speculation length for\ndifferent batch sizes. Our evaluations show that our proposed method can\nachieve equal or better performance than the state-of-the-art speculation\ndecoding schemes with fixed speculation length.\n", "title": "The Synergy of Speculative Decoding and Batching in Serving Large\n  Language Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18814", "abstract_url": "http://arxiv.org/abs/2310.18814", "authors": [{"last_name": "Wang", "first_name": "Yan"}, {"last_name": "Wu", "first_name": "Huaiqing"}, {"last_name": "Nettleton", "first_name": "Dan"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  We establish stability of random forests under the mild condition that the\nsquared response ($Y^2$) does not have a heavy tail. In particular, our\nanalysis holds for the practical version of random forests that is implemented\nin popular packages like \\texttt{randomForest} in \\texttt{R}. Empirical results\nshow that stability may persist even beyond our assumption and hold for\nheavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic\nlower bound for the coverage probability of prediction intervals constructed\nfrom the out-of-bag error of random forests. With another mild condition that\nis typically satisfied when $Y$ is continuous, we also establish a\ncomplementary upper bound, which can be similarly established for the jackknife\nprediction interval constructed from an arbitrary stable algorithm. We also\ndiscuss the asymptotic coverage probability under assumptions weaker than those\nconsidered in previous literature. Our work implies that random forests, with\nits stability property, is an effective machine learning method that can\nprovide not only satisfactory point prediction but also justified interval\nprediction at almost no extra computational cost.\n", "title": "Stability of Random Forests and Coverage of Random-Forest Prediction\n  Intervals", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18815", "abstract_url": "http://arxiv.org/abs/2310.18815", "authors": [{"last_name": "Saha", "first_name": "Pramit"}, {"last_name": "Mishra", "first_name": "Divyanshu"}, {"last_name": "Noble", "first_name": "J. Alison"}], "primary_category": "LG", "categories": ["LG", "", "CV"], "abstract": "  The most challenging, yet practical, setting of semi-supervised federated\nlearning (SSFL) is where a few clients have fully labeled data whereas the\nother clients have fully unlabeled data. This is particularly common in\nhealthcare settings where collaborating partners (typically hospitals) may have\nimages but not annotations. The bottleneck in this setting is the joint\ntraining of labeled and unlabeled clients as the objective function for each\nclient varies based on the availability of labels. This paper investigates an\nalternative way for effective training with labeled and unlabeled clients in a\nfederated setting. We propose a novel learning scheme specifically designed for\nSSFL which we call Isolated Federated Learning (IsoFed) that circumvents the\nproblem by avoiding simple averaging of supervised and semi-supervised models\ntogether. In particular, our training approach consists of two parts - (a)\nisolated aggregation of labeled and unlabeled client models, and (b) local\nself-supervised pretraining of isolated global models in all clients. We\nevaluate our model performance on medical image datasets of four different\nmodalities publicly available within the biomedical image classification\nbenchmark MedMNIST. We further vary the proportion of labeled clients and the\ndegree of heterogeneity to demonstrate the effectiveness of the proposed method\nunder varied experimental settings.\n", "title": "Rethinking Semi-Supervised Federated Learning: How to co-train\n  fully-labeled and fully-unlabeled client imaging data", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18816", "abstract_url": "http://arxiv.org/abs/2310.18816", "authors": [{"last_name": "Bao", "first_name": "Wenxuan"}, {"last_name": "Wei", "first_name": "Tianxin"}, {"last_name": "Wang", "first_name": "Haohan"}, {"last_name": "He", "first_name": "Jingrui"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Personalized federated learning algorithms have shown promising results in\nadapting models to various distribution shifts. However, most of these methods\nrequire labeled data on testing clients for personalization, which is usually\nunavailable in real-world scenarios. In this paper, we introduce a novel\nsetting called test-time personalized federated learning (TTPFL), where clients\nlocally adapt a global model in an unsupervised way without relying on any\nlabeled data during test-time. While traditional test-time adaptation (TTA) can\nbe used in this scenario, most of them inherently assume training data come\nfrom a single domain, while they come from multiple clients (source domains)\nwith different distributions. Overlooking these domain interrelationships can\nresult in suboptimal generalization. Moreover, most TTA algorithms are designed\nfor a specific kind of distribution shift and lack the flexibility to handle\nmultiple kinds of distribution shifts in FL. In this paper, we find that this\nlack of flexibility partially results from their pre-defining which modules to\nadapt in the model. To tackle this challenge, we propose a novel algorithm\ncalled ATP to adaptively learns the adaptation rates for each module in the\nmodel from distribution shifts among source domains. Theoretical analysis\nproves the strong generalization of ATP. Extensive experiments demonstrate its\nsuperiority in handling various distribution shifts including label shift,\nimage corruptions, and domain shift, outperforming existing TTA methods across\nmultiple datasets and model architectures. Our code is available at\nhttps://github.com/baowenxuan/ATP .\n", "title": "Adaptive Test-Time Personalization for Federated Learning", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18820", "abstract_url": "http://arxiv.org/abs/2310.18820", "authors": [{"last_name": "Lakshminarayana", "first_name": "Subhash"}, {"last_name": "Maple", "first_name": "Carsten"}, {"last_name": "Larkins", "first_name": "Andrew"}, {"last_name": "Flack", "first_name": "Daryl"}, {"last_name": "Few", "first_name": "Christopher"}, {"last_name": "Srivastava", "first_name": "Anurag. K."}], "primary_category": "CR", "categories": ["CR", "IT", ""], "abstract": "  The growing adoption of Internet-of-Things (IoT)-enabled energy smart\nappliances (ESAs) at the consumer end, such as smart heat pumps, electric\nvehicle chargers, etc., is seen as key to enabling demand-side response (DSR)\nservices. However, these smart appliances are often poorly engineered from a\nsecurity point of view and present a new threat to power grid operations. They\nmay become convenient entry points for malicious parties to gain access to the\nsystem and disrupt important grid operations by abruptly changing the demand.\nUnlike utility-side and SCADA assets, ESAs are not monitored continuously due\nto their large numbers and the lack of extensive monitoring infrastructure at\nconsumer sites. This article presents an in-depth analysis of the demand side\nthreats to power grid operations including (i) an overview of the\nvulnerabilities in ESAs and the wider risk from the DSR ecosystem and (ii) key\nfactors influencing the attack impact on power grid operations. Finally, it\npresents measures to improve the cyber-physical resilience of power grids,\nputting them in the context of ongoing efforts from the industry and regulatory\nbodies worldwide.\n", "title": "Demand-Side Threats to Power Grid Operations from IoT-Enabled Edge", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18823", "abstract_url": "http://arxiv.org/abs/2310.18823", "authors": [{"last_name": "Jiang", "first_name": "Chao"}, {"last_name": "Hui", "first_name": "Bo"}, {"last_name": "Liu", "first_name": "Bohan"}, {"last_name": "Yan", "first_name": "Da"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Despite the success of diffusion models, the training and inference of\ndiffusion models are notoriously expensive due to the long chain of the reverse\nprocess. In parallel, the Lottery Ticket Hypothesis (LTH) claims that there\nexists winning tickets (i.e., aproperly pruned sub-network together with\noriginal weight initialization) that can achieve performance competitive to the\noriginal dense neural network when trained in isolation. In this work, we for\nthe first time apply LTH to diffusion models. We empirically find subnetworks\nat sparsity 90%-99% without compromising performance for denoising diffusion\nprobabilistic models on benchmarks (CIFAR-10, CIFAR-100, MNIST). Moreover,\nexisting LTH works identify the subnetworks with a unified sparsity along\ndifferent layers. We observe that the similarity between two winning tickets of\na model varies from block to block. Specifically, the upstream layers from two\nwinning tickets for a model tend to be more similar than the downstream layers.\nTherefore, we propose to find the winning ticket with varying sparsity along\ndifferent layers in the model. Experimental results demonstrate that our method\ncan find sparser sub-models that require less memory for storage and reduce the\nnecessary number of FLOPs. Codes are available at\nhttps://github.com/osier0524/Lottery-Ticket-to-DDPM.\n", "title": "Successfully Applying Lottery Ticket Hypothesis to Diffusion Model", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18824", "abstract_url": "http://arxiv.org/abs/2310.18824", "authors": [{"last_name": "Robert-Nicoud", "first_name": "Daniel"}, {"last_name": "Krause", "first_name": "Andreas"}, {"last_name": "Borovitskiy", "first_name": "Viacheslav"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Various applications ranging from robotics to climate science require\nmodeling signals on non-Euclidean domains, such as the sphere. Gaussian process\nmodels on manifolds have recently been proposed for such tasks, in particular\nwhen uncertainty quantification is needed. In the manifold setting,\nvector-valued signals can behave very differently from scalar-valued ones, with\nmuch of the progress so far focused on modeling the latter. The former,\nhowever, are crucial for many applications, such as modeling wind speeds or\nforce fields of unknown dynamical systems. In this paper, we propose novel\nGaussian process models for vector-valued signals on manifolds that are\nintrinsically defined and account for the geometry of the space in\nconsideration. We provide computational primitives needed to deploy the\nresulting Hodge-Mat\\'ern Gaussian vector fields on the two-dimensional sphere\nand the hypertori. Further, we highlight two generalization directions:\ndiscrete two-dimensional meshes and \"ideal\" manifolds like hyperspheres, Lie\ngroups, and homogeneous spaces. Finally, we show that our Gaussian vector\nfields constitute considerably more refined inductive biases than the extrinsic\nfields proposed before.\n", "title": "Intrinsic Gaussian Vector Fields on Manifolds", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18825", "abstract_url": "http://arxiv.org/abs/2310.18825", "authors": [{"last_name": "Ortiz-Arroyo", "first_name": "Daniel"}], "primary_category": "", "categories": ["", "NE"], "abstract": "  During the last decades, a myriad of fuzzy time series models have been\nproposed in scientific literature. Among the most accurate models found in\nfuzzy time series, the high-order ones are the most accurate. The research\ndescribed in this paper tackles three potential limitations associated with the\napplication of high-order fuzzy time series models. To begin with, the adequacy\nof forecast rules lacks consistency. Secondly, as the model's order increases,\ndata utilization diminishes. Thirdly, the uniformity of forecast rules proves\nto be highly contingent on the chosen interval partitions. To address these\nlikely drawbacks, we introduce a novel model based on fuzzy time series that\namalgamates the principles of particle swarm optimization (PSO) and weighted\nsummation. Our results show that our approach models accurately the time series\nin comparison with previous methods.\n", "title": "A Fuzzy Time Series-Based Model Using Particle Swarm Optimization and\n  Weighted Rules", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18827", "abstract_url": "http://arxiv.org/abs/2310.18827", "authors": [{"last_name": "Liu", "first_name": "Yujian"}, {"last_name": "Zhang", "first_name": "Xinliang Frederick"}, {"last_name": "Zou", "first_name": "Kaijian"}, {"last_name": "Huang", "first_name": "Ruihong"}, {"last_name": "Beauchamp", "first_name": "Nick"}, {"last_name": "Wang", "first_name": "Lu"}], "primary_category": "CL", "categories": ["CL", ""], "abstract": "  Public opinion is shaped by the information news media provide, and that\ninformation in turn may be shaped by the ideological preferences of media\noutlets. But while much attention has been devoted to media bias via overt\nideological language or topic selection, a more unobtrusive way in which the\nmedia shape opinion is via the strategic inclusion or omission of partisan\nevents that may support one side or the other. We develop a latent\nvariable-based framework to predict the ideology of news articles by comparing\nmultiple articles on the same story and identifying partisan events whose\ninclusion or omission reveals ideology. Our experiments first validate the\nexistence of partisan event selection, and then show that article alignment and\ncross-document comparison detect partisan events and article ideology better\nthan competitive baselines. Our results reveal the high-level form of media\nbias, which is present even among mainstream media with strong norms of\nobjectivity and nonpartisanship. Our codebase and dataset are available at\nhttps://github.com/launchnlp/ATC.\n", "title": "All Things Considered: Detecting Partisan Events from News Media with\n  Cross-Article Comparison", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18830", "abstract_url": "http://arxiv.org/abs/2310.18830", "authors": [{"last_name": "Jalota", "first_name": "Rricha"}, {"last_name": "Chowdhury", "first_name": "Koel Dutta"}, {"last_name": "Espa\u00f1a-Bonet", "first_name": "Cristina"}, {"last_name": "van Genabith", "first_name": "Josef"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Translated texts exhibit systematic linguistic differences compared to\noriginal texts in the same language, and these differences are referred to as\ntranslationese. Translationese has effects on various cross-lingual natural\nlanguage processing tasks, potentially leading to biased results. In this\npaper, we explore a novel approach to reduce translationese in translated\ntexts: translation-based style transfer. As there are no parallel\nhuman-translated and original data in the same language, we use a\nself-supervised approach that can learn from comparable (rather than parallel)\nmono-lingual original and translated data. However, even this self-supervised\napproach requires some parallel data for validation. We show how we can\neliminate the need for parallel validation data by combining the\nself-supervised loss with an unsupervised loss. This unsupervised loss\nleverages the original language model loss over the style-transferred output\nand a semantic similarity loss between the input and style-transferred output.\nWe evaluate our approach in terms of original vs. translationese binary\nclassification in addition to measuring content preservation and target-style\nfluency. The results show that our approach is able to reduce translationese\nclassifier accuracy to a level of a random classifier after style transfer\nwhile adequately preserving the content and fluency in the target original\nstyle.\n", "title": "Translating away Translationese without Parallel Data", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18831", "abstract_url": "http://arxiv.org/abs/2310.18831", "authors": [{"last_name": "Dvo\u0159\u00e1k", "first_name": "Tom\u00e1\u0161"}, {"last_name": "Gu", "first_name": "Mei-Mei"}], "primary_category": "DM", "categories": ["DM", "", "", ""], "abstract": "  The burnt pancake graph $BP_n$ is the Cayley graph of the hyperoctahedral\ngroup using prefix reversals as generators. Let $\\{u,v\\}$ and $\\{x,y\\}$ be any\ntwo pairs of distinct vertices of $BP_n$ for $n\\geq 4$. We show that there are\n$u-v$ and $x-y$ paths whose vertices partition the vertex set of $BP_n$ even if\n$BP_n$ has up to $n-4$ faulty elements. On the other hand, for every $n\\ge3$\nthere is a set of $n-2$ faulty edges or faulty vertices for which such a\nfault-free disjoint path cover does not exist.\n", "title": "Paired 2-disjoint path covers of burnt pancake graphs with faulty\n  elements", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18832", "abstract_url": "http://arxiv.org/abs/2310.18832", "authors": [{"last_name": "Gupta", "first_name": "Yash"}, {"last_name": "Zhai", "first_name": "Runtian"}, {"last_name": "Suggala", "first_name": "Arun"}, {"last_name": "Ravikumar", "first_name": "Pradeep"}], "primary_category": "", "categories": [""], "abstract": "  Several recent works have studied the societal effects of AI; these include\nissues such as fairness, robustness, and safety. In many of these objectives, a\nlearner seeks to minimize its worst-case loss over a set of predefined\ndistributions (known as uncertainty sets), with usual examples being perturbed\nversions of the empirical distribution. In other words, aforementioned problems\ncan be written as min-max problems over these uncertainty sets. In this work,\nwe provide a general framework for studying these problems, which we refer to\nas Responsible AI (RAI) games. We provide two classes of algorithms for solving\nthese games: (a) game-play based algorithms, and (b) greedy stagewise\nestimation algorithms. The former class is motivated by online learning and\ngame theory, whereas the latter class is motivated by the classical statistical\nliterature on boosting, and regression. We empirically demonstrate the\napplicability and competitive performance of our techniques for solving several\nRAI problems, particularly around subpopulation shift.\n", "title": "Responsible AI (RAI) Games and Ensembles", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18833", "abstract_url": "http://arxiv.org/abs/2310.18833", "authors": [{"last_name": "Alemansour", "first_name": "Hamed"}, {"last_name": "Moheimani", "first_name": "S. O. Reza"}], "primary_category": "", "categories": [""], "abstract": "  The invention of scanning tunneling microscope (STM) dates back to the work\nof Binnig and Rohrer in the early 1980s, whose seminal contribution was\nrewarded by the 1986 Nobel Prize in Physics for the design of the scanning\ntunneling microscope. Forty years later, the STM remains the best existing tool\nfor studying electronic, chemical, and physical properties of conducting and\nsemiconducting surfaces with atomic precision. It has opened entirely new\nfields of research, enabling scientists to gain invaluable insight into\nproperties and structure of matter at the atomic scale. Recent breakthroughs in\nSTM-based automated hydrogen depassivation lithography (HDL) on silicon have\nresulted in the STM being considered a viable tool for fabrication of\nerror-free silicon-based quantum-electronic devices. Despite the STM's unique\nability to interrogate and manipulate matter with atomic precision, it remains\na challenging tool to use. It turns out that many issues can be traced back to\nthe STM's feedback control system, which has remained essentially unchanged\nsince its invention about 40 years ago. This article explains the role of\nfeedback control system of the STM and reviews some of the recent progress made\npossible in imaging, spectroscopy, and lithography by making appropriate\nchanges to the STM's feedback control loop. We believe that the full potential\nof the STM is yet to be realized, and the key to new innovations will be the\napplication of advanced model-based control and estimation techniques to this\nsystem.\n", "title": "Model-based Control of the Scanning Tunneling Microscope: Enabling New\n  Modes of Imaging, Spectroscopy, and Lithography", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18834", "abstract_url": "http://arxiv.org/abs/2310.18834", "authors": [{"last_name": "Cotroneo", "first_name": "Domenico"}, {"last_name": "Foggia", "first_name": "Alessio"}, {"last_name": "Improta", "first_name": "Cristina"}, {"last_name": "Liguori", "first_name": "Pietro"}, {"last_name": "Natella", "first_name": "Roberto"}], "primary_category": "SE", "categories": ["SE", ""], "abstract": "  In this paper, we propose a fully automated method, named ACCA, to evaluate\nthe correctness of AI-generated code for security purposes. The method uses\nsymbolic execution to assess whether the AI-generated code behaves as a\nreference implementation. We use ACCA to assess four state-of-the-art models\ntrained to generate security-oriented assembly code and compare the results of\nthe evaluation with different baseline solutions, including output similarity\nmetrics, widely used in the field, and the well-known ChatGPT, the AI-powered\nlanguage model developed by OpenAI. Our experiments show that our method\noutperforms the baseline solutions and assesses the correctness of the\nAI-generated code similar to the human-based evaluation, which is considered\nthe ground truth for the assessment in the field. Moreover, ACCA has a very\nstrong correlation with human evaluation (Pearson's correlation coefficient\nr=0.84 on average). Finally, since it is a fully automated solution that does\nnot require any human intervention, the proposed method performs the assessment\nof every code snippet in ~0.17s on average, which is definitely lower than the\naverage time required by human analysts to manually inspect the code, based on\nour experience.\n", "title": "Automating the Correctness Assessment of AI-generated Code for Security\n  Contexts", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18839", "abstract_url": "http://arxiv.org/abs/2310.18839", "authors": [{"last_name": "Mahdi", "first_name": "Syed Sarosh"}, {"last_name": "Ullah", "first_name": "Zaib"}, {"last_name": "Battineni", "first_name": "Gopi"}, {"last_name": "Babar", "first_name": "Muneer Gohar"}, {"last_name": "Daood", "first_name": "Umer"}], "primary_category": "CR", "categories": ["CR"], "abstract": "  Blockchain technology provides a secure and decentralized platform for\nstoring and transferring sensitive medical data, which can be utilized to\nenable remote medical consultations. This paper proposes a theoretical\nframework for creating a blockchain-based digital entity to facilitate\ntelemedicine services. The proposed framework utilizes blockchain technology to\nprovide a secure and reliable platform for medical practitioners to remotely\ninteract with patient transactions. The blockchain will serve as a one-stop\ndigital service to secure patient data, ensure privacy, and facilitate\npayments. The proposed framework leverages the existing Hyperledger Fabric\nplatform to build a secure blockchain-assisted telemedicine platform.\n", "title": "The Telehealth Chain: a protocol for secure and transparent telemedicine\n  transactions on the blockchain", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18840", "abstract_url": "http://arxiv.org/abs/2310.18840", "authors": [{"last_name": "Wang", "first_name": "Hai"}, {"last_name": "Xiang", "first_name": "Xiaoyu"}, {"last_name": "Fan", "first_name": "Yuchen"}, {"last_name": "Xue", "first_name": "Jing-Hao"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Personalized text-to-image (T2I) synthesis based on diffusion models has\nattracted significant attention in recent research. However, existing methods\nprimarily concentrate on customizing subjects or styles, neglecting the\nexploration of global geometry. In this study, we propose an approach that\nfocuses on the customization of 360-degree panoramas, which inherently possess\nglobal geometric properties, using a T2I diffusion model. To achieve this, we\ncurate a paired image-text dataset specifically designed for the task and\nsubsequently employ it to fine-tune a pre-trained T2I diffusion model with\nLoRA. Nevertheless, the fine-tuned model alone does not ensure the continuity\nbetween the leftmost and rightmost sides of the synthesized images, a crucial\ncharacteristic of 360-degree panoramas. To address this issue, we propose a\nmethod called StitchDiffusion. Specifically, we perform pre-denoising\noperations twice at each time step of the denoising process on the stitch block\nconsisting of the leftmost and rightmost image regions. Furthermore, a global\ncropping is adopted to synthesize seamless 360-degree panoramas. Experimental\nresults demonstrate the effectiveness of our customized model combined with the\nproposed StitchDiffusion in generating high-quality 360-degree panoramic\nimages. Moreover, our customized model exhibits exceptional generalization\nability in producing scenes unseen in the fine-tuning dataset. Code is\navailable at https://github.com/littlewhitesea/StitchDiffusion.\n", "title": "Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18841", "abstract_url": "http://arxiv.org/abs/2310.18841", "authors": [{"last_name": "Li", "first_name": "Shuyao"}, {"last_name": "Wright", "first_name": "Stephen J."}], "primary_category": "", "categories": ["", "LG"], "abstract": "  We consider minimization of a smooth nonconvex function with inexact oracle\naccess to gradient and Hessian (but not the function value) to achieve\n$(\\epsilon_{g}, \\epsilon_{H})$-approximate second-order optimality. A novel\nfeature of our method is that if an approximate direction of negative curvature\nis chosen as the step, we choose its sense to be positive or negative with\nequal probability. We also use relative inexactness measures on gradient and\nHessian and relax the coupling between the first- and second-order tolerances\n$\\epsilon_{g}$ and $\\epsilon_{H}$. Our convergence analysis includes both an\nexpectation bound based on martingale analysis and a high-probability bound\nbased on concentration inequalities. We apply our algorithm to empirical risk\nminimization problems and obtain gradient sample complexity.\n", "title": "A randomized algorithm for nonconvex minimization with inexact\n  evaluations and complexity guarantees", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18844", "abstract_url": "http://arxiv.org/abs/2310.18844", "authors": [{"last_name": "Tiwari", "first_name": "Mo"}, {"last_name": "Kang", "first_name": "Ryan"}, {"last_name": "Lee", "first_name": "Donghyun"}, {"last_name": "Thrun", "first_name": "Sebastian"}, {"last_name": "Piech", "first_name": "Chris"}, {"last_name": "Shomorony", "first_name": "Ilan"}, {"last_name": "Zhang", "first_name": "Martin Jinye"}], "primary_category": "LG", "categories": ["LG", "", "", "", "", "", "", ""], "abstract": "  Clustering is a fundamental task in data science with wide-ranging\napplications. In $k$-medoids clustering, cluster centers must be actual\ndatapoints and arbitrary distance metrics may be used; these features allow for\ngreater interpretability of the cluster centers and the clustering of exotic\nobjects in $k$-medoids clustering, respectively. $k$-medoids clustering has\nrecently grown in popularity due to the discovery of more efficient $k$-medoids\nalgorithms. In particular, recent research has proposed BanditPAM, a randomized\n$k$-medoids algorithm with state-of-the-art complexity and clustering accuracy.\nIn this paper, we present BanditPAM++, which accelerates BanditPAM via two\nalgorithmic improvements, and is $O(k)$ faster than BanditPAM in complexity and\nsubstantially faster than BanditPAM in wall-clock runtime. First, we\ndemonstrate that BanditPAM has a special structure that allows the reuse of\nclustering information $\\textit{within}$ each iteration. Second, we demonstrate\nthat BanditPAM has additional structure that permits the reuse of information\n$\\textit{across}$ different iterations. These observations inspire our proposed\nalgorithm, BanditPAM++, which returns the same clustering solutions as\nBanditPAM but often several times faster. For example, on the CIFAR10 dataset,\nBanditPAM++ returns the same results as BanditPAM but runs over 10$\\times$\nfaster. Finally, we provide a high-performance C++ implementation of\nBanditPAM++, callable from Python and R, that may be of interest to\npractitioners at https://github.com/motiwari/BanditPAM. Auxiliary code to\nreproduce all of our experiments via a one-line script is available at\nhttps://github.com/ThrunGroup/BanditPAM_plusplus_experiments.\n", "title": "BanditPAM++: Faster $k$-medoids Clustering", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18845", "abstract_url": "http://arxiv.org/abs/2310.18845", "authors": [{"last_name": "Garcia", "first_name": "Rita"}, {"last_name": "Treude", "first_name": "Christoph"}, {"last_name": "Valentine", "first_name": "Andrew"}], "primary_category": "SE", "categories": ["SE"], "abstract": "  Collaboration is used in Software Engineering (SE) to develop software.\nIndustry seeks SE graduates with collaboration skills to contribute to\nproductive software development. SE educators can use Collaborative Learning\n(CL) to help students develop collaboration skills. This paper uses a\nSystematic Mapping Study (SMS) to examine the application of the CL educational\ntheory in SE Education. The SMS identified 14 papers published between 2011 and\n2022. We used qualitative analysis to classify the papers into four CL\nparadigms: Conditions, Effect, Interactions, and Computer-Supported\nCollaborative Learning (CSCL). We found a high interest in CSCL, with a shift\nin student interaction research to computer-mediated technologies. We discussed\nthe 14 papers in depth, describing their goals and further analysing the CSCL\nresearch. Almost half the papers did not achieve the appropriate level of\nsupporting evidence; however, calibrating the instruments presented could\nstrengthen findings and support multiple CL paradigms, especially opportunities\nto learn at the social and community levels, where research was lacking. Though\nour results demonstrate limited CL educational theory applied in SE Education,\nwe discuss future work to layer the theory on existing study designs for more\neffective teaching strategies.\n", "title": "Application of Collaborative Learning Paradigms within Software\n  Engineering Education: A Systematic Mapping Study", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18846", "abstract_url": "http://arxiv.org/abs/2310.18846", "authors": [{"last_name": "Kazerouni", "first_name": "Amirhossein"}, {"last_name": "Azad", "first_name": "Reza"}, {"last_name": "Hosseini", "first_name": "Alireza"}, {"last_name": "Merhof", "first_name": "Dorit"}, {"last_name": "Bagci", "first_name": "Ulas"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Implicit Neural Representations (INRs) have revolutionized signal\nrepresentation by leveraging neural networks to provide continuous and smooth\nrepresentations of complex data. However, existing INRs face limitations in\ncapturing fine-grained details, handling noise, and adapting to diverse signal\ntypes. To address these challenges, we introduce INCODE, a novel approach that\nenhances the control of the sinusoidal-based activation function in INRs using\ndeep prior knowledge. INCODE comprises a harmonizer network and a composer\nnetwork, where the harmonizer network dynamically adjusts key parameters of the\nactivation function. Through a task-specific pre-trained model, INCODE adapts\nthe task-specific parameters to optimize the representation process. Our\napproach not only excels in representation, but also extends its prowess to\ntackle complex tasks such as audio, image, and 3D shape reconstructions, as\nwell as intricate challenges such as neural radiance fields (NeRFs), and\ninverse problems, including denoising, super-resolution, inpainting, and CT\nreconstruction. Through comprehensive experiments, INCODE demonstrates its\nsuperiority in terms of robustness, accuracy, quality, and convergence rate,\nbroadening the scope of signal representation. Please visit the project's\nwebsite for details on the proposed method and access to the code.\n", "title": "INCODE: Implicit Neural Conditioning with Prior Knowledge Embeddings", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18847", "abstract_url": "http://arxiv.org/abs/2310.18847", "authors": [{"last_name": "Liu", "first_name": "Chen"}, {"last_name": "Lekkala", "first_name": "Kiran"}, {"last_name": "Itti", "first_name": "Laurent"}], "primary_category": "RO", "categories": ["RO", "LG"], "abstract": "  Sim2Real transfer has gained popularity because it helps transfer from\ninexpensive simulators to real world. This paper presents a novel system that\nfuses components in a traditional \\textit{World Model} into a robust system,\ntrained entirely within a simulator, that \\textit{Zero-Shot} transfers to the\nreal world. To facilitate transfer, we use an intermediary representation that\nare based on \\textit{Bird's Eye View (BEV)} images. Thus, our robot learns to\nnavigate in a simulator by first learning to translate from complex\n\\textit{First-Person View (FPV)} based RGB images to BEV representations, then\nlearning to navigate using those representations. Later, when tested in the\nreal world, the robot uses the perception model that translates FPV-based RGB\nimages to embeddings that are used by the downstream policy. The incorporation\nof state-checking modules using \\textit{Anchor images} and \\textit{Mixture\nDensity LSTM} not only interpolates uncertain and missing observations but also\nenhances the robustness of the model when exposed to the real-world\nenvironment. We trained the model using data collected using a\n\\textit{Differential drive} robot in the CARLA simulator. Our methodology's\neffectiveness is shown through the deployment of trained models onto a\n\\textit{Real world Differential drive} robot. Lastly we release a comprehensive\ncodebase, dataset and models for training and deployment that are available to\nthe public.\n", "title": "World Model Based Sim2Real Transfer for Visual Navigation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18849", "abstract_url": "http://arxiv.org/abs/2310.18849", "authors": [{"last_name": "Seleem", "first_name": "Abdelrahman"}, {"last_name": "Guarda", "first_name": "Andr\u00e9 F. R."}, {"last_name": "Rodrigues", "first_name": "Nuno M. M."}, {"last_name": "Pereira", "first_name": "Fernando"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  In the current golden age of multimedia, human visualization is no longer the\nsingle main target, with the final consumer often being a machine which\nperforms some processing or computer vision tasks. In both cases, deep learning\nplays a undamental role in extracting features from the multimedia\nrepresentation data, usually producing a compressed representation referred to\nas latent representation. The increasing development and adoption of deep\nlearning-based solutions in a wide area of multimedia applications have opened\nan exciting new vision where a common compressed multimedia representation is\nused for both man and machine. The main benefits of this vision are two-fold:\ni) improved performance for the computer vision tasks, since the effects of\ncoding artifacts are mitigated; and ii) reduced computational complexity, since\nprior decoding is not required. This paper proposes the first taxonomy for\ndesigning compressed domain computer vision solutions driven by the\narchitecture and weights compatibility with an available spatio-temporal\ncomputer vision processor. The potential of the proposed taxonomy is\ndemonstrated for the specific case of point cloud classification by designing\nnovel compressed domain processors using the JPEG Pleno Point Cloud Coding\nstandard under development and adaptations of the PointGrid classifier.\nExperimental results show that the designed compressed domain point cloud\nclassification solutions can significantly outperform the spatial-temporal\ndomain classification benchmarks when applied to the decompressed data,\ncontaining coding artifacts, and even surpass their performance when applied to\nthe original uncompressed data.\n", "title": "Deep Learning-based Compressed Domain Multimedia for Man and Machine: A\n  Taxonomy and Application to Point Cloud Classification", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18850", "abstract_url": "http://arxiv.org/abs/2310.18850", "authors": [{"last_name": "Mo", "first_name": "Shentong"}, {"last_name": "Sun", "first_name": "Zhun"}, {"last_name": "Li", "first_name": "Chao"}], "primary_category": "CV", "categories": ["CV", "", "LG"], "abstract": "  Data augmentation has become a standard component of vision pre-trained\nmodels to capture the invariance between augmented views. In practice,\naugmentation techniques that mask regions of a sample with zero/mean values or\npatches from other samples are commonly employed in pre-trained models with\nself-/semi-/fully-supervised contrastive losses. However, the underlying\nmechanism behind the effectiveness of these augmentation techniques remains\npoorly explored. To investigate the problems, we conduct an empirical study to\nquantify how data augmentation affects performance. Concretely, we apply 4\ntypes of data augmentations termed with Random Erasing, CutOut, CutMix and\nMixUp to a series of self-/semi-/fully- supervised pre-trained models. We\nreport their performance on vision tasks such as image classification, object\ndetection, instance segmentation, and semantic segmentation. We then explicitly\nevaluate the invariance and diversity of the feature embedding. We observe\nthat: 1) Masking regions of the images decreases the invariance of the learned\nfeature embedding while providing a more considerable diversity. 2) Manual\nannotations do not change the invariance or diversity of the learned feature\nembedding. 3) The MixUp approach improves the diversity significantly, with\nonly a marginal decrease in terms of the invariance.\n", "title": "Exploring Data Augmentations on Self-/Semi-/Fully- Supervised\n  Pre-trained Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18852", "abstract_url": "http://arxiv.org/abs/2310.18852", "authors": [{"last_name": "Yakaboski", "first_name": "Chase"}, {"last_name": "Hyde", "first_name": "Gregory"}, {"last_name": "Nyanhongo", "first_name": "Clement"}, {"last_name": "Santos Jr", "first_name": "Eugene"}], "primary_category": "", "categories": [""], "abstract": "  AI for Science (AI4Science), particularly in the form of self-driving labs,\nhas the potential to sideline human involvement and hinder scientific discovery\nwithin the broader community. While prior research has focused on ensuring the\nresponsible deployment of AI applications, enhancing security, and ensuring\ninterpretability, we also propose that promoting openness in AI4Science\ndiscoveries should be carefully considered. In this paper, we introduce the\nconcept of AI for Open Science (AI4OS) as a multi-agent extension of AI4Science\nwith the core principle of maximizing open knowledge translation throughout the\nscientific enterprise rather than a single organizational unit. We use the\nestablished principles of Knowledge Discovery and Data Mining (KDD) to\nformalize a language around AI4OS. We then discuss three principle stages of\nknowledge translation embedded in AI4Science systems and detail specific points\nwhere openness can be applied to yield an AI4OS alternative. Lastly, we\nformulate a theoretical metric to assess AI4OS with a supporting ethical\nargument highlighting its importance. Our goal is that by drawing attention to\nAI4OS we can ensure the natural consequence of AI4Science (e.g., self-driving\nlabs) is a benefit not only for its developers but for society as a whole.\n", "title": "AI for Open Science: A Multi-Agent Perspective for Ethically Translating\n  Data to Knowledge", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18859", "abstract_url": "http://arxiv.org/abs/2310.18859", "authors": [{"last_name": "Du", "first_name": "Zhixu"}, {"last_name": "Li", "first_name": "Shiyu"}, {"last_name": "Wu", "first_name": "Yuhao"}, {"last_name": "Jiang", "first_name": "Xiangyu"}, {"last_name": "Sun", "first_name": "Jingwei"}, {"last_name": "Zheng", "first_name": "Qilin"}, {"last_name": "Wu", "first_name": "Yongkai"}, {"last_name": "Li", "first_name": "Ang"}, {"last_name": "Li", "first_name": "Hai \"Helen\""}, {"last_name": "Chen", "first_name": "Yiran"}], "primary_category": "LG", "categories": ["LG", "DC"], "abstract": "  Mixture-of-Experts (MoE) has emerged as a favorable architecture in the era\nof large models due to its inherent advantage, i.e., enlarging model capacity\nwithout incurring notable computational overhead. Yet, the realization of such\nbenefits often results in ineffective GPU memory utilization, as large portions\nof the model parameters remain dormant during inference. Moreover, the memory\ndemands of large models consistently outpace the memory capacity of\ncontemporary GPUs. Addressing this, we introduce SiDA (Sparsity-inspired\nData-Aware), an efficient inference approach tailored for large MoE models.\nSiDA judiciously exploits both the system's main memory, which is now abundant\nand readily scalable, and GPU memory by capitalizing on the inherent sparsity\non expert activation in MoE models. By adopting a data-aware perspective, SiDA\nachieves enhanced model efficiency with a neglectable performance drop.\nSpecifically, SiDA attains a remarkable speedup in MoE inference with up to\n3.93X throughput increasing, up to 75% latency reduction, and up to 80% GPU\nmemory saving with down to 1% performance drop. This work paves the way for\nscalable and efficient deployment of large MoE models, even in\nmemory-constrained systems.\n", "title": "SiDA: Sparsity-Inspired Data-Aware Serving for Efficient and Scalable\n  Large Mixture-of-Experts Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18860", "abstract_url": "http://arxiv.org/abs/2310.18860", "authors": [{"last_name": "Tew", "first_name": "Shu Yu"}, {"last_name": "Boley", "first_name": "Mario"}, {"last_name": "Schmidt", "first_name": "Daniel F."}], "primary_category": "", "categories": ["", "LG"], "abstract": "  We present a novel method for tuning the regularization hyper-parameter,\n$\\lambda$, of a ridge regression that is faster to compute than leave-one-out\ncross-validation (LOOCV) while yielding estimates of the regression parameters\nof equal, or particularly in the setting of sparse covariates, superior quality\nto those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from\nmultiple and bad local minima for finite $n$ and thus requires the\nspecification of a set of candidate $\\lambda$, which can fail to provide good\nsolutions. In contrast, we show that the proposed method is guaranteed to find\na unique optimal solution for large enough $n$, under relatively mild\nconditions, without requiring the specification of any difficult to determine\nhyper-parameters. This is based on a Bayesian formulation of ridge regression\nthat we prove to have a unimodal posterior for large enough $n$, allowing for\nboth the optimal $\\lambda$ and the regression coefficients to be jointly\nlearned within an iterative expectation maximization (EM) procedure.\nImportantly, we show that by utilizing an appropriate preprocessing step, a\nsingle iteration of the main EM loop can be implemented in $O(\\min(n, p))$\noperations, for input data with $n$ rows and $p$ columns. In contrast,\nevaluating a single value of $\\lambda$ using fast LOOCV costs $O(n \\min(n, p))$\noperations when using the same preprocessing. This advantage amounts to an\nasymptotic improvement of a factor of $l$ for $l$ candidate values for\n$\\lambda$ (in the regime $q, p \\in O(\\sqrt{n})$ where $q$ is the number of\nregression targets).\n", "title": "Bayes beats Cross Validation: Efficient and Accurate Ridge Regression\n  via Expectation Maximization", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18861", "abstract_url": "http://arxiv.org/abs/2310.18861", "authors": [{"last_name": "Pranav", "first_name": "Srinivasa"}, {"last_name": "Moura", "first_name": "Jos\u00e9 M. F."}], "primary_category": "LG", "categories": ["LG", "DC"], "abstract": "  We present P2PL, a practical multi-device peer-to-peer deep learning\nalgorithm that, unlike the federated learning paradigm, does not require\ncoordination from edge servers or the cloud. This makes P2PL well-suited for\nthe sheer scale of beyond-5G computing environments like smart cities that\notherwise create range, latency, bandwidth, and single point of failure issues\nfor federated approaches.\n  P2PL introduces max norm synchronization to catalyze training, retains\non-device deep model training to preserve privacy, and leverages local\ninter-device communication to implement distributed consensus. Each device\niteratively alternates between two phases: 1) on-device learning and 2)\ndistributed cooperation where they combine model parameters with nearby\ndevices. We empirically show that all participating devices achieve the same\ntest performance attained by federated and centralized training -- even with\n100 devices and relaxed singly stochastic consensus weights. We extend these\nexperimental results to settings with diverse network topologies, sparse and\nintermittent communication, and non-IID data distributions.\n", "title": "Peer-to-Peer Deep Learning for Beyond-5G IoT", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18862", "abstract_url": "http://arxiv.org/abs/2310.18862", "authors": [{"last_name": "Srinivasan", "first_name": "Anirudh"}, {"last_name": "Govindarajan", "first_name": "Venkata S"}, {"last_name": "Mahowald", "first_name": "Kyle"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Techniques in causal analysis of language models illuminate how linguistic\ninformation is organized in LLMs. We use one such technique, AlterRep, a method\nof counterfactual probing, to explore the internal structure of multilingual\nmodels (mBERT and XLM-R). We train a linear classifier on a binary language\nidentity task, to classify tokens between Language X and Language Y. Applying a\ncounterfactual probing procedure, we use the classifier weights to project the\nembeddings into the null space and push the resulting embeddings either in the\ndirection of Language X or Language Y. Then we evaluate on a masked language\nmodeling task. We find that, given a template in Language X, pushing towards\nLanguage Y systematically increases the probability of Language Y words, above\nand beyond a third-party control language. But it does not specifically push\nthe model towards translation-equivalent words in Language Y. Pushing towards\nLanguage X (the same direction as the template) has a minimal effect, but\nsomewhat degrades these models. Overall, we take these results as further\nevidence of the rich structure of massive multilingual language models, which\ninclude both a language-specific and language-general component. And we show\nthat counterfactual probing can be fruitfully applied to multilingual models.\n", "title": "Counterfactually Probing Language Identity in Multilingual Models", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18863", "abstract_url": "http://arxiv.org/abs/2310.18863", "authors": [{"last_name": "Hosseinmardi", "first_name": "Homa"}, {"last_name": "Wolken", "first_name": "Samuel"}, {"last_name": "Rothschild", "first_name": "David M."}, {"last_name": "Watts", "first_name": "Duncan J."}], "primary_category": "IR", "categories": ["IR", "CY", ""], "abstract": "  The potential for a large, diverse population to coexist peacefully is\nthought to depend on the existence of a ``shared reality:'' a public sphere in\nwhich participants are exposed to similar facts about similar topics. A\ngeneration ago, broadcast television news was widely considered to serve this\nfunction; however, since the rise of cable news in the 1990s, critics and\nscholars have worried that the corresponding fragmentation and segregation of\naudiences along partisan lines has caused this shared reality to be lost. Here\nwe examine this concern using a unique combination of data sets tracking the\nproduction (since 2012) and consumption (since 2016) of television news content\non the three largest cable and broadcast networks respectively. With regard to\nproduction, we find strong evidence for the ``loss of shared reality\nhypothesis:'' while broadcast continues to cover similar topics with similar\nlanguage, cable news networks have become increasingly distinct, both from\nbroadcast news and each other, diverging both in terms of content and language.\nWith regard to consumption, we find more mixed evidence: while broadcast news\nhas indeed declined in popularity, it remains the dominant source of news for\nroughly 50\\% more Americans than does cable; moreover, its decline, while\nsomewhat attributable to cable, appears driven more by a shift away from news\nconsumption altogether than a growth in cable consumption. We conclude that\nshared reality on US television news is indeed diminishing, but is more robust\nthan previously thought and is declining for somewhat different reasons.\n", "title": "The diminishing state of shared reality on US television news", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18865", "abstract_url": "http://arxiv.org/abs/2310.18865", "authors": [{"last_name": "Farooq", "first_name": "Muhammad Umar"}, {"last_name": "Ahmad", "first_name": "Rehan"}, {"last_name": "Hain", "first_name": "Thomas"}], "primary_category": "CL", "categories": ["CL", "SD", ""], "abstract": "  Student-teacher learning or knowledge distillation (KD) has been previously\nused to address data scarcity issue for training of speech recognition (ASR)\nsystems. However, a limitation of KD training is that the student model classes\nmust be a proper or improper subset of the teacher model classes. It prevents\ndistillation from even acoustically similar languages if the character sets are\nnot same. In this work, the aforementioned limitation is addressed by proposing\na MUltilingual Student-Teacher (MUST) learning which exploits a posteriors\nmapping approach. A pre-trained mapping model is used to map posteriors from a\nteacher language to the student language ASR. These mapped posteriors are used\nas soft labels for KD learning. Various teacher ensemble schemes are\nexperimented to train an ASR model for low-resource languages. A model trained\nwith MUST learning reduces relative character error rate (CER) up to 9.5% in\ncomparison with a baseline monolingual ASR.\n", "title": "MUST: A Multilingual Student-Teacher Learning approach for low-resource\n  speech recognition", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18867", "abstract_url": "http://arxiv.org/abs/2310.18867", "authors": [{"last_name": "Amyeen", "first_name": "Rubaba"}], "primary_category": "CL", "categories": ["CL", ""], "abstract": "  Question generation has numerous applications in the educational context.\nQuestion generation can prove helpful for students when reviewing content and\ntesting themselves. Furthermore, a question generation model can aid teachers\nby lessening the burden of creating assessments and other practice material.\nThis paper aims to find the best method to generate questions from textual data\nthrough a transformer model and prompt engineering. In this research, we\nfinetuned a pretrained distilBERT model on the SQuAD question answering dataset\nto generate questions. In addition to training a transformer model, prompt\nengineering was applied to generate questions effectively using the LLaMA\nmodel. The generated questions were compared against the baseline questions in\nthe SQuAD dataset to evaluate the effectiveness of four different prompts. All\nfour prompts demonstrated over 60% similarity on average. Of the\nprompt-generated questions, 30% achieved a high similarity score greater than\n70%.\n", "title": "Prompt-Engineering and Transformer-based Question Generation and\n  Evaluation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18868", "abstract_url": "http://arxiv.org/abs/2310.18868", "authors": [{"last_name": "Jiang", "first_name": "Shuli"}, {"last_name": "Sharma", "first_name": "Pranay"}, {"last_name": "Joshi", "first_name": "Gauri"}], "primary_category": "DC", "categories": ["DC", "LG"], "abstract": "  We study the problem of communication-efficient distributed vector mean\nestimation, a commonly used subroutine in distributed optimization and\nFederated Learning (FL). Rand-$k$ sparsification is a commonly used technique\nto reduce communication cost, where each client sends $k < d$ of its\ncoordinates to the server. However, Rand-$k$ is agnostic to any correlations,\nthat might exist between clients in practical scenarios. The recently proposed\nRand-$k$-Spatial estimator leverages the cross-client correlation information\nat the server to improve Rand-$k$'s performance. Yet, the performance of\nRand-$k$-Spatial is suboptimal. We propose the Rand-Proj-Spatial estimator with\na more flexible encoding-decoding procedure, which generalizes the encoding of\nRand-$k$ by projecting the client vectors to a random $k$-dimensional subspace.\nWe utilize Subsampled Randomized Hadamard Transform (SRHT) as the projection\nmatrix and show that Rand-Proj-Spatial with SRHT outperforms Rand-$k$-Spatial,\nusing the correlation information more efficiently. Furthermore, we propose an\napproach to incorporate varying degrees of correlation and suggest a practical\nvariant of Rand-Proj-Spatial when the correlation information is not available\nto the server. Experiments on real-world distributed optimization tasks\nshowcase the superior performance of Rand-Proj-Spatial compared to\nRand-$k$-Spatial and other more sophisticated sparsification techniques.\n", "title": "Correlation Aware Sparsified Mean Estimation Using Random Projection", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18874", "abstract_url": "http://arxiv.org/abs/2310.18874", "authors": [{"last_name": "Xue", "first_name": "Weiyi"}, {"last_name": "Lu", "first_name": "Fan"}, {"last_name": "Chen", "first_name": "Guang"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Outdoor LiDAR point clouds are typically large-scale and complexly\ndistributed. To achieve efficient and accurate registration, emphasizing the\nsimilarity among local regions and prioritizing global local-to-local matching\nis of utmost importance, subsequent to which accuracy can be enhanced through\ncost-effective fine registration. In this paper, a novel hierarchical neural\nnetwork with double attention named HDMNet is proposed for large-scale outdoor\nLiDAR point cloud registration. Specifically, A novel feature consistency\nenhanced double-soft matching network is introduced to achieve two-stage\nmatching with high flexibility while enlarging the receptive field with high\nefficiency in a patch-to patch manner, which significantly improves the\nregistration performance. Moreover, in order to further utilize the sparse\nmatching information from deeper layer, we develop a novel trainable embedding\nmask to incorporate the confidence scores of correspondences obtained from pose\nestimation of deeper layer, eliminating additional computations. The\nhigh-confidence keypoints in the sparser point cloud of the deeper layer\ncorrespond to a high-confidence spatial neighborhood region in shallower layer,\nwhich will receive more attention, while the features of non-key regions will\nbe masked. Extensive experiments are conducted on two large-scale outdoor LiDAR\npoint cloud datasets to demonstrate the high accuracy and efficiency of the\nproposed HDMNet.\n", "title": "HDMNet: A Hierarchical Matching Network with Double Attention for\n  Large-scale Outdoor LiDAR Point Cloud Registration", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18877", "abstract_url": "http://arxiv.org/abs/2310.18877", "authors": [{"last_name": "Slaughter", "first_name": "Isaac"}, {"last_name": "Greenberg", "first_name": "Craig"}, {"last_name": "Schwartz", "first_name": "Reva"}, {"last_name": "Caliskan", "first_name": "Aylin"}], "primary_category": "CL", "categories": ["CL", "LG", "SD", ""], "abstract": "  Previous work has established that a person's demographics and speech style\naffect how well speech processing models perform for them. But where does this\nbias come from? In this work, we present the Speech Embedding Association Test\n(SpEAT), a method for detecting bias in one type of model used for many speech\ntasks: pre-trained models. The SpEAT is inspired by word embedding association\ntests in natural language processing, which quantify intrinsic bias in a\nmodel's representations of different concepts, such as race or valence\n(something's pleasantness or unpleasantness) and capture the extent to which a\nmodel trained on large-scale socio-cultural data has learned human-like biases.\nUsing the SpEAT, we test for six types of bias in 16 English speech models\n(including 4 models also trained on multilingual data), which come from the\nwav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more\nmodels reveal positive valence (pleasantness) associations with abled people\nover disabled people, with European-Americans over African-Americans, with\nfemales over males, with U.S. accented speakers over non-U.S. accented\nspeakers, and with younger people over older people. Beyond establishing that\npre-trained speech models contain these biases, we also show that they can have\nreal world effects. We compare biases found in pre-trained models to biases in\ndownstream models adapted to the task of Speech Emotion Recognition (SER) and\nfind that in 66 of the 96 tests performed (69%), the group that is more\nassociated with positive valence as indicated by the SpEAT also tends to be\npredicted as speaking with higher valence by the downstream model. Our work\nprovides evidence that, like text and image-based models, pre-trained speech\nbased-models frequently learn human-like biases. Our work also shows that bias\nfound in pre-trained models can propagate to the downstream task of SER.\n", "title": "Pre-trained Speech Processing Models Contain Human-Like Biases that\n  Propagate to Speech Emotion Recognition", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18882", "abstract_url": "http://arxiv.org/abs/2310.18882", "authors": [{"last_name": "Lee", "first_name": "Changwoo"}, {"last_name": "Kim", "first_name": "Hun-Seok"}], "primary_category": "LG", "categories": ["LG", "", "CV", "", ""], "abstract": "  This paper investigates efficient deep neural networks (DNNs) to replace\ndense unstructured weight matrices with structured ones that possess desired\nproperties. The challenge arises because the optimal weight matrix structure in\npopular neural network models is obscure in most cases and may vary from layer\nto layer even in the same network. Prior structured matrices proposed for\nefficient DNNs were mostly hand-crafted without a generalized framework to\nsystematically learn them. To address this issue, we propose a generalized and\ndifferentiable framework to learn efficient structures of weight matrices by\ngradient descent. We first define a new class of structured matrices that\ncovers a wide range of structured matrices in the literature by adjusting the\nstructural parameters. Then, the frequency-domain differentiable\nparameterization scheme based on the Gaussian-Dirichlet kernel is adopted to\nlearn the structural parameters by proximal gradient descent. Finally, we\nintroduce an effective initialization method for the proposed scheme. Our\nmethod learns efficient DNNs with structured matrices, achieving lower\ncomplexity and/or higher performance than prior approaches that employ\nlow-rank, block-sparse, or block-low-rank matrices.\n", "title": "Differentiable Learning of Generalized Structured Matrices for Efficient\n  Deep Neural Networks", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18884", "abstract_url": "http://arxiv.org/abs/2310.18884", "authors": [{"last_name": "Xiao", "first_name": "Teng"}, {"last_name": "Zhu", "first_name": "Huaisheng"}, {"last_name": "Chen", "first_name": "Zhengyu"}, {"last_name": "Wang", "first_name": "Suhang"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  Graph Contrastive Learning (GCL) has shown superior performance in\nrepresentation learning in graph-structured data. Despite their success, most\nexisting GCL methods rely on prefabricated graph augmentation and homophily\nassumptions. Thus, they fail to generalize well to heterophilic graphs where\nconnected nodes may have different class labels and dissimilar features. In\nthis paper, we study the problem of conducting contrastive learning on\nhomophilic and heterophilic graphs. We find that we can achieve promising\nperformance simply by considering an asymmetric view of the neighboring nodes.\nThe resulting simple algorithm, Asymmetric Contrastive Learning for Graphs\n(GraphACL), is easy to implement and does not rely on graph augmentations and\nhomophily assumptions. We provide theoretical and empirical evidence that\nGraphACL can capture one-hop local neighborhood information and two-hop\nmonophily similarity, which are both important for modeling heterophilic\ngraphs. Experimental results show that the simple GraphACL significantly\noutperforms state-of-the-art graph contrastive learning and self-supervised\nlearning methods on homophilic and heterophilic graphs. The code of GraphACL is\navailable at https://github.com/tengxiao1/GraphACL.\n", "title": "Simple and Asymmetric Graph Contrastive Learning without Augmentations", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18885", "abstract_url": "http://arxiv.org/abs/2310.18885", "authors": [{"last_name": "Tripura", "first_name": "Tapas"}, {"last_name": "Chakraborty", "first_name": "Souvik"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Machine learning has witnessed substantial growth, leading to the development\nof advanced artificial intelligence models crafted to address a wide range of\nreal-world challenges spanning various domains, such as computer vision,\nnatural language processing, and scientific computing. Nevertheless, the\ncreation of custom models for each new task remains a resource-intensive\nundertaking, demanding considerable computational time and memory resources. In\nthis study, we introduce the concept of the Neural Combinatorial Wavelet Neural\nOperator (NCWNO) as a foundational model for scientific computing. This model\nis specifically designed to excel in learning from a diverse spectrum of\nphysics and continuously adapt to the solution operators associated with\nparametric partial differential equations (PDEs). The NCWNO leverages a gated\nstructure that employs local wavelet experts to acquire shared features across\nmultiple physical systems, complemented by a memory-based ensembling approach\namong these local wavelet experts. This combination enables rapid adaptation to\nnew challenges. The proposed foundational model offers two key advantages: (i)\nit can simultaneously learn solution operators for multiple parametric PDEs,\nand (ii) it can swiftly generalize to new parametric PDEs with minimal\nfine-tuning. The proposed NCWNO is the first foundational operator learning\nalgorithm distinguished by its (i) robustness against catastrophic forgetting,\n(ii) the maintenance of positive transfer for new parametric PDEs, and (iii)\nthe facilitation of knowledge transfer across dissimilar tasks. Through an\nextensive set of benchmark examples, we demonstrate that the NCWNO can\noutperform task-specific baseline operator learning frameworks with minimal\nhyperparameter tuning at the prediction stage. We also show that with minimal\nfine-tuning, the NCWNO performs accurate combinatorial learning of new\nparametric PDEs.\n", "title": "A foundational neural operator that continuously learns without\n  forgetting", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18887", "abstract_url": "http://arxiv.org/abs/2310.18887", "authors": [{"last_name": "Sun", "first_name": "Yihong"}, {"last_name": "Hariharan", "first_name": "Bharath"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Unsupervised monocular depth estimation techniques have demonstrated\nencouraging results but typically assume that the scene is static. These\ntechniques suffer when trained on dynamical scenes, where apparent object\nmotion can equally be explained by hypothesizing the object's independent\nmotion, or by altering its depth. This ambiguity causes depth estimators to\npredict erroneous depth for moving objects. To resolve this issue, we introduce\nDynamo-Depth, an unifying approach that disambiguates dynamical motion by\njointly learning monocular depth, 3D independent flow field, and motion\nsegmentation from unlabeled monocular videos. Specifically, we offer our key\ninsight that a good initial estimation of motion segmentation is sufficient for\njointly learning depth and independent motion despite the fundamental\nunderlying ambiguity. Our proposed method achieves state-of-the-art performance\non monocular depth estimation on Waymo Open and nuScenes Dataset with\nsignificant improvement in the depth of moving objects. Code and additional\nresults are available at https://dynamo-depth.github.io.\n", "title": "Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18888", "abstract_url": "http://arxiv.org/abs/2310.18888", "authors": [{"last_name": "Zhang", "first_name": "Zecheng"}, {"last_name": "Moya", "first_name": "Christian"}, {"last_name": "Lu", "first_name": "Lu"}, {"last_name": "Lin", "first_name": "Guang"}, {"last_name": "Schaeffer", "first_name": "Hayden"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Neural operators have been applied in various scientific fields, such as\nsolving parametric partial differential equations, dynamical systems with\ncontrol, and inverse problems. However, challenges arise when dealing with\ninput functions that exhibit heterogeneous properties, requiring multiple\nsensors to handle functions with minimal regularity. To address this issue,\ndiscretization-invariant neural operators have been used, allowing the sampling\nof diverse input functions with different sensor locations. However, existing\nframeworks still require an equal number of sensors for all functions. In our\nstudy, we propose a novel distributed approach to further relax the\ndiscretization requirements and solve the heterogeneous dataset challenges. Our\nmethod involves partitioning the input function space and processing individual\ninput functions using independent and separate neural networks. A centralized\nneural network is used to handle shared information across all output\nfunctions. This distributed methodology reduces the number of gradient descent\nback-propagation steps, improving efficiency while maintaining accuracy. We\ndemonstrate that the corresponding neural network is a universal approximator\nof continuous nonlinear operators and present four numerical examples to\nvalidate its performance.\n", "title": "D2NO: Efficient Handling of Heterogeneous Input Function Spaces with\n  Distributed Deep Neural Operators", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18890", "abstract_url": "http://arxiv.org/abs/2310.18890", "authors": [{"last_name": "Wang", "first_name": "Jiatai"}, {"last_name": "Xu", "first_name": "Zhiwei"}, {"last_name": "Wang", "first_name": "Xin"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Existing multi-stage clustering methods independently learn the salient\nfeatures from multiple views and then perform the clustering task.\nParticularly, multi-view clustering (MVC) has attracted a lot of attention in\nmulti-view or multi-modal scenarios. MVC aims at exploring common semantics and\npseudo-labels from multiple views and clustering in a self-supervised manner.\nHowever, limited by noisy data and inadequate feature learning, such a\nclustering paradigm generates overconfident pseudo-labels that mis-guide the\nmodel to produce inaccurate predictions. Therefore, it is desirable to have a\nmethod that can correct this pseudo-label mistraction in multi-stage clustering\nto avoid the bias accumulation. To alleviate the effect of overconfident\npseudo-labels and improve the generalization ability of the model, this paper\nproposes a novel multi-stage deep MVC framework where multi-view\nself-distillation (DistilMVC) is introduced to distill dark knowledge of label\ndistribution. Specifically, in the feature subspace at different hierarchies,\nwe explore the common semantics of multiple views through contrastive learning\nand obtain pseudo-labels by maximizing the mutual information between views.\nAdditionally, a teacher network is responsible for distilling pseudo-labels\ninto dark knowledge, supervising the student network and improving its\npredictive capabilities to enhance the robustness. Extensive experiments on\nreal-world multi-view datasets show that our method has better clustering\nperformance than state-of-the-art methods.\n", "title": "Towards Generalized Multi-stage Clustering: Multi-view Self-distillation", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18891", "abstract_url": "http://arxiv.org/abs/2310.18891", "authors": [{"last_name": "Crosato", "first_name": "Luca"}, {"last_name": "Tian", "first_name": "Kai"}, {"last_name": "Shum", "first_name": "Hubert P. H"}, {"last_name": "Ho", "first_name": "Edmond S. L."}, {"last_name": "Wang", "first_name": "Yafei"}, {"last_name": "We", "first_name": "Chongfeng"}], "primary_category": "HC", "categories": ["HC", "CY", "RO", ""], "abstract": "  Interaction-aware Autonomous Driving (IAAD) is a rapidly growing field of\nresearch that focuses on the development of autonomous vehicles (AVs) that are\ncapable of interacting safely and efficiently with human road users. This is a\nchallenging task, as it requires the autonomous vehicle to be able to\nunderstand and predict the behaviour of human road users. In this literature\nreview, the current state of IAAD research is surveyed in this work. Commencing\nwith an examination of terminology, attention is drawn to challenges and\nexisting models employed for modelling the behaviour of drivers and\npedestrians. Next, a comprehensive review is conducted on various techniques\nproposed for interaction modelling, encompassing cognitive methods, machine\nlearning approaches, and game-theoretic methods. The conclusion is reached\nthrough a discussion of potential advantages and risks associated with IAAD,\nalong with the illumination of pivotal research inquiries necessitating future\nexploration.\n", "title": "Social Interaction-Aware Dynamical Models and Decision Making for\n  Autonomous Vehicles", "date": "2023-10-28", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18893", "abstract_url": "http://arxiv.org/abs/2310.18893", "authors": [{"last_name": "Ding", "first_name": "Li"}, {"last_name": "Zoghi", "first_name": "Masrour"}, {"last_name": "Tennenholtz", "first_name": "Guy"}, {"last_name": "Karimzadehgan", "first_name": "Maryam"}], "primary_category": "LG", "categories": ["LG", "", "NE"], "abstract": "  We introduce EV3, a novel meta-optimization framework designed to efficiently\ntrain scalable machine learning models through an intuitive\nexplore-assess-adapt protocol. In each iteration of EV3, we explore various\nmodel parameter updates, assess them using pertinent evaluation methods, and\nadapt the model based on the optimal updates and previous progress history. EV3\noffers substantial flexibility without imposing stringent constraints like\ndifferentiability on the key objectives relevant to the tasks of interest.\nMoreover, this protocol welcomes updates with biased gradients and allows for\nthe use of a diversity of losses and optimizers. Additionally, in scenarios\nwith multiple objectives, it can be used to dynamically prioritize tasks. With\ninspiration drawn from evolutionary algorithms, meta-learning, and neural\narchitecture search, we investigate an application of EV3 to knowledge\ndistillation. Our experimental results illustrate EV3's capability to safely\nexplore model spaces, while hinting at its potential applicability across\nnumerous domains due to its inherent flexibility and adaptability.\n", "title": "Ever Evolving Evaluator (EV3): Towards Flexible and Reliable\n  Meta-Optimization for Knowledge Distillation", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18894", "abstract_url": "http://arxiv.org/abs/2310.18894", "authors": [{"last_name": "Li", "first_name": "Tianqin"}, {"last_name": "Wen", "first_name": "Ziqi"}, {"last_name": "Li", "first_name": "Yangfan"}, {"last_name": "Lee", "first_name": "Tai Sing"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Current deep-learning models for object recognition are known to be heavily\nbiased toward texture. In contrast, human visual systems are known to be biased\ntoward shape and structure. What could be the design principles in human visual\nsystems that led to this difference? How could we introduce more shape bias\ninto the deep learning models? In this paper, we report that sparse coding, a\nubiquitous principle in the brain, can in itself introduce shape bias into the\nnetwork. We found that enforcing the sparse coding constraint using a\nnon-differential Top-K operation can lead to the emergence of structural\nencoding in neurons in convolutional neural networks, resulting in a smooth\ndecomposition of objects into parts and subparts and endowing the networks with\nshape bias. We demonstrated this emergence of shape bias and its functional\nbenefits for different network structures with various datasets. For object\nrecognition convolutional neural networks, the shape bias leads to greater\nrobustness against style and pattern change distraction. For the image\nsynthesis generative adversary networks, the emerged shape bias leads to more\ncoherent and decomposable structures in the synthesized images. Ablation\nstudies suggest that sparse codes tend to encode structures, whereas the more\ndistributed codes tend to favor texture. Our code is host at the github\nrepository: \\url{https://github.com/Crazy-Jack/nips2023_shape_vs_texture}\n", "title": "Emergence of Shape Bias in Convolutional Neural Networks through\n  Activation Sparsity", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18895", "abstract_url": "http://arxiv.org/abs/2310.18895", "authors": [{"last_name": "Sun", "first_name": "Jingzhou"}, {"last_name": "Wang", "first_name": "Lehan"}, {"last_name": "Nan", "first_name": "Zhaojun"}, {"last_name": "Sun", "first_name": "Yuxuan"}, {"last_name": "Zhou", "first_name": "Sheng"}, {"last_name": "Niu", "first_name": "Zhisheng"}], "primary_category": "NI", "categories": ["NI", "IT"], "abstract": "  Intelligent real-time applications, such as video surveillance, demand\nintensive computation to extract status information from raw sensing data. This\nposes a substantial challenge in orchestrating computation and communication\nresources to provide fresh status information. In this paper, we consider a\nscenario where multiple energy-constrained devices served by an edge server. To\nextract status information, each device can either do the computation locally\nor offload it to the edge server. A scheduling policy is needed to determine\nwhen and where to compute for each device, taking into account communication\nand computation capabilities, as well as task-specific timeliness requirements.\nTo that end, we first model the timeliness requirements as general penalty\nfunctions of Age of Information (AoI). A convex optimization problem is\nformulated to provide a lower bound of the minimum AoI penalty given system\nparameters. Using KKT conditions, we proposed a novel scheduling policy which\nevaluates status update priorities based on communication and computation\ndelays and task-specific timeliness requirements. The proposed policy is\napplied to an object tracking application and carried out on a large video\ndataset. Simulation results show that our policy improves tracking accuracy\ncompared with scheduling policies based on video content information.\n", "title": "Optimizing Task-Specific Timeliness With Edge-Assisted Scheduling for\n  Status Update", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18897", "abstract_url": "http://arxiv.org/abs/2310.18897", "authors": [{"last_name": "Kang", "first_name": "Shinhoo"}, {"last_name": "Constantinescu", "first_name": "Emil M."}], "primary_category": "", "categories": ["", "LG", "", ""], "abstract": "  The growing computing power over the years has enabled simulations to become\nmore complex and accurate. However, high-fidelity simulations, while immensely\nvaluable for scientific discovery and problem solving, come with significant\ncomputational demands. As a result, it is common to run a low-fidelity model\nwith a subgrid-scale model to reduce the computational cost, but selecting the\nappropriate subgrid-scale models and tuning them are challenging. We propose a\nnovel method for learning the subgrid-scale model effects when simulating\npartial differential equations using neural ordinary differential equations in\nthe context of discontinuous Galerkin (DG) spatial discretization. Our approach\nlearns the missing scales of the low-order DG solver at a continuous level and\nhence improves the accuracy of the low-order DG approximations as well as\naccelerates the filtered high-order DG simulations with a certain degree of\nprecision. We demonstrate the performance of our approach through\nmultidimensional Taylor--Green vortex examples at different Reynolds numbers\nand times, which cover laminar, transitional, and turbulent regimes. The\nproposed method not only reconstructs the subgrid-scale from the low-order\n(1st-order) approximation but also speeds up the filtered high-order DG\n(6th-order) simulation by two orders of magnitude.\n", "title": "Learning Subgrid-Scale Models in Discontinuous Galerkin Methods with\n  Neural Ordinary Differential Equations for Compressible Navier--Stokes\n  Equations", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18899", "abstract_url": "http://arxiv.org/abs/2310.18899", "authors": [{"last_name": "Qian", "first_name": "Zhen"}, {"last_name": "Chen", "first_name": "Min"}, {"last_name": "Sun", "first_name": "Zhuo"}, {"last_name": "Zhang", "first_name": "Fan"}, {"last_name": "Xu", "first_name": "Qingsong"}, {"last_name": "Guo", "first_name": "Jinzhao"}, {"last_name": "Xie", "first_name": "Zhiwei"}, {"last_name": "Zhang", "first_name": "Zhixin"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Understanding urban dynamics and promoting sustainable development requires\ncomprehensive insights about buildings. While geospatial artificial\nintelligence has advanced the extraction of such details from Earth\nobservational data, existing methods often suffer from computational\ninefficiencies and inconsistencies when compiling unified building-related\ndatasets for practical applications. To bridge this gap, we introduce the\nMulti-task Building Refiner (MT-BR), an adaptable neural network tailored for\nsimultaneous extraction of spatial and attributional building details from\nhigh-resolution satellite imagery, exemplified by building rooftops, urban\nfunctional types, and roof architectural types. Notably, MT-BR can be\nfine-tuned to incorporate additional building details, extending its\napplicability. For large-scale applications, we devise a novel spatial sampling\nscheme that strategically selects limited but representative image samples.\nThis process optimizes both the spatial distribution of samples and the urban\nenvironmental characteristics they contain, thus enhancing extraction\neffectiveness while curtailing data preparation expenditures. We further\nenhance MT-BR's predictive performance and generalization capabilities through\nthe integration of advanced augmentation techniques. Our quantitative results\nhighlight the efficacy of the proposed methods. Specifically, networks trained\nwith datasets curated via our sampling method demonstrate improved predictive\naccuracy relative to those using alternative sampling approaches, with no\nalterations to network architecture. Moreover, MT-BR consistently outperforms\nother state-of-the-art methods in extracting building details across various\nmetrics. The real-world practicality is also demonstrated in an application\nacross Shanghai, generating a unified dataset that encompasses both the spatial\nand attributional details of buildings.\n", "title": "Multi-task deep learning for large-scale building detail extraction from\n  high-resolution satellite imagery", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18900", "abstract_url": "http://arxiv.org/abs/2310.18900", "authors": [{"last_name": "An", "first_name": "Dong"}, {"last_name": "Trivisa", "first_name": "Konstantina"}], "primary_category": "", "categories": ["", ""], "abstract": "  High-dimensional fractional reaction-diffusion equations have numerous\napplications in the fields of biology, chemistry, and physics, and exhibit a\nrange of rich phenomena. While classical algorithms have an exponential\ncomplexity in the spatial dimension, a quantum computer can produce a quantum\nstate that encodes the solution with only polynomial complexity, provided that\nsuitable input access is available. In this work, we investigate efficient\nquantum algorithms for linear and nonlinear fractional reaction-diffusion\nequations with periodic boundary conditions. For linear equations, we analyze\nand compare the complexity of various methods, including the second-order\nTrotter formula, time-marching method, and truncated Dyson series method. We\nalso present a novel algorithm that combines the linear combination of\nHamiltonian simulation technique with the interaction picture formalism,\nresulting in optimal scaling in the spatial dimension. For nonlinear equations,\nwe employ the Carleman linearization method and propose a block-encoding\nversion that is appropriate for the dense matrices that arise from the spatial\ndiscretization of fractional reaction-diffusion equations.\n", "title": "Quantum algorithms for linear and non-linear fractional\n  reaction-diffusion equations", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18902", "abstract_url": "http://arxiv.org/abs/2310.18902", "authors": [{"last_name": "Scott-Brown", "first_name": "James"}, {"last_name": "Bach", "first_name": "Benjamin"}], "primary_category": "HC", "categories": ["HC"], "abstract": "  This paper introduces NetPanorama, a domain-specific language and declarative\ngrammar for interactive network visualizations. Exploring complex networks with\nmultivariate, geographical, or temporal information often require bespoke\nvisualization designs, such as adjacency matrices, arc-diagrams, small\nmultiples, timelines, or geographic map visualizations. However, creating these\nrequires implementing data loading, data transformations, visualization, and\ninteractivity, which is time-consuming and slows down the iterative exploration\nof this huge design space. With NetPanorama, a developer specifies a network\nvisualization design as a pipeline of parameterizable steps. Our specification\nand reference implementation aims to facilitate visualization development and\nreuse; allow for easy design exploration and iteration; and make data\ntransformation and visual mapping decisions transparent. Documentation, source\ncode, examples, and an interactive online editor can be found online:\nhttps://netpanorama.netlify.app/\n", "title": "NetPanorama: A Declarative Grammar for Network Construction,\n  Transformation, and Visualization", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18904", "abstract_url": "http://arxiv.org/abs/2310.18904", "authors": [{"last_name": "Zhang", "first_name": "Qi"}, {"last_name": "Wang", "first_name": "Yifei"}, {"last_name": "Wang", "first_name": "Yisen"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Existing contrastive learning methods rely on pairwise sample contrast\n$z_x^\\top z_{x'}$ to learn data representations, but the learned features often\nlack clear interpretability from a human perspective. Theoretically, it lacks\nfeature identifiability and different initialization may lead to totally\ndifferent features. In this paper, we study a new method named tri-factor\ncontrastive learning (triCL) that involves a 3-factor contrast in the form of\n$z_x^\\top S z_{x'}$, where $S=\\text{diag}(s_1,\\dots,s_k)$ is a learnable\ndiagonal matrix that automatically captures the importance of each feature. We\nshow that by this simple extension, triCL can not only obtain identifiable\nfeatures that eliminate randomness but also obtain more interpretable features\nthat are ordered according to the importance matrix $S$. We show that features\nwith high importance have nice interpretability by capturing common classwise\nfeatures, and obtain superior performance when evaluated for image retrieval\nusing a few features. The proposed triCL objective is general and can be\napplied to different contrastive learning methods like SimCLR and CLIP. We\nbelieve that it is a better alternative to existing 2-factor contrastive\nlearning by improving its identifiability and interpretability with minimal\noverhead. Code is available at\nhttps://github.com/PKU-ML/Tri-factor-Contrastive-Learning.\n", "title": "Identifiable Contrastive Learning with Automatic Feature Importance\n  Discovery", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18906", "abstract_url": "http://arxiv.org/abs/2310.18906", "authors": [{"last_name": "Nguyen", "first_name": "Duke"}, {"last_name": "Naing", "first_name": "Khaing Myat Noe"}, {"last_name": "Joshi", "first_name": "Aditya"}], "primary_category": "CL", "categories": ["CL", ""], "abstract": "  This paper reports our submission under the team name `SynthDetectives' to\nthe ALTA 2023 Shared Task. We use a stacking ensemble of Transformers for the\ntask of AI-generated text detection. Our approach is novel in terms of its\nchoice of models in that we use accessible and lightweight models in the\nensemble. We show that ensembling the models results in an improved accuracy in\ncomparison with using them individually. Our approach achieves an accuracy\nscore of 0.9555 on the official test data provided by the shared task\norganisers.\n", "title": "Stacking the Odds: Transformer-Based Ensemble for AI-Generated Text\n  Detection", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18907", "abstract_url": "http://arxiv.org/abs/2310.18907", "authors": [{"last_name": "Rasul", "first_name": "Ashiqur"}, {"last_name": "Hossain", "first_name": "Md Shafayat"}, {"last_name": "Dastider", "first_name": "Ankan Ghosh"}, {"last_name": "Roy", "first_name": "Himaddri"}, {"last_name": "Hasan", "first_name": "M. Zahid"}, {"last_name": "Khosru", "first_name": "Quazi D. M."}], "primary_category": "", "categories": ["", "LG"], "abstract": "  Prediction and discovery of new materials with desired properties are at the\nforefront of quantum science and technology research. A major bottleneck in\nthis field is the computational resources and time complexity related to\nfinding new materials from ab initio calculations. In this work, an effective\nand robust deep learning-based model is proposed by incorporating persistent\nhomology and graph neural network which offers an accuracy of 91.4% and an F1\nscore of 88.5% in classifying topological vs. non-topological materials,\noutperforming the other state-of-the-art classifier models. The incorporation\nof the graph neural network encodes the underlying relation between the atoms\ninto the model based on their own crystalline structures and thus proved to be\nan effective method to represent and process non-euclidean data like molecules\nwith a relatively shallow network. The persistent homology pipeline in the\nsuggested neural network is capable of integrating the atom-specific\ntopological information into the deep learning model, increasing robustness,\nand gain in performance. It is believed that the presented work will be an\nefficacious tool for predicting the topological class and therefore enable the\nhigh-throughput search for novel materials in this field.\n", "title": "Topological, or Non-topological? A Deep Learning Based Prediction", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18908", "abstract_url": "http://arxiv.org/abs/2310.18908", "authors": [{"last_name": "Yang", "first_name": "Yibo"}, {"last_name": "Eckstein", "first_name": "Stephan"}, {"last_name": "Nutz", "first_name": "Marcel"}, {"last_name": "Mandt", "first_name": "Stephan"}], "primary_category": "IT", "categories": ["IT", "LG", "", ""], "abstract": "  In the theory of lossy compression, the rate-distortion (R-D) function $R(D)$\ndescribes how much a data source can be compressed (in bit-rate) at any given\nlevel of fidelity (distortion). Obtaining $R(D)$ for a given data source\nestablishes the fundamental performance limit for all compression algorithms.\nWe propose a new method to estimate $R(D)$ from the perspective of optimal\ntransport. Unlike the classic Blahut--Arimoto algorithm which fixes the support\nof the reproduction distribution in advance, our Wasserstein gradient descent\nalgorithm learns the support of the optimal reproduction distribution by moving\nparticles. We prove its local convergence and analyze the sample complexity of\nour R-D estimator based on a connection to entropic optimal transport.\nExperimentally, we obtain comparable or tighter bounds than state-of-the-art\nneural network methods on low-rate sources while requiring considerably less\ntuning and computation effort. We also highlight a connection to\nmaximum-likelihood deconvolution and introduce a new class of sources that can\nbe used as test cases with known solutions to the R-D problem.\n", "title": "Estimating the Rate-Distortion Function by Wasserstein Gradient Descent", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18910", "abstract_url": "http://arxiv.org/abs/2310.18910", "authors": [{"last_name": "Li", "first_name": "Muyang"}, {"last_name": "Wu", "first_name": "Runze"}, {"last_name": "Liu", "first_name": "Haoyu"}, {"last_name": "Yu", "first_name": "Jun"}, {"last_name": "Yang", "first_name": "Xun"}, {"last_name": "Han", "first_name": "Bo"}, {"last_name": "Liu", "first_name": "Tongliang"}], "primary_category": "LG", "categories": ["LG", "", "CV", ""], "abstract": "  Semi-supervised learning (SSL) has been a fundamental challenge in machine\nlearning for decades. The primary family of SSL algorithms, known as\npseudo-labeling, involves assigning pseudo-labels to confident unlabeled\ninstances and incorporating them into the training set. Therefore, the\nselection criteria of confident instances are crucial to the success of SSL.\nRecently, there has been growing interest in the development of SSL methods\nthat use dynamic or adaptive thresholds. Yet, these methods typically apply the\nsame threshold to all samples, or use class-dependent thresholds for instances\nbelonging to a certain class, while neglecting instance-level information. In\nthis paper, we propose the study of instance-dependent thresholds, which has\nthe highest degree of freedom compared with existing methods. Specifically, we\ndevise a novel instance-dependent threshold function for all unlabeled\ninstances by utilizing their instance-level ambiguity and the\ninstance-dependent error rates of pseudo-labels, so instances that are more\nlikely to have incorrect pseudo-labels will have higher thresholds.\nFurthermore, we demonstrate that our instance-dependent threshold function\nprovides a bounded probabilistic guarantee for the correctness of the\npseudo-labels it assigns.\n", "title": "InstanT: Semi-supervised Learning with Instance-dependent Thresholds", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18911", "abstract_url": "http://arxiv.org/abs/2310.18911", "authors": [{"last_name": "Jain", "first_name": "Brisha"}, {"last_name": "Mondal", "first_name": "Mainack"}], "primary_category": "SI", "categories": ["SI", "CY", "HC"], "abstract": "  Gender bias in political discourse is a significant problem on today's social\nmedia. Previous studies found that the gender of politicians indeed influences\nthe content directed towards them by the general public. However, these works\nare particularly focused on the global north, which represents individualistic\nculture. Furthermore, they did not address whether there is gender bias even\nwithin the interaction between popular journalists and politicians in the\nglobal south. These understudied journalist-politician interactions are\nimportant (more so in collectivistic cultures like the global south) as they\ncan significantly affect public sentiment and help set gender-biased social\nnorms. In this work, using large-scale data from Indian Twitter we address this\nresearch gap.\n  We curated a gender-balanced set of 100 most-followed Indian journalists on\nTwitter and 100 most-followed politicians. Then we collected 21,188 unique\ntweets posted by these journalists that mentioned these politicians. Our\nanalysis revealed that there is a significant gender bias -- the frequency with\nwhich journalists mention male politicians vs. how frequently they mention\nfemale politicians is statistically significantly different ($p<<0.05$). In\nfact, median tweets from female journalists mentioning female politicians\nreceived ten times fewer likes than median tweets from female journalists\nmentioning male politicians. However, when we analyzed tweet content, our\nemotion score analysis and topic modeling analysis did not reveal any\nsignificant gender-based difference within the journalists' tweets towards\npoliticians. Finally, we found a potential reason for the significant gender\nbias: the number of popular male Indian politicians is almost twice as large as\nthe number of popular female Indian politicians, which might have resulted in\nthe observed bias. We conclude by discussing the implications of this work.\n", "title": "Uncovering Gender Bias within Journalist-Politician Interaction in\n  Indian Twitter", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18912", "abstract_url": "http://arxiv.org/abs/2310.18912", "authors": [{"last_name": "Zhang", "first_name": "Hao"}, {"last_name": "Liu", "first_name": "Yang"}, {"last_name": "Liu", "first_name": "Xiaoyan"}, {"last_name": "Liang", "first_name": "Tianming"}, {"last_name": "Sharma", "first_name": "Gaurav"}, {"last_name": "Xue", "first_name": "Liang"}, {"last_name": "Guo", "first_name": "Maozu"}], "primary_category": "LG", "categories": ["LG", "CL"], "abstract": "  We introduce a novel graph-based framework for alleviating key challenges in\ndistantly-supervised relation extraction and demonstrate its effectiveness in\nthe challenging and important domain of biomedical data. Specifically, we\npropose a graph view of sentence bags referring to an entity pair, which\nenables message-passing based aggregation of information related to the entity\npair over the sentence bag. The proposed framework alleviates the common\nproblem of noisy labeling in distantly supervised relation extraction and also\neffectively incorporates inter-dependencies between sentences within a bag.\nExtensive experiments on two large-scale biomedical relation datasets and the\nwidely utilized NYT dataset demonstrate that our proposed framework\nsignificantly outperforms the state-of-the-art methods for biomedical distant\nsupervision relation extraction while also providing excellent performance for\nrelation extraction in the general text mining domain.\n", "title": "Sentence Bag Graph Formulation for Biomedical Distant Supervision\n  Relation Extraction", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18913", "abstract_url": "http://arxiv.org/abs/2310.18913", "authors": [{"last_name": "Limisiewicz", "first_name": "Tomasz"}, {"last_name": "Mare\u010dek", "first_name": "David"}, {"last_name": "Musil", "first_name": "Tom\u00e1\u0161"}], "primary_category": "CL", "categories": ["CL", "", ""], "abstract": "  Large language models are becoming the go-to solution for various language\ntasks. However, with growing capacity, models are prone to rely on spurious\ncorrelations stemming from biases and stereotypes present in the training data.\nThis work proposes a novel method for detecting and mitigating gender bias in\nlanguage models. We perform causal analysis to identify problematic model\ncomponents and discover that mid-upper feed-forward layers are most prone to\nconvey biases. Based on the analysis results, we adapt the model by multiplying\nthese layers by a linear projection. Our titular method, DAMA, significantly\ndecreases bias as measured by diverse metrics while maintaining the model's\nperformance on downstream tasks. We release code for our method and models,\nwhich retrain LLaMA's state-of-the-art performance while being significantly\nless biased.\n", "title": "Debiasing Algorithm through Model Adaptation", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18917", "abstract_url": "http://arxiv.org/abs/2310.18917", "authors": [{"last_name": "Duan", "first_name": "Chengyao"}, {"last_name": "Yang", "first_name": "Zhiliu"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Previous attempts to integrate Neural Radiance Fields (NeRF) into\nSimultaneous Localization and Mapping (SLAM) framework either rely on the\nassumption of static scenes or treat dynamic objects as outliers. However, most\nof real-world scenarios is dynamic. In this paper, we propose a time-varying\nrepresentation to track and reconstruct the dynamic scenes. Our system\nsimultaneously maintains two processes, tracking process and mapping process.\nFor tracking process, the entire input images are uniformly sampled and\ntraining of the RGB images are self-supervised. For mapping process, we\nleverage know masks to differentiate dynamic objects and static backgrounds,\nand we apply distinct sampling strategies for two types of areas. The\nparameters optimization for both processes are made up by two stages, the first\nstage associates time with 3D positions to convert the deformation field to the\ncanonical field. And the second associates time with 3D positions in canonical\nfield to obtain colors and Signed Distance Function (SDF). Besides, We propose\na novel keyframe selection strategy based on the overlapping rate. We evaluate\nour approach on two publicly available synthetic datasets and validate that our\nmethod is more effective compared to current state-of-the-art dynamic mapping\nmethods.\n", "title": "TiV-NeRF: Tracking and Mapping via Time-Varying Representation with\n  Dynamic Neural Radiance Fields", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18918", "abstract_url": "http://arxiv.org/abs/2310.18918", "authors": [{"last_name": "Choudhary", "first_name": "Nurendra"}, {"last_name": "Rao", "first_name": "Nikhil"}, {"last_name": "Reddy", "first_name": "Chandan K."}], "primary_category": "LG", "categories": ["LG", "SI"], "abstract": "  The progress in hyperbolic neural networks (HNNs) research is hindered by\ntheir absence of inductive bias mechanisms, which are essential for\ngeneralizing to new tasks and facilitating scalable learning over large\ndatasets. In this paper, we aim to alleviate these issues by learning\ngeneralizable inductive biases from the nodes' local subgraph and transfer them\nfor faster learning over new subgraphs with a disjoint set of nodes, edges, and\nlabels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph\nMeta Learner (H-GRAM), that, for the tasks of node classification and link\nprediction, learns transferable information from a set of support local\nsubgraphs in the form of hyperbolic meta gradients and label hyperbolic\nprotonets to enable faster learning over a query set of new tasks dealing with\ndisjoint subgraphs. Furthermore, we show that an extension of our meta-learning\nframework also mitigates the scalability challenges seen in HNNs faced by\nexisting approaches. Our comparative analysis shows that H-GRAM effectively\nlearns and transfers information in multiple challenging few-shot settings\ncompared to other state-of-the-art baselines. Additionally, we demonstrate\nthat, unlike standard HNNs, our approach is able to scale over large graph\ndatasets and improve performance over its Euclidean counterparts.\n", "title": "Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18919", "abstract_url": "http://arxiv.org/abs/2310.18919", "authors": [{"last_name": "Kuang", "first_name": "Nikki Lijing"}, {"last_name": "Yin", "first_name": "Ming"}, {"last_name": "Wang", "first_name": "Mengdi"}, {"last_name": "Wang", "first_name": "Yu-Xiang"}, {"last_name": "Ma", "first_name": "Yi-An"}], "primary_category": "LG", "categories": ["LG", "", ""], "abstract": "  Recent studies in reinforcement learning (RL) have made significant progress\nby leveraging function approximation to alleviate the sample complexity hurdle\nfor better performance. Despite the success, existing provably efficient\nalgorithms typically rely on the accessibility of immediate feedback upon\ntaking actions. The failure to account for the impact of delay in observations\ncan significantly degrade the performance of real-world systems due to the\nregret blow-up. In this work, we tackle the challenge of delayed feedback in RL\nwith linear function approximation by employing posterior sampling, which has\nbeen shown to empirically outperform the popular UCB algorithms in a wide range\nof regimes. We first introduce Delayed-PSVI, an optimistic value-based\nalgorithm that effectively explores the value function space via noise\nperturbation with posterior sampling. We provide the first analysis for\nposterior sampling algorithms with delayed feedback in RL and show our\nalgorithm achieves $\\widetilde{O}(\\sqrt{d^3H^3 T} + d^2H^2 E[\\tau])$ worst-case\nregret in the presence of unknown stochastic delays. Here $E[\\tau]$ is the\nexpected delay. To further improve its computational efficiency and to expand\nits applicability in high-dimensional RL problems, we incorporate a\ngradient-based approximate sampling scheme via Langevin dynamics for\nDelayed-LPSVI, which maintains the same order-optimal regret guarantee with\n$\\widetilde{O}(dHK)$ computational cost. Empirical evaluations are performed to\ndemonstrate the statistical and computational efficacy of our algorithms.\n", "title": "Posterior Sampling with Delayed Feedback for Reinforcement Learning with\n  Linear Function Approximation", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18920", "abstract_url": "http://arxiv.org/abs/2310.18920", "authors": [{"last_name": "Fu", "first_name": "Zehua"}, {"last_name": "Zuo", "first_name": "Wenhang"}, {"last_name": "Hu", "first_name": "Zhenghui"}, {"last_name": "Liu", "first_name": "Qingjie"}, {"last_name": "Wang", "first_name": "Yunhong"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Human pose estimation and tracking are fundamental tasks for understanding\nhuman behaviors in videos. Existing top-down framework-based methods usually\nperform three-stage tasks: human detection, pose estimation and tracking.\nAlthough promising results have been achieved, these methods rely heavily on\nhigh-performance detectors and may fail to track persons who are occluded or\nmiss-detected. To overcome these problems, in this paper, we develop a novel\nkeypoint confidence network and a tracking pipeline to improve human detection\nand pose estimation in top-down approaches. Specifically, the keypoint\nconfidence network is designed to determine whether each keypoint is occluded,\nand it is incorporated into the pose estimation module. In the tracking\npipeline, we propose the Bbox-revision module to reduce missing detection and\nthe ID-retrieve module to correct lost trajectories, improving the performance\nof the detection stage. Experimental results show that our approach is\nuniversal in human detection and pose estimation, achieving state-of-the-art\nperformance on both PoseTrack 2017 and 2018 datasets.\n", "title": "Improving Multi-Person Pose Tracking with A Confidence Network", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18921", "abstract_url": "http://arxiv.org/abs/2310.18921", "authors": [{"last_name": "Rathore", "first_name": "Parikshit Singh"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  In this paper, we present an efficient solution for weed classification in\nagriculture. We focus on optimizing model performance at inference while\nrespecting the constraints of the agricultural domain. We propose a Quantized\nDeep Neural Network model that classifies a dataset of 9 weed classes using\n8-bit integer (int8) quantization, a departure from standard 32-bit floating\npoint (fp32) models. Recognizing the hardware resource limitations in\nagriculture, our model balances model size, inference time, and accuracy,\naligning with practical requirements. We evaluate the approach on ResNet-50 and\nInceptionV3 architectures, comparing their performance against their int8\nquantized versions. Transfer learning and fine-tuning are applied using the\nDeepWeeds dataset. The results show staggering model size and inference time\nreductions while maintaining accuracy in real-world production scenarios like\nDesktop, Mobile and Raspberry Pi. Our work sheds light on a promising direction\nfor efficient AI in agriculture, holding potential for broader applications.\n  Code: https://github.com/parikshit14/QNN-for-weed\n", "title": "QWID: Quantized Weed Identification Deep neural network", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18924", "abstract_url": "http://arxiv.org/abs/2310.18924", "authors": [{"last_name": "Suh", "first_name": "Sungho"}, {"last_name": "Mittal", "first_name": "Dhruv Aditya"}, {"last_name": "Bello", "first_name": "Hymalai"}, {"last_name": "Zhou", "first_name": "Bo"}, {"last_name": "Jha", "first_name": "Mayank Shekhar"}, {"last_name": "Lukowicz", "first_name": "Paul"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Lithium-ion batteries are widely used in various applications, including\nelectric vehicles and renewable energy storage. The prediction of the remaining\nuseful life (RUL) of batteries is crucial for ensuring reliable and efficient\noperation, as well as reducing maintenance costs. However, determining the life\ncycle of batteries in real-world scenarios is challenging, and existing methods\nhave limitations in predicting the number of cycles iteratively. In addition,\nexisting works often oversimplify the datasets, neglecting important features\nof the batteries such as temperature, internal resistance, and material type.\nTo address these limitations, this paper proposes a two-stage remaining useful\nlife prediction scheme for Lithium-ion batteries using a spatio-temporal\nmultimodal attention network (ST-MAN). The proposed model is designed to\niteratively predict the number of cycles required for the battery to reach the\nend of its useful life, based on available data. The proposed ST-MAN is to\ncapture the complex spatio-temporal dependencies in the battery data, including\nthe features that are often neglected in existing works. Experimental results\ndemonstrate that the proposed ST-MAN model outperforms existing CNN and\nLSTM-based methods, achieving state-of-the-art performance in predicting the\nremaining useful life of Li-ion batteries. The proposed method has the\npotential to improve the reliability and efficiency of battery operations and\nis applicable in various industries, including automotive and renewable energy.\n", "title": "Remaining Useful Life Prediction of Lithium-ion Batteries using\n  Spatio-temporal Multimodal Attention Networks", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18926", "abstract_url": "http://arxiv.org/abs/2310.18926", "authors": [{"last_name": "Wei", "first_name": "Rukai"}, {"last_name": "Liu", "first_name": "Yu"}, {"last_name": "Song", "first_name": "Jingkuan"}, {"last_name": "Cui", "first_name": "Heng"}, {"last_name": "Xie", "first_name": "Yanzhao"}, {"last_name": "Zhou", "first_name": "Ke"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Compressing videos into binary codes can improve retrieval speed and reduce\nstorage overhead. However, learning accurate hash codes for video retrieval can\nbe challenging due to high local redundancy and complex global dependencies\nbetween video frames, especially in the absence of labels. Existing\nself-supervised video hashing methods have been effective in designing\nexpressive temporal encoders, but have not fully utilized the temporal dynamics\nand spatial appearance of videos due to less challenging and unreliable\nlearning tasks. To address these challenges, we begin by utilizing the\ncontrastive learning task to capture global spatio-temporal information of\nvideos for hashing. With the aid of our designed augmentation strategies, which\nfocus on spatial and temporal variations to create positive pairs, the learning\nframework can generate hash codes that are invariant to motion, scale, and\nviewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e.,\nframe order verification and scene change regularization, to capture local\nspatio-temporal details within video frames, thereby enhancing the perception\nof temporal structure and the modeling of spatio-temporal relationships. Our\nproposed Contrastive Hashing with Global-Local Spatio-temporal Information\n(CHAIN) outperforms state-of-the-art self-supervised video hashing methods on\nfour video benchmark datasets. Our codes will be released.\n", "title": "CHAIN: Exploring Global-Local Spatio-Temporal Information for Improved\n  Self-Supervised Video Hashing", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18928", "abstract_url": "http://arxiv.org/abs/2310.18928", "authors": [{"last_name": "Younesi", "first_name": "Abolfazl"}, {"last_name": "Afrouzian", "first_name": "Reza"}, {"last_name": "Seyfari", "first_name": "Yousef"}], "primary_category": "CV", "categories": ["CV", "LG"], "abstract": "  Due to the epidemic of the coronavirus (Covid-19) and its rapid spread around\nthe world, the world has faced an enormous crisis. To prevent the spread of the\ncoronavirus, the World Health Organization (WHO) has introduced the use of\nmasks and keeping social distance as the best preventive method. So, developing\nan automatic monitoring system for detecting facemasks in some crowded places\nis essential. To do this, we propose a mask recognition system based on\ntransfer learning and Inception v3 architecture. In the proposed method, two\ndatasets are used simultaneously for training including the Simulated Mask Face\nDataset (SMFD) and MaskedFace-Net (MFN) This paper tries to increase the\naccuracy of the proposed system by optimally setting hyper-parameters and\naccurately designing the fully connected layers. The main advantage of the\nproposed method is that in addition to masked and unmasked faces, it can also\ndetect cases of incorrect use of mask. Therefore, the proposed method\nclassifies the input face images into three categories. Experimental results\nshow the high accuracy and efficiency of the proposed method; so, this method\nhas achieved an accuracy of 99.47% and 99.33% in training and test data\nrespectively\n", "title": "A transfer learning approach with convolutional neural network for Face\n  Mask Detection", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18929", "abstract_url": "http://arxiv.org/abs/2310.18929", "authors": [{"last_name": "Abdel-Keream", "first_name": "Mona"}, {"last_name": "Be\u00dfler", "first_name": "Daniel"}, {"last_name": "Janssen", "first_name": "Ayden"}, {"last_name": "Jongebloed", "first_name": "Sascha"}, {"last_name": "Nolte", "first_name": "Robin"}, {"last_name": "Pomarlan", "first_name": "Mihai"}, {"last_name": "Porzel", "first_name": "Robert"}], "primary_category": "RO", "categories": ["RO", "HC"], "abstract": "  The notion of preferences plays an important role in many disciplines\nincluding service robotics which is concerned with scenarios in which robots\ninteract with humans. These interactions can be favored by robots taking human\npreferences into account. This raises the issue of how preferences should be\nrepresented to support such preference-aware decision making. Several formal\naccounts for a notion of preferences exist. However, these approaches fall\nshort on defining the nature and structure of the options that a robot has in a\ngiven situation. In this work, we thus investigate a formal model of\npreferences where options are non-atomic entities that are defined by the\ncomplex situations they bring about.\n", "title": "An Ontological Model of User Preferences", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18930", "abstract_url": "http://arxiv.org/abs/2310.18930", "authors": [{"last_name": "Shah", "first_name": "Sapan"}, {"last_name": "Reddy", "first_name": "Sreedhar"}, {"last_name": "Bhattacharyya", "first_name": "Pushpak"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  We present a novel retrofitting method to induce emotion aspects into\npre-trained language models (PLMs) such as BERT and RoBERTa. Our method updates\npre-trained network weights using contrastive learning so that the text\nfragments exhibiting similar emotions are encoded nearby in the representation\nspace, and the fragments with different emotion content are pushed apart. While\ndoing so, it also ensures that the linguistic knowledge already present in PLMs\nis not inadvertently perturbed. The language models retrofitted by our method,\ni.e., BERTEmo and RoBERTaEmo, produce emotion-aware text representations, as\nevaluated through different clustering and retrieval metrics. For the\ndownstream tasks on sentiment analysis and sarcasm detection, they perform\nbetter than their pre-trained counterparts (about 1% improvement in F1-score)\nand other existing approaches. Additionally, a more significant boost in\nperformance is observed for the retrofitted models over pre-trained ones in\nfew-shot learning setting.\n", "title": "Retrofitting Light-weight Language Models for Emotions using Supervised\n  Contrastive Learning", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18932", "abstract_url": "http://arxiv.org/abs/2310.18932", "authors": [{"last_name": "Kim", "first_name": "Kyung Geun"}, {"last_name": "Lee", "first_name": "Byeong Tak"}], "primary_category": "", "categories": [""], "abstract": "  Many of diverse phenomena in nature often inherently encode both short and\nlong term temporal dependencies, short term dependencies especially resulting\nfrom the direction of flow of time. In this respect, we discovered experimental\nevidences suggesting that {\\it interrelations} of these events are higher for\ncloser time stamps. However, to be able for attention based models to learn\nthese regularities in short term dependencies, it requires large amounts of\ndata which are often infeasible. This is due to the reason that, while they are\ngood at learning piece wised temporal dependencies, attention based models lack\nstructures that encode biases in time series. As a resolution, we propose a\nsimple and efficient method that enables attention layers to better encode\nshort term temporal bias of these data sets by applying learnable, adaptive\nkernels directly to the attention matrices. For the experiments, we chose\nvarious prediction tasks using Electronic Health Records (EHR) data sets since\nthey are great examples that have underlying long and short term temporal\ndependencies. The results of our experiments show exceptional classification\nresults compared to best performing models on most of the task and data sets.\n", "title": "Self Attention with Temporal Prior: Can We Learn More from Arrow of\n  Time?", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18933", "abstract_url": "http://arxiv.org/abs/2310.18933", "authors": [{"last_name": "Jha", "first_name": "Rishi D."}, {"last_name": "Hayase", "first_name": "Jonathan"}, {"last_name": "Oh", "first_name": "Sewoong"}], "primary_category": "LG", "categories": ["LG", "CR", "CV"], "abstract": "  In a backdoor attack, an adversary injects corrupted data into a model's\ntraining dataset in order to gain control over its predictions on images with a\nspecific attacker-defined trigger. A typical corrupted training example\nrequires altering both the image, by applying the trigger, and the label.\nModels trained on clean images, therefore, were considered safe from backdoor\nattacks. However, in some common machine learning scenarios, the training\nlabels are provided by potentially malicious third-parties. This includes\ncrowd-sourced annotation and knowledge distillation. We, hence, investigate a\nfundamental question: can we launch a successful backdoor attack by only\ncorrupting labels? We introduce a novel approach to design label-only backdoor\nattacks, which we call FLIP, and demonstrate its strengths on three datasets\n(CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32,\nResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels\ncorrupted, FLIP achieves a near-perfect attack success rate of 99.4% while\nsuffering only a 1.8% drop in the clean test accuracy. Our approach builds upon\nthe recent advances in trajectory matching, originally introduced for dataset\ndistillation.\n", "title": "Label Poisoning is All You Need", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18935", "abstract_url": "http://arxiv.org/abs/2310.18935", "authors": [{"last_name": "Kou", "first_name": "Yiwen"}, {"last_name": "Chen", "first_name": "Zixiang"}, {"last_name": "Gu", "first_name": "Quanquan"}], "primary_category": "LG", "categories": ["LG", "", ""], "abstract": "  The implicit bias towards solutions with favorable properties is believed to\nbe a key reason why neural networks trained by gradient-based optimization can\ngeneralize well. While the implicit bias of gradient flow has been widely\nstudied for homogeneous neural networks (including ReLU and leaky ReLU\nnetworks), the implicit bias of gradient descent is currently only understood\nfor smooth neural networks. Therefore, implicit bias in non-smooth neural\nnetworks trained by gradient descent remains an open question. In this paper,\nwe aim to answer this question by studying the implicit bias of gradient\ndescent for training two-layer fully connected (leaky) ReLU neural networks. We\nshowed that when the training data are nearly-orthogonal, for leaky ReLU\nactivation function, gradient descent will find a network with a stable rank\nthat converges to $1$, whereas for ReLU activation function, gradient descent\nwill find a neural network with a stable rank that is upper bounded by a\nconstant. Additionally, we show that gradient descent will find a neural\nnetwork such that all the training data points have the same normalized margin\nasymptotically. Experiments on both synthetic and real data backup our\ntheoretical findings.\n", "title": "Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU\n  Networks on Nearly-orthogonal Data", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18936", "abstract_url": "http://arxiv.org/abs/2310.18936", "authors": [{"last_name": "Li", "first_name": "Ang"}, {"last_name": "Wang", "first_name": "Yifei"}, {"last_name": "Guo", "first_name": "Yiwen"}, {"last_name": "Wang", "first_name": "Yisen"}], "primary_category": "LG", "categories": ["LG", "CV"], "abstract": "  The existence of adversarial examples has been a mystery for years and\nattracted much interest. A well-known theory by \\citet{ilyas2019adversarial}\nexplains adversarial vulnerability from a data perspective by showing that one\ncan extract non-robust features from adversarial examples and these features\nalone are useful for classification. However, the explanation remains quite\ncounter-intuitive since non-robust features are mostly noise features to\nhumans. In this paper, we re-examine the theory from a larger context by\nincorporating multiple learning paradigms. Notably, we find that contrary to\ntheir good usefulness under supervised learning, non-robust features attain\npoor usefulness when transferred to other self-supervised learning paradigms,\nsuch as contrastive learning, masked image modeling, and diffusion models. It\nreveals that non-robust features are not really as useful as robust or natural\nfeatures that enjoy good transferability between these paradigms. Meanwhile,\nfor robustness, we also show that naturally trained encoders from robust\nfeatures are largely non-robust under AutoAttack. Our cross-paradigm\nexamination suggests that the non-robust features are not really useful but\nmore like paradigm-wise shortcuts, and robust features alone might be\ninsufficient to attain reliable model robustness. Code is available at\n\\url{https://github.com/PKU-ML/AdvNotRealFeatures}.\n", "title": "Adversarial Examples Are Not Real Features", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18937", "abstract_url": "http://arxiv.org/abs/2310.18937", "authors": [{"last_name": "Kenny", "first_name": "Eoin M."}, {"last_name": "Huang", "first_name": "Weipeng"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  When users receive either a positive or negative outcome from an automated\nsystem, Explainable AI (XAI) has almost exclusively focused on how to mutate\nnegative outcomes into positive ones by crossing a decision boundary using\ncounterfactuals (e.g., \\textit{\"If you earn 2k more, we will accept your loan\napplication\"}). Here, we instead focus on \\textit{positive} outcomes, and take\nthe novel step of using XAI to optimise them (e.g., \\textit{\"Even if you wish\nto half your down-payment, we will still accept your loan application\"}).\nExplanations such as these that employ \"even if...\" reasoning, and do not cross\na decision boundary, are known as semifactuals. To instantiate semifactuals in\nthis context, we introduce the concept of \\textit{Gain} (i.e., how much a user\nstands to benefit from the explanation), and consider the first causal\nformalisation of semifactuals. Tests on benchmark datasets show our algorithms\nare better at maximising gain compared to prior work, and that causality is\nimportant in the process. Most importantly however, a user study supports our\nmain hypothesis by showing people find semifactual explanations more useful\nthan counterfactuals when they receive the positive outcome of a loan\nacceptance.\n", "title": "The Utility of \"Even if...\" Semifactual Explanation to Optimise Positive\n  Outcomes", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18938", "abstract_url": "http://arxiv.org/abs/2310.18938", "authors": [{"last_name": "Deo", "first_name": "Shreyan"}, {"last_name": "Dwivedi", "first_name": "Nishchal"}], "primary_category": "", "categories": ["", "LG"], "abstract": "  This work focuses on the analysis of Chess 960, also known as Fischer Random\nChess, a variant of traditional chess where the starting positions of the\npieces are randomized. The study aims to predict the game outcome using machine\nlearning techniques and develop an opening theme for each starting position.\nThe first part of the analysis utilizes machine learning models to predict the\ngame result based on certain moves in each position. The methodology involves\nsegregating raw data from .pgn files into usable formats and creating datasets\ncomprising approximately 500 games for each starting position. Three machine\nlearning algorithms -- KNN Clustering, Random Forest, and Gradient Boosted\nTrees -- have been used to predict the game outcome. To establish an opening\ntheme, the board is divided into five regions: center, white kingside, white\nqueenside, black kingside, and black queenside. The data from games played by\ntop engines in all 960 positions is used to track the movement of pieces in the\nopening. By analysing the change in the number of pieces in each region at\nspecific moves, the report predicts the region towards which the game is\ndeveloping. These models provide valuable insights into predicting game\noutcomes and understanding the opening theme in Chess 960.\n", "title": "Machine Learning Algorithms to Predict Chess960 Result and Develop\n  Opening Themes", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18940", "abstract_url": "http://arxiv.org/abs/2310.18940", "authors": [{"last_name": "Xu", "first_name": "Zelai"}, {"last_name": "Yu", "first_name": "Chao"}, {"last_name": "Fang", "first_name": "Fei"}, {"last_name": "Wang", "first_name": "Yu"}, {"last_name": "Wu", "first_name": "Yi"}], "primary_category": "", "categories": ["", "LG", "MA"], "abstract": "  Agents built with large language models (LLMs) have recently achieved great\nadvancements. However, most of the efforts focus on single-agent or cooperative\nsettings, leaving more general multi-agent environments underexplored. We\npropose a new framework powered by reinforcement learning (RL) to develop\nstrategic language agents, i.e., LLM-based agents with strategic thinking\nability, for a popular language game, Werewolf. Werewolf is a social deduction\ngame with hidden roles that involves both cooperation and competition and\nemphasizes deceptive communication and diverse gameplay. Our agent tackles this\ngame by first using LLMs to reason about potential deceptions and generate a\nset of strategically diverse actions. Then an RL policy, which selects an\naction from the candidates, is learned by population-based training to enhance\nthe agents' decision-making ability. By combining LLMs with the RL policy, our\nagent produces a variety of emergent strategies, achieves the highest win rate\nagainst other LLM-based agents, and stays robust against adversarial human\nplayers in the Werewolf game.\n", "title": "Language Agents with Reinforcement Learning for Strategic Play in the\n  Werewolf Game", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18944", "abstract_url": "http://arxiv.org/abs/2310.18944", "authors": [{"last_name": "Xu", "first_name": "Yongxiu"}, {"last_name": "Huang", "first_name": "Heyan"}, {"last_name": "Hu", "first_name": "Yue"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  Named Entity Recognition (NER) remains challenging due to the complex\nentities, like nested, overlapping, and discontinuous entities. Existing\napproaches, such as sequence-to-sequence (Seq2Seq) generation and span-based\nclassification, have shown impressive performance on various NER subtasks, but\nthey are difficult to scale to datasets with longer input text because of\neither exposure bias issue or inefficient computation. In this paper, we\npropose a novel Sequence-to-Forest generation paradigm, S2F-NER, which can\ndirectly extract entities in sentence via a Forest decoder that decode multiple\nentities in parallel rather than sequentially. Specifically, our model generate\neach path of each tree in forest autoregressively, where the maximum depth of\neach tree is three (which is the shortest feasible length for complex NER and\nis far smaller than the decoding length of Seq2Seq). Based on this novel\nparadigm, our model can elegantly mitigates the exposure bias problem and keep\nthe simplicity of Seq2Seq. Experimental results show that our model\nsignificantly outperforms the baselines on three discontinuous NER datasets and\non two nested NER datasets, especially for discontinuous entity recognition.\n", "title": "S2F-NER: Exploring Sequence-to-Forest Generation for Complex Entity\n  Recognition", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18946", "abstract_url": "http://arxiv.org/abs/2310.18946", "authors": [{"last_name": "Hu", "first_name": "Ping"}, {"last_name": "Niklaus", "first_name": "Simon"}, {"last_name": "Zhang", "first_name": "Lu"}, {"last_name": "Sclaroff", "first_name": "Stan"}, {"last_name": "Saenko", "first_name": "Kate"}], "primary_category": "CV", "categories": ["CV", "MM"], "abstract": "  In this work, we first propose a fully differentiable Many-to-Many (M2M)\nsplatting framework to interpolate frames efficiently. Given a frame pair, we\nestimate multiple bidirectional flows to directly forward warp the pixels to\nthe desired time step before fusing overlapping pixels. In doing so, each\nsource pixel renders multiple target pixels and each target pixel can be\nsynthesized from a larger area of visual context, establishing a many-to-many\nsplatting scheme with robustness to undesirable artifacts. For each input frame\npair, M2M has a minuscule computational overhead when interpolating an\narbitrary number of in-between frames, hence achieving fast multi-frame\ninterpolation. However, directly warping and fusing pixels in the intensity\ndomain is sensitive to the quality of motion estimation and may suffer from\nless effective representation capacity. To improve interpolation accuracy, we\nfurther extend an M2M++ framework by introducing a flexible Spatial Selective\nRefinement (SSR) component, which allows for trading computational efficiency\nfor interpolation quality and vice versa. Instead of refining the entire\ninterpolated frame, SSR only processes difficult regions selected under the\nguidance of an estimated error map, thereby avoiding redundant computation.\nEvaluation on multiple benchmark datasets shows that our method is able to\nimprove the efficiency while maintaining competitive video interpolation\nquality, and it can be adjusted to use more or less compute as needed.\n", "title": "Video Frame Interpolation with Many-to-many Splatting and Spatial\n  Selective Refinement", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18948", "abstract_url": "http://arxiv.org/abs/2310.18948", "authors": [{"last_name": "Spadon", "first_name": "Gabriel"}, {"last_name": "Kumar", "first_name": "Jay"}, {"last_name": "Smith", "first_name": "Matthew"}, {"last_name": "Vela", "first_name": "Sarah"}, {"last_name": "Gehrmann", "first_name": "Romina"}, {"last_name": "Eden", "first_name": "Derek"}, {"last_name": "van Berkel", "first_name": "Joshua"}, {"last_name": "Soares", "first_name": "Amilcar"}, {"last_name": "Fablet", "first_name": "Ronan"}, {"last_name": "Pelot", "first_name": "Ronald"}, {"last_name": "Matwin", "first_name": "Stan"}], "primary_category": "LG", "categories": ["LG", "", "DM", ""], "abstract": "  Maritime transport is paramount to global economic growth and environmental\nsustainability. In this regard, the Automatic Identification System (AIS) data\nplays a significant role by offering real-time streaming data on vessel\nmovement, which allows for enhanced traffic surveillance, assisting in vessel\nsafety by avoiding vessel-to-vessel collisions and proactively preventing\nvessel-to-whale ones. This paper tackles an intrinsic problem to trajectory\nforecasting: the effective multi-path long-term vessel trajectory forecasting\non engineered sequences of AIS data. We utilize an encoder-decoder model with\nBidirectional Long Short-Term Memory Networks (Bi-LSTM) to predict the next 12\nhours of vessel trajectories using 1 to 3 hours of AIS data. We feed the model\nwith probabilistic features engineered from the AIS data that refer to the\npotential route and destination of each trajectory so that the model,\nleveraging convolutional layers for spatial feature learning and a\nposition-aware attention mechanism that increases the importance of recent\ntimesteps of a sequence during temporal feature learning, forecasts the vessel\ntrajectory taking the potential route and destination into account. The F1\nScore of these features is approximately 85% and 75%, indicating their\nefficiency in supplementing the neural network. We trialed our model in the\nGulf of St. Lawrence, one of the North Atlantic Right Whales (NARW) habitats,\nachieving an R2 score exceeding 98% with varying techniques and features.\nDespite the high R2 score being attributed to well-defined shipping lanes, our\nmodel demonstrates superior complex decision-making during path selection. In\naddition, our model shows enhanced accuracy, with average and median\nforecasting errors of 11km and 6km, respectively. Our study confirms the\npotential of geographical data engineering and trajectory forecasting models\nfor preserving marine life species.\n", "title": "Building a Safer Maritime Environment Through Multi-Path Long-Term\n  Vessel Trajectory Forecasting", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18949", "abstract_url": "http://arxiv.org/abs/2310.18949", "authors": [{"last_name": "Zhang", "first_name": "Shaocong"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Generating images from human sketches typically requires dedicated networks\ntrained from scratch. In contrast, the emergence of the pre-trained\nVision-Language models (e.g., CLIP) has propelled generative applications based\non controlling the output imagery of existing StyleGAN models with text inputs\nor reference images. Parallelly, our work proposes a framework to control\nStyleGAN imagery with a single user sketch. In particular, we learn a\nconditional distribution in the latent space of a pre-trained StyleGAN model\nvia energy-based learning and propose two novel energy functions leveraging\nCLIP for cross-domain semantic supervision. Once trained, our model can\ngenerate multi-modal images semantically aligned with the input sketch.\nQuantitative evaluations on synthesized datasets have shown that our approach\nimproves significantly from previous methods in the one-shot regime. The\nsuperiority of our method is further underscored when experimenting with a wide\nrange of human sketches of diverse styles and poses. Surprisingly, our models\noutperform the previous baseline regarding both the range of sketch inputs and\nimage qualities despite operating with a stricter setting: with no extra\ntraining data and single sketch input.\n", "title": "Customize StyleGAN with One Hand Sketch", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18951", "abstract_url": "http://arxiv.org/abs/2310.18951", "authors": [{"last_name": "Yu", "first_name": "Zhihang"}, {"last_name": "Wang", "first_name": "Shu"}, {"last_name": "Zhu", "first_name": "Yunqiang"}, {"last_name": "Zou", "first_name": "Zhiqiang"}], "primary_category": "IR", "categories": ["IR"], "abstract": "  The Ecological Civilization Pattern Recommendation System (ECPRS) aims to\nrecommend suitable ecological civilization patterns for target regions,\npromoting sustainable development and reducing regional disparities. However,\nthe current representative recommendation methods are not suitable for\nrecommending ecological civilization patterns in a geographical context. There\nare two reasons for this. Firstly, regions have spatial heterogeneity, and the\n(ECPRS)needs to consider factors like climate, topography, vegetation, etc., to\nrecommend civilization patterns adapted to specific ecological environments,\nensuring the feasibility and practicality of the recommendations. Secondly, the\nabstract features of the ecological civilization patterns in the real world\nhave not been fully utilized., resulting in poor richness in their embedding\nrepresentations and consequently, lower performance of the recommendation\nsystem. Considering these limitations, we propose the ECPR-MML method.\nInitially, based on the novel method UGPIG, we construct a knowledge graph to\nextract regional representations incorporating spatial heterogeneity features.\nFollowing that, inspired by the significant progress made by Large Language\nModels (LLMs) in the field of Natural Language Processing (NLP), we employ\nLarge LLMs to generate multimodal features for ecological civilization patterns\nin the form of text and images. We extract and integrate these multimodal\nfeatures to obtain semantically rich representations of ecological\ncivilization. Through extensive experiments, we validate the performance of our\nECPR-MML model. Our results show that F1@5 is 2.11% higher compared to\nstate-of-the-art models, 2.02% higher than NGCF, and 1.16% higher than UGPIG.\nFurthermore, multimodal data can indeed enhance recommendation performance.\nHowever, the data generated by LLM is not as effective as real data to a\ncertain extent.\n", "title": "A Multimodal Ecological Civilization Pattern Recommendation Method Based\n  on Large Language Models and Knowledge Graph", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18953", "abstract_url": "http://arxiv.org/abs/2310.18953", "authors": [{"last_name": "Shukla", "first_name": "Megh"}, {"last_name": "Salzmann", "first_name": "Mathieu"}, {"last_name": "Alahi", "first_name": "Alexandre"}], "primary_category": "LG", "categories": ["LG", "CV", ""], "abstract": "  We study the problem of unsupervised heteroscedastic covariance estimation,\nwhere the goal is to learn the multivariate target distribution $\\mathcal{N}(y,\n\\Sigma_y | x )$ given an observation $x$. This problem is particularly\nchallenging as $\\Sigma_{y}$ varies for different samples (heteroscedastic) and\nno annotation for the covariance is available (unsupervised). Typically,\nstate-of-the-art methods predict the mean $f_{\\theta}(x)$ and covariance\n$\\textrm{Cov}(f_{\\theta}(x))$ of the target distribution through two neural\nnetworks trained using the negative log-likelihood. This raises two questions:\n(1) Does the predicted covariance truly capture the randomness of the predicted\nmean? (2) In the absence of ground-truth annotation, how can we quantify the\nperformance of covariance estimation? We address (1) by deriving TIC: Taylor\nInduced Covariance, which captures the randomness of the multivariate\n$f_{\\theta}(x)$ by incorporating its gradient and curvature around $x$ through\nthe second order Taylor polynomial. Furthermore, we tackle (2) by introducing\nTAC: Task Agnostic Correlations, a metric which leverages conditioning of the\nnormal distribution to evaluate the covariance. We verify the effectiveness of\nTIC through multiple experiments spanning synthetic (univariate, multivariate)\nand real-world datasets (UCI Regression, LSP, and MPII Human Pose Estimation).\nOur experiments show that TIC outperforms state-of-the-art in accurately\nlearning the covariance, as quantified through TAC.\n", "title": "TIC-TAC: A Framework To Learn And Evaluate Your Covariance", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18954", "abstract_url": "http://arxiv.org/abs/2310.18954", "authors": [{"last_name": "Weng", "first_name": "Yuetian"}, {"last_name": "Han", "first_name": "Mingfei"}, {"last_name": "He", "first_name": "Haoyu"}, {"last_name": "Li", "first_name": "Mingjie"}, {"last_name": "Yao", "first_name": "Lina"}, {"last_name": "Chang", "first_name": "Xiaojun"}, {"last_name": "Zhuang", "first_name": "Bohan"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Video Semantic Segmentation (VSS) involves assigning a semantic label to each\npixel in a video sequence. Prior work in this field has demonstrated promising\nresults by extending image semantic segmentation models to exploit temporal\nrelationships across video frames; however, these approaches often incur\nsignificant computational costs. In this paper, we propose an efficient mask\npropagation framework for VSS, called MPVSS. Our approach first employs a\nstrong query-based image segmentor on sparse key frames to generate accurate\nbinary masks and class predictions. We then design a flow estimation module\nutilizing the learned queries to generate a set of segment-aware flow maps,\neach associated with a mask prediction from the key frame. Finally, the\nmask-flow pairs are warped to serve as the mask predictions for the non-key\nframes. By reusing predictions from key frames, we circumvent the need to\nprocess a large volume of video frames individually with resource-intensive\nsegmentors, alleviating temporal redundancy and significantly reducing\ncomputational costs. Extensive experiments on VSPW and Cityscapes demonstrate\nthat our mask propagation framework achieves SOTA accuracy and efficiency\ntrade-offs. For instance, our best model with Swin-L backbone outperforms the\nSOTA MRCFA using MiT-B5 by 4.0% mIoU, requiring only 26% FLOPs on the VSPW\ndataset. Moreover, our framework reduces up to 4x FLOPs compared to the\nper-frame Mask2Former baseline with only up to 2% mIoU degradation on the\nCityscapes validation set. Code is available at\nhttps://github.com/ziplab/MPVSS.\n", "title": "Mask Propagation for Efficient Video Semantic Segmentation", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18955", "abstract_url": "http://arxiv.org/abs/2310.18955", "authors": [{"last_name": "Sinha", "first_name": "Abhishek"}, {"last_name": "Vaze", "first_name": "Rahul"}], "primary_category": "LG", "categories": ["LG", ""], "abstract": "  We study a generalization of the classic Online Convex Optimization (OCO)\nframework by considering additional long-term adversarial constraints.\nSpecifically, after an online policy decides its action on a round, in addition\nto a convex cost function, the adversary also reveals a set of $k$ convex\nconstraints. The cost and the constraint functions could change arbitrarily\nwith time, and no information about the future functions is assumed to be\navailable. In this paper, we propose a meta-policy that simultaneously achieves\na sublinear cumulative constraint violation and a sublinear regret. This is\nachieved via a black box reduction of the constrained problem to the standard\nOCO problem for a recursively constructed sequence of surrogate cost functions.\nWe show that optimal performance bounds can be achieved by solving the\nsurrogate problem using any adaptive OCO policy enjoying a standard\ndata-dependent regret bound. A new Lyapunov-based proof technique is presented\nthat reveals a connection between regret and certain sequential inequalities\nthrough a novel decomposition result. We conclude the paper by highlighting\napplications to online multi-task learning and network control problems.\n", "title": "Playing in the Dark: No-regret Learning with Adversarial Constraints", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18956", "abstract_url": "http://arxiv.org/abs/2310.18956", "authors": [{"last_name": "Towle", "first_name": "Benjamin"}, {"last_name": "Zhou", "first_name": "Ke"}], "primary_category": "CL", "categories": ["CL", "", "LG"], "abstract": "  Reply suggestion systems represent a staple component of many instant\nmessaging and email systems. However, the requirement to produce sets of\nreplies, rather than individual replies, makes the task poorly suited for\nout-of-the-box retrieval architectures, which only consider individual\nmessage-reply similarity. As a result, these system often rely on additional\npost-processing modules to diversify the outputs. However, these approaches are\nultimately bottlenecked by the performance of the initial retriever, which in\npractice struggles to present a sufficiently diverse range of options to the\ndownstream diversification module, leading to the suggestions being less\nrelevant to the user. In this paper, we consider a novel approach that\nradically simplifies this pipeline through an autoregressive text-to-text\nretrieval model, that learns the smart reply task end-to-end from a dataset of\n(message, reply set) pairs obtained via bootstrapping. Empirical results show\nthis method consistently outperforms a range of state-of-the-art baselines\nacross three datasets, corresponding to a 5.1%-17.9% improvement in relevance,\nand a 0.5%-63.1% improvement in diversity compared to the best baseline\napproach. We make our code publicly available.\n", "title": "End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply\n  Systems", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18961", "abstract_url": "http://arxiv.org/abs/2310.18961", "authors": [{"last_name": "Zhou", "first_name": "Qihang"}, {"last_name": "Pang", "first_name": "Guansong"}, {"last_name": "Tian", "first_name": "Yu"}, {"last_name": "He", "first_name": "Shibo"}, {"last_name": "Chen", "first_name": "Jiming"}], "primary_category": "CV", "categories": ["CV"], "abstract": "  Zero-shot anomaly detection (ZSAD) requires detection models trained using\nauxiliary data to detect anomalies without any training sample in a target\ndataset. It is a crucial task when training data is not accessible due to\nvarious concerns, \\eg, data privacy, yet it is challenging since the models\nneed to generalize to anomalies across different domains where the appearance\nof foreground objects, abnormal regions, and background features, such as\ndefects/tumors on different products/organs, can vary significantly. Recently\nlarge pre-trained vision-language models (VLMs), such as CLIP, have\ndemonstrated strong zero-shot recognition ability in various vision tasks,\nincluding anomaly detection. However, their ZSAD performance is weak since the\nVLMs focus more on modeling the class semantics of the foreground objects\nrather than the abnormality/normality in the images. In this paper we introduce\na novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across\ndifferent domains. The key insight of AnomalyCLIP is to learn object-agnostic\ntext prompts that capture generic normality and abnormality in an image\nregardless of its foreground objects. This allows our model to focus on the\nabnormal image regions rather than the object semantics, enabling generalized\nnormality and abnormality recognition on diverse types of objects. Large-scale\nexperiments on 17 real-world anomaly detection datasets show that AnomalyCLIP\nachieves superior zero-shot performance of detecting and segmenting anomalies\nin datasets of highly diverse class semantics from various defect inspection\nand medical imaging domains. Code will be made available at\nhttps://github.com/zqhang/AnomalyCLIP.\n", "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly\n  Detection", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18964", "abstract_url": "http://arxiv.org/abs/2310.18964", "authors": [{"last_name": "Nasir", "first_name": "Ahmad"}, {"last_name": "Sharma", "first_name": "Aadish"}, {"last_name": "Jaidka", "first_name": "Kokil"}], "primary_category": "CL", "categories": ["CL"], "abstract": "  This paper compares different pre-trained and fine-tuned large language\nmodels (LLMs) for hate speech detection. Our research underscores challenges in\nLLMs' cross-domain validity and overfitting risks. Through evaluations, we\nhighlight the need for fine-tuned models that grasp the nuances of hate speech\nthrough greater label heterogeneity. We conclude with a vision for the future\nof hate speech detection, emphasizing cross-domain generalizability and\nappropriate benchmarking practices.\n", "title": "LLMs and Finetuning: Benchmarking cross-domain performance for hate\n  speech detection", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18965", "abstract_url": "http://arxiv.org/abs/2310.18965", "authors": [{"last_name": "Yamakami", "first_name": "Tomoyuki"}], "primary_category": "CC", "categories": ["CC", "FL"], "abstract": "  Lately, there have been intensive studies on strengths and limitations of\nnonuniform families of promise decision problems solvable by various types of\npolynomial-size finite automata families, where \"polynomial-size\" refers to the\npolynomially-bounded state complexity of a finite automata family. In this line\nof study, we further expand the scope of these studies to families of partial\ncounting and gap functions, defined in terms of nonuniform families of\npolynomial-size nondeterministic finite automata, and their relevant families\nof promise decision problems. Counting functions have an ability of counting\nthe number of accepting computation paths produced by nondeterministic finite\nautomata. With no unproven hardness assumption, we show numerous separations\nand collapses of complexity classes of those partial counting and gap function\nfamilies and their induced promise decision problem families. We also\ninvestigate their relationships to pushdown automata families of polynomial\nstack-state complexity.\n", "title": "Power of Counting by Nonuniform Families of Polynomial-Size Finite\n  Automata", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18966", "abstract_url": "http://arxiv.org/abs/2310.18966", "authors": [{"last_name": "Bourriez", "first_name": "Nicolas"}, {"last_name": "Loizeau", "first_name": "Adrien"}, {"last_name": "Abdin", "first_name": "Adam F."}], "primary_category": "RO", "categories": ["RO", "", "CV"], "abstract": "  The space environment around the Earth is becoming increasingly populated by\nboth active spacecraft and space debris. To avoid potential collision events,\nsignificant improvements in Space Situational Awareness (SSA) activities and\nCollision Avoidance (CA) technologies are allowing the tracking and maneuvering\nof spacecraft with increasing accuracy and reliability. However, these\nprocedures still largely involve a high level of human intervention to make the\nnecessary decisions. For an increasingly complex space environment, this\ndecision-making strategy is not likely to be sustainable. Therefore, it is\nimportant to successfully introduce higher levels of automation for key Space\nTraffic Management (STM) processes to ensure the level of reliability needed\nfor navigating a large number of spacecraft. These processes range from\ncollision risk detection to the identification of the appropriate action to\ntake and the execution of avoidance maneuvers. This work proposes an\nimplementation of autonomous CA decision-making capabilities on spacecraft\nbased on Reinforcement Learning (RL) techniques. A novel methodology based on a\nPartially Observable Markov Decision Process (POMDP) framework is developed to\ntrain the Artificial Intelligence (AI) system on board the spacecraft,\nconsidering epistemic and aleatory uncertainties. The proposed framework\nconsiders imperfect monitoring information about the status of the debris in\norbit and allows the AI system to effectively learn stochastic policies to\nperform accurate Collision Avoidance Maneuvers (CAMs). The objective is to\nsuccessfully delegate the decision-making process for autonomously implementing\na CAM to the spacecraft without human intervention. This approach would allow\nfor a faster response in the decision-making process and for highly\ndecentralized operations.\n", "title": "Spacecraft Autonomous Decision-Planning for Collision Avoidance: a\n  Reinforcement Learning Approach", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18969", "abstract_url": "http://arxiv.org/abs/2310.18969", "authors": [{"last_name": "Vilas", "first_name": "Martina G."}, {"last_name": "Schauml\u00f6ffel", "first_name": "Timothy"}, {"last_name": "Roig", "first_name": "Gemma"}], "primary_category": "CV", "categories": ["CV", ""], "abstract": "  Despite the growing use of transformer models in computer vision, a\nmechanistic understanding of these networks is still needed. This work\nintroduces a method to reverse-engineer Vision Transformers trained to solve\nimage classification tasks. Inspired by previous research in NLP, we\ndemonstrate how the inner representations at any level of the hierarchy can be\nprojected onto the learned class embedding space to uncover how these networks\nbuild categorical representations for their predictions. We use our framework\nto show how image tokens develop class-specific representations that depend on\nattention mechanisms and contextual information, and give insights on how\nself-attention and MLP layers differentially contribute to this categorical\ncomposition. We additionally demonstrate that this method (1) can be used to\ndetermine the parts of an image that would be important for detecting the class\nof interest, and (2) exhibits significant advantages over traditional linear\nprobing approaches. Taken together, our results position our proposed framework\nas a powerful tool for mechanistic interpretability and explainability\nresearch.\n", "title": "Analyzing Vision Transformers for Image Classification in Class\n  Embedding Space", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18970", "abstract_url": "http://arxiv.org/abs/2310.18970", "authors": [{"last_name": "Seedat", "first_name": "Nabeel"}, {"last_name": "Crabb\u00e9", "first_name": "Jonathan"}, {"last_name": "Qian", "first_name": "Zhaozhi"}, {"last_name": "van der Schaar", "first_name": "Mihaela"}], "primary_category": "LG", "categories": ["LG"], "abstract": "  Data quality is crucial for robust machine learning algorithms, with the\nrecent interest in data-centric AI emphasizing the importance of training data\ncharacterization. However, current data characterization methods are largely\nfocused on classification settings, with regression settings largely\nunderstudied. To address this, we introduce TRIAGE, a novel data\ncharacterization framework tailored to regression tasks and compatible with a\nbroad class of regressors. TRIAGE utilizes conformal predictive distributions\nto provide a model-agnostic scoring method, the TRIAGE score. We operationalize\nthe score to analyze individual samples' training dynamics and characterize\nsamples as under-, over-, or well-estimated by the model. We show that TRIAGE's\ncharacterization is consistent and highlight its utility to improve performance\nvia data sculpting/filtering, in multiple regression settings. Additionally,\nbeyond sample level, we show TRIAGE enables new approaches to dataset selection\nand feature acquisition. Overall, TRIAGE highlights the value unlocked by data\ncharacterization in real-world regression applications\n", "title": "TRIAGE: Characterizing and auditing training data for improved\n  regression", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18974", "abstract_url": "http://arxiv.org/abs/2310.18974", "authors": [{"last_name": "Dwivedi", "first_name": "Ashutosh"}, {"last_name": "Lavania", "first_name": "Pradhyumna"}, {"last_name": "Modi", "first_name": "Ashutosh"}], "primary_category": "CL", "categories": ["CL", "", "LG"], "abstract": "  Etiquettes are an essential ingredient of day-to-day interactions among\npeople. Moreover, etiquettes are region-specific, and etiquettes in one region\nmight contradict those in other regions. In this paper, we propose EtiCor, an\nEtiquettes Corpus, having texts about social norms from five different regions\nacross the globe. The corpus provides a test bed for evaluating LLMs for\nknowledge and understanding of region-specific etiquettes. Additionally, we\npropose the task of Etiquette Sensitivity. We experiment with state-of-the-art\nLLMs (Delphi, Falcon40B, and GPT-3.5). Initial results indicate that LLMs,\nmostly fail to understand etiquettes from regions from non-Western world.\n", "title": "EtiCor: Corpus for Analyzing LLMs for Etiquettes", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18979", "abstract_url": "http://arxiv.org/abs/2310.18979", "authors": [{"last_name": "Mendling", "first_name": "Jan"}, {"last_name": "Leopold", "first_name": "Henrik"}, {"last_name": "Meyerhenke", "first_name": "Henning"}, {"last_name": "Depaire", "first_name": "Beno\u00eet"}], "primary_category": "DS", "categories": ["DS"], "abstract": "  Research on algorithms has drastically increased in recent years. Various\nsub-disciplines of computer science investigate algorithms according to\ndifferent objectives and standards. This plurality of the field has led to\nvarious methodological advances that have not yet been transferred to\nneighboring sub-disciplines. The central roadblock for a better knowledge\nexchange is the lack of a common methodological framework integrating the\nperspectives of these sub-disciplines. It is the objective of this paper to\ndevelop a research framework for algorithm engineering. Our framework builds on\nthree areas discussed in the philosophy of science: ontology, epistemology and\nmethodology. In essence, ontology describes algorithm engineering as being\nconcerned with algorithmic problems, algorithmic tasks, algorithm designs and\nalgorithm implementations. Epistemology describes the body of knowledge of\nalgorithm engineering as a collection of prescriptive and descriptive\nknowledge, residing in World 3 of Popper's Three Worlds model. Methodology\nrefers to the steps how we can systematically enhance our knowledge of specific\nalgorithms. The framework helps us to identify and discuss various validity\nconcerns relevant to any algorithm engineering contribution. In this way, our\nframework has important implications for researching algorithms in various\nareas of computer science.\n", "title": "Methodology of Algorithm Engineering", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18981", "abstract_url": "http://arxiv.org/abs/2310.18981", "authors": [{"last_name": "Albareda-Sambola", "first_name": "Maria"}, {"last_name": "Fern\u00e1ndez", "first_name": "Elena"}, {"last_name": "Saldanha-da-Gama", "first_name": "Francisco"}], "primary_category": "", "categories": ["", "DM"], "abstract": "  This paper focuses on the Facility Location Problem with Bernoulli Demand, a\ndiscrete facility location problem with uncertainty where the joint\ndistribution of the customers' demands is expressed by means of a set of\npossible scenarios. A two-stage stochastic program with recourse is used to\nselect the facility locations and the a priori assignments of customers to open\nplants, together with the a posteriori strategy to apply in those realizations\nwhere the a priori solution is not feasible. Four alternative outsourcing\npolicies are studied for the recourse action, and a mathematical programming\nformulation is presented for each of them. Extensive computational experiments\nhave been carried-out to analyze the performance of each of the formulations\nand to compare the quality of the solutions produced by each of them relative\nto the other outsourcing policies.\n", "title": "Outsourcing policies for the Facility Location Problem with Bernoulli\n  Demand", "date": "2023-10-29", "group": "cs"}, {"identifier": "oai:arXiv.org:2310.18983", "abstract_url": "http://arxiv.org/abs/2310.18983", "authors": [{"last_name": "Wu", "first_name": "Anran"}, {"last_name": "Xiao", "first_name": "Luwei"}, {"last_name": "Wu", "first_name": "Xingjiao"}, {"last_name": "Yang", "first_name": "Shuwen"}, {"last_name": "Xu", "first_name": "Junjie"}, {"last_name": "Zhuang", "first_name": "Zisong"}, {"last_name": "Xie", "first_name": "Nian"}, {"last_name": "Jin", "first_name": "Cheng"}, {"last_name": "He", "first_name": "Liang"}], "primary_category": "", "categories": [""], "abstract": "  Visually-situated languages such as charts and plots are omnipresent in\nreal-world documents. These graphical depictions are human-readable and are\noften analyzed in visually-rich documents to address a variety of questions\nthat necessitate complex reasoning and common-sense responses. Despite the\ngrowing number of datasets that aim to answer questions over charts, most only\naddress this task in isolation, without considering the broader context of\ndocument-level question answering. Moreover, such datasets lack adequate\ncommon-sense reasoning information in their questions. In this work, we\nintroduce a novel task named document-level chart question answering (DCQA).\nThe goal of this task is to conduct document-level question answering,\nextracting charts or plots in the document via document layout analysis (DLA)\nfirst and subsequently performing chart question answering (CQA). The newly\ndeveloped benchmark dataset comprises 50,010 synthetic documents integrating\ncharts in a wide range of styles (6 styles in contrast to 3 for PlotQA and\nChartQA) and includes 699,051 questions that demand a high degree of reasoning\nability and common-sense understanding. Besides, we present the development of\na potent question-answer generation engine that employs table data, a rich\ncolor set, and basic question templates to produce a vast array of reasoning\nquestion-answer pairs automatically. Based on DCQA, we devise an OCR-free\ntransformer for document-level chart-oriented understanding, capable of DLA and\nanswering complex reasoning and common-sense questions over charts in an\nOCR-free manner. Our DCQA dataset is expected to foster research on\nunderstanding visualizations in documents, especially for scenarios that\nrequire complex reasoning for charts in the visually-rich document. We\nimplement and evaluate a set of baselines, and our proposed method achieves\ncomparable results.\n", "title": "DCQA: Document-Level Chart Question Answering towards Complex Reasoning\n  and Common-Sense Understanding", "date": "2023-10-29", "group": "cs"}]}